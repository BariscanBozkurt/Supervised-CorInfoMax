{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7492e9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import glob\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "from itertools import repeat\n",
    "from torch.nn.parameter import Parameter\n",
    "import collections\n",
    "import matplotlib\n",
    "from torch_utils import *\n",
    "from models import *\n",
    "from visualization import *\n",
    "# matplotlib.use('Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "155e542e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c51f0747",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(), \n",
    "                                            torchvision.transforms.Normalize(mean=(0.0,), std=(1.0,))])\n",
    "\n",
    "mnist_dset_train = torchvision.datasets.MNIST('./data', train=True, transform=transform, target_transform=None, download=True)\n",
    "train_loader = torch.utils.data.DataLoader(mnist_dset_train, batch_size=20, shuffle=True, num_workers=0)\n",
    "\n",
    "mnist_dset_test = torchvision.datasets.MNIST('./data', train=False, transform=transform, target_transform=None, download=True)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_dset_test, batch_size=20, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de1ad4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = hard_sigmoid\n",
    "criterion = torch.nn.MSELoss(reduction='none').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "953b2eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "architecture = [784, 500, 10]\n",
    "\n",
    "x,y = next(iter(train_loader))\n",
    "x = x.view(x.size(0),-1).to(device).T\n",
    "y_one_hot = F.one_hot(y, 10).to(device).T\n",
    "\n",
    "lambda_h = 0.9999\n",
    "lambda_y = 0.9999\n",
    "epsilon = 0.1\n",
    "one_over_epsilon = 1 / epsilon\n",
    "lr = {'ff' : 0.1, 'fb': 0.1, 'lat': 1e-3}\n",
    "neural_lr = 0.05\n",
    "model = TwoLayerCorInfoMax(architecture = architecture, lambda_h = lambda_h, lambda_y = lambda_y, \n",
    "                           epsilon = epsilon, activation = activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf85ec83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [00:34, 85.79it/s]\n",
      "9it [00:00, 88.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1, Train Accuracy : 0.19958333333333333, Test Accuracy : 0.1989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "690it [00:07, 89.93it/s]"
     ]
    }
   ],
   "source": [
    "trn_acc_list = []\n",
    "tst_acc_list = []\n",
    "neural_dynamic_iterations_free = 20\n",
    "neural_dynamic_iterations_nudged = 4\n",
    "# lambda_h = 0.01\n",
    "# lambda_y = 0.01\n",
    "# epsilon = 1\n",
    "# one_over_epsilon = 1 / epsilon\n",
    "beta = 1\n",
    "n_epochs = 50\n",
    "# lr = {'ff' : 1e-3, 'fb': 1e-3, 'lat': 1e-3}\n",
    "# neural_lr = 0.25\n",
    "\n",
    "for epoch_ in range(n_epochs):\n",
    "    for idx, (x, y) in tqdm(enumerate(train_loader)):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        x = x.view(x.size(0),-1).T\n",
    "        y_one_hot = F.one_hot(y, 10).to(device).T\n",
    "\n",
    "        h, y_hat = model.batch_step(  x, y_one_hot, lr, neural_lr, neural_dynamic_iterations_free, \n",
    "                                      neural_dynamic_iterations_nudged, beta)\n",
    "\n",
    "    trn_acc = evaluateCorInfoMax(model, train_loader, neural_lr, 20, device = 'cuda', printing = False)\n",
    "    tst_acc = evaluateCorInfoMax(model, test_loader, neural_lr, 20, device = 'cuda', printing = False)\n",
    "    trn_acc_list.append(trn_acc)\n",
    "    tst_acc_list.append(tst_acc)\n",
    "    if epoch_ == 4:\n",
    "        lr = {'ff' : 0.1, 'fb': 0.1, 'lat': 1e-3}\n",
    "    \n",
    "    print(\"Epoch : {}, Train Accuracy : {}, Test Accuracy : {}\".format(epoch_+1, trn_acc, tst_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d928fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14885bda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3ba852",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb9b9cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5810019c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerCorInfoMax():\n",
    "    \n",
    "    def __init__(self, architecture, lambda_h, lambda_y, epsilon, activation = hard_sigmoid):\n",
    "        \n",
    "        self.architecture = architecture\n",
    "        self.lambda_h = lambda_h\n",
    "        self.lambda_y = lambda_y\n",
    "        self.epsilon = epsilon\n",
    "        self.one_over_epsilon = one_over_epsilon\n",
    "        self.activation = activation\n",
    "        self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        # Feedforward Synapses Initialization\n",
    "        Wff = []\n",
    "        for idx in range(len(architecture)-1):\n",
    "            weight = torch.randn(architecture[idx + 1], architecture[idx], requires_grad = False).to(device)\n",
    "            torch.nn.init.xavier_uniform_(weight)\n",
    "            bias = torch.zeros(architecture[idx + 1], 1, requires_grad = False).to(device)\n",
    "            Wff.append({'weight': weight, 'bias': bias})\n",
    "        Wff = np.array(Wff)\n",
    "        \n",
    "        # Feedback Synapses Initialization\n",
    "        Wfb = []\n",
    "        for idx in range(len(architecture)-1):\n",
    "            weight = torch.randn(architecture[idx], architecture[idx + 1], requires_grad = False).to(device)\n",
    "            torch.nn.init.xavier_uniform_(weight)\n",
    "            bias = torch.zeros(architecture[idx], 1, requires_grad = False).to(device)\n",
    "            Wfb.append({'weight': weight, 'bias': bias})\n",
    "        Wfb = np.array(Wfb)\n",
    "        \n",
    "        # Lateral Synapses Initialization\n",
    "        B = []\n",
    "        for idx in range(len(architecture)-1):\n",
    "            weight = torch.randn(architecture[idx + 1], architecture[idx + 1], requires_grad = False).to(device)\n",
    "            torch.nn.init.xavier_uniform_(weight)\n",
    "            weight = weight @ weight.T\n",
    "            B.append({'weight': weight})\n",
    "        B = np.array(B)\n",
    "#         # Feedforward Synapses Initialization\n",
    "#         Wff = []\n",
    "#         for idx in range(len(architecture)-1):\n",
    "#             weight = torch.eye(architecture[idx + 1], architecture[idx], requires_grad = False).to(device)\n",
    "#             #torch.nn.init.xavier_uniform_(weight)\n",
    "#             bias = torch.zeros(architecture[idx + 1], 1, requires_grad = False).to(device)\n",
    "#             Wff.append({'weight': weight, 'bias': bias})\n",
    "\n",
    "#         # Feedback Synapses Initialization\n",
    "#         Wfb = []\n",
    "#         for idx in range(len(architecture)-1):\n",
    "#             weight = torch.eye(architecture[idx], architecture[idx + 1], requires_grad = False).to(device)\n",
    "#             #torch.nn.init.xavier_uniform_(weight)\n",
    "#             bias = torch.zeros(architecture[idx], 1, requires_grad = False).to(device)\n",
    "#             Wfb.append({'weight': weight, 'bias': bias})\n",
    "\n",
    "#         # Lateral Synapses Initialization\n",
    "#         B = []\n",
    "#         for idx in range(len(architecture)-1):\n",
    "#             weight = 10*torch.eye(architecture[idx + 1], architecture[idx + 1], requires_grad = False).to(device)\n",
    "#             #torch.nn.init.xavier_uniform_(weight)\n",
    "#             #weight = weight @ weight.T\n",
    "#             B.append({'weight': weight})\n",
    "            \n",
    "        self.Wff = Wff\n",
    "        self.Wfb = Wfb\n",
    "        self.B = B\n",
    "        \n",
    "    def init_neurons(self, mbs, random_initialize = True, device = 'cuda'):\n",
    "        # Initializing the neurons\n",
    "        if random_initialize:\n",
    "            neurons = []\n",
    "            append = neurons.append\n",
    "            for size in self.architecture[1:]:  \n",
    "                append(torch.randn((mbs, size), requires_grad=False, device=device).T)       \n",
    "        else:\n",
    "            neurons = []\n",
    "            append = neurons.append\n",
    "            for size in self.architecture[1:]:  \n",
    "                append(torch.zeros((mbs, size), requires_grad=False, device=device).T)\n",
    "        return neurons\n",
    "    \n",
    "    def calculate_neural_dynamics_grad(self, x, h, y_hat, y, beta):\n",
    "        Wff = self.Wff\n",
    "        Wfb = self.Wfb\n",
    "        B = self.B\n",
    "        lambda_h = self.lambda_h\n",
    "        lambda_y = self.lambda_y\n",
    "        one_over_epsilon = self.one_over_epsilon\n",
    "        \n",
    "        grad_h = 0.5*(one_over_epsilon * Wfb[0]['weight'].T @ (x - (Wfb[0]['weight'] @ h + Wfb[0]['bias'])) + \n",
    "             ((1 - lambda_h) / lambda_h) * B[0]['weight'] @ h -\n",
    "             one_over_epsilon * (h - (Wff[0]['weight'] @ x + Wff[0]['bias'])))\n",
    "\n",
    "        grad_y = 0.5*(one_over_epsilon * Wfb[1]['weight'].T @ (h - (Wfb[1]['weight'] @ y_hat + Wfb[1]['bias'])) +\n",
    "             ((1 - lambda_y) / lambda_y) * B[1]['weight'] @ y_hat - \n",
    "             one_over_epsilon * (y_hat - (Wff[1]['weight'] @ h + Wff[1]['bias']))) + 2 * beta * (y - y_hat)\n",
    "\n",
    "        return grad_h, grad_y\n",
    "\n",
    "    def run_neural_dynamics(self, x, h, y_hat, y, neural_lr, neural_dynamic_iterations, beta):\n",
    "        for iter_count in range(neural_dynamic_iterations):\n",
    "            with torch.no_grad():       \n",
    "                grad_h, grad_y = self.calculate_neural_dynamics_grad(x, h, y_hat, y, beta)\n",
    "                h = self.activation(h + neural_lr * grad_h)\n",
    "                y_hat = self.activation(y_hat + neural_lr * grad_y)\n",
    "        return h, y_hat\n",
    "    \n",
    "    def batch_step(self, x, lr, neural_lr, neural_dynamic_iterations_free, \n",
    "                   neural_dynamic_iterations_nudged, beta):\n",
    "        \n",
    "        Wff, Wfb, B = self.Wff, self.Wfb, self.B\n",
    "        \n",
    "        h, y_hat = model.init_neurons(x.size(1), device = model.device)\n",
    "\n",
    "        h, y_hat = self.run_neural_dynamics(x, h, y_hat, y_one_hot, neural_lr, \n",
    "                                            neural_dynamic_iterations_free, 0)\n",
    "        neurons1 = [h, y_hat].copy()\n",
    "\n",
    "        error_hx_free = h - (self.Wff[0]['weight'] @ x + self.Wff[0]['bias'])\n",
    "        error_xh_free = x - (self.Wfb[0]['weight'] @ h + self.Wfb[0]['bias'])\n",
    "\n",
    "        error_yh_free = y_hat - (self.Wff[1]['weight'] @ h + self.Wff[1]['bias'])\n",
    "        error_hy_free = h - (self.Wfb[1]['weight'] @ y_hat + self.Wfb[1]['bias'])\n",
    "\n",
    "        h, y_hat = self.run_neural_dynamics(x, h, y_hat, y_one_hot, neural_lr, \n",
    "                                            neural_dynamic_iterations_nudged, beta)\n",
    "        neurons2 = [h, y_hat].copy()\n",
    "\n",
    "        error_hx_nudged = h - (self.Wff[0]['weight'] @ x + self.Wff[0]['bias'])\n",
    "        error_xh_nudged = x - (self.Wfb[0]['weight'] @ h + self.Wfb[0]['bias'])\n",
    "\n",
    "        error_yh_nudged = y_hat - (self.Wff[1]['weight'] @ h + self.Wff[1]['bias'])\n",
    "        error_hy_nudged = h - (self.Wfb[1]['weight'] @ y_hat + self.Wfb[1]['bias'])\n",
    "        \n",
    "        Wff_old = torch.clone(Wff[0]['weight'])\n",
    "        ### Weight Updates\n",
    "        #k = 5  # Below lines output ---> tensor(0., device='cuda:0')\n",
    "        #torch.norm(outer_prod_broadcasting(error_hx_free.T, x.T)[k] - (torch.outer(error_hx_free[:,k], x[:,k])))\n",
    "        Wff[0]['weight'] -= lr['ff'] * torch.mean(outer_prod_broadcasting((error_hx_free - error_hx_nudged).T, x.T), axis = 0)\n",
    "        Wfb[0]['weight'] -= lr['ff'] * torch.mean(outer_prod_broadcasting(error_xh_free.T, neurons1[0].T) - outer_prod_broadcasting(error_xh_nudged.T, neurons2[0].T), axis = 0)\n",
    "        Wff[1]['weight'] -= lr['ff'] * torch.mean(outer_prod_broadcasting(error_yh_free.T, neurons1[0].T) - outer_prod_broadcasting(error_yh_nudged.T, neurons2[0].T), axis = 0)\n",
    "        Wfb[1]['weight'] -= lr['ff'] * torch.mean(outer_prod_broadcasting(error_hy_free.T, neurons1[1].T) - outer_prod_broadcasting(error_hy_nudged.T, neurons2[1].T), axis = 0)\n",
    "        \n",
    "        Wff[0]['bias'] -= lr['fb'] * torch.mean(error_hx_nudged - error_hx_free, axis = 1, keepdims = True)\n",
    "        Wfb[0]['bias'] -= lr['fb'] * torch.mean(error_xh_nudged - error_xh_free, axis = 1, keepdims = True)\n",
    "        Wff[1]['bias'] -= lr['fb'] * torch.mean(error_yh_nudged - error_yh_free, axis = 1, keepdims = True)\n",
    "        Wfb[1]['bias'] -= lr['fb'] * torch.mean(error_hy_nudged - error_hy_free, axis = 1, keepdims = True)\n",
    "\n",
    "        B[0]['weight'] -= lr['lat'] * (torch.mean(outer_prod_broadcasting(neurons2[0].T, neurons2[0].T), axis = 0) - torch.mean(outer_prod_broadcasting(neurons1[0].T, neurons1[0].T), axis = 0))\n",
    "        B[1]['weight'] -= lr['lat'] * (torch.mean(outer_prod_broadcasting(neurons2[1].T, neurons2[1].T), axis = 0) - torch.mean(outer_prod_broadcasting(neurons1[1].T, neurons1[1].T), axis = 0))\n",
    "        \n",
    "        self.Wff = Wff\n",
    "        self.Wfb = Wfb\n",
    "        self.B = B\n",
    "        \n",
    "#         print(torch.norm(Wff_old - Wff[0]['weight']))\n",
    "#         print(torch.norm(torch.mean(outer_prod_broadcasting((error_hx_free - error_hx_nudged).T, x.T), axis = 0)))\n",
    "        return h, y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3a24ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateCorInfoMax(model, loader, neural_lr, T, device, printing = True):\n",
    "    # Evaluate the model on a dataloader with T steps for the dynamics\n",
    "    #model.eval()\n",
    "    correct=0\n",
    "    phase = 'Train' if loader.dataset.train else 'Test'\n",
    "    \n",
    "    for x, y in loader:\n",
    "        x = x.view(x.size(0),-1).to(device).T\n",
    "        y = y.to(device)\n",
    "        \n",
    "        h, y_hat = model.init_neurons(x.size(1), device = model.device)\n",
    "        \n",
    "        # dynamics for T time steps\n",
    "        h, y_hat = model.run_neural_dynamics(x, h, y_hat, 0, neural_lr = neural_lr, \n",
    "                                             neural_dynamic_iterations = T, beta = 0) \n",
    "        \n",
    "        pred = torch.argmax(y_hat, dim=0).squeeze()  # in this case prediction is done directly on the last (output) layer of neurons\n",
    "        correct += (y == pred).sum().item()\n",
    "\n",
    "    acc = correct/len(loader.dataset) \n",
    "    if printing:\n",
    "        print(phase+' accuracy :\\t', acc)   \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70eec2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "architecture = [784, 500, 10]\n",
    "\n",
    "x,y = next(iter(train_loader))\n",
    "x = x.view(x.size(0),-1).to(device).T\n",
    "y_one_hot = F.one_hot(y, 10).to(device).T\n",
    "\n",
    "lambda_h = 0.5\n",
    "lambda_y = 0.5\n",
    "epsilon = 1\n",
    "one_over_epsilon = 1 / epsilon\n",
    "lr = {'ff' : 1e-1, 'fb': 1e-1, 'lat': 1e-3}\n",
    "neural_lr = 0.02\n",
    "model = TwoLayerCorInfoMax(architecture = architecture, lambda_h = lambda_h, lambda_y = lambda_y, \n",
    "                           epsilon = epsilon, activation = activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62296e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluateCorInfoMax(model, test_loader, neural_lr, 20, device = 'cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22111e4c",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c232ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_acc_list = []\n",
    "tst_acc_list = []\n",
    "neural_dynamic_iterations_free = 20\n",
    "neural_dynamic_iterations_nudged = 4\n",
    "lambda_h = 0.5\n",
    "lambda_y = 0.5\n",
    "epsilon = 1\n",
    "one_over_epsilon = 1 / epsilon\n",
    "beta = 1\n",
    "n_epochs = 50\n",
    "# lr = 1e-3\n",
    "lr = {'ff' : 1e-3, 'fb': 1e-3, 'lat': 1e-3}\n",
    "neural_lr = 0.1\n",
    "# Wff_old = torch.clone(model.Wff[0]['weight'])\n",
    "# print(model.Wff[0]['weight'])\n",
    "for epoch_ in range(n_epochs):\n",
    "    for idx, (x, y) in tqdm(enumerate(train_loader)):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        x = x.view(x.size(0),-1).T\n",
    "        y_one_hot = F.one_hot(y, 10).to(device).T\n",
    "\n",
    "        h, y_hat = model.batch_step(  x, lr, neural_lr, neural_dynamic_iterations_free, \n",
    "                                      neural_dynamic_iterations_nudged, beta)\n",
    "\n",
    "#         break\n",
    "#     break\n",
    "    trn_acc = evaluateCorInfoMax(model, train_loader, neural_lr, 20, device = 'cuda', printing = False)\n",
    "    tst_acc = evaluateCorInfoMax(model, test_loader, neural_lr, 20, device = 'cuda', printing = False)\n",
    "    trn_acc_list.append(trn_acc)\n",
    "    tst_acc_list.append(tst_acc)\n",
    "    \n",
    "    print(\"Epoch : {}, Train Accuracy : {}, Test Accuracy : {}\".format(epoch_+1, trn_acc, tst_acc))\n",
    "\n",
    "# print(model.Wff[0]['weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261bc88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch2numpy(x):\n",
    "    return x.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0166baa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(torch2numpy(Wff_old - model.Wff[0]['weight']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5561db",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.Wff[0]['weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f799c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "h, y_hat = model.init_neurons(x.size(1), device = model.device)\n",
    "\n",
    "# dynamics for T time steps\n",
    "h, y_hat = model.run_neural_dynamics(x, h, y_hat, 0, neural_lr = neural_lr, \n",
    "                                     neural_dynamic_iterations = 20, beta = 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b19def4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.Wff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4bc41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "architecture = [784, 500, 10]\n",
    "\n",
    "x,y = next(iter(train_loader))\n",
    "x = x.view(x.size(0),-1).to(device).T\n",
    "y_one_hot = F.one_hot(y, 10).to(device).T\n",
    "\n",
    "lambda_h = 1e-2\n",
    "lambda_y = 1e-2\n",
    "epsilon = 1e-2\n",
    "one_over_epsilon = 1 / epsilon\n",
    "lr = 1e-3\n",
    "\n",
    "model = TwoLayerCorInfoMax(architecture = architecture, lambda_h = lambda_h, lambda_y = lambda_y, \n",
    "                           epsilon = epsilon, activation = activation)\n",
    "\n",
    "Wff = model.Wff\n",
    "Wfb = model.Wfb\n",
    "B = model.B\n",
    "\n",
    "h, y_hat = model.init_neurons(x.size(1), device = model.device)\n",
    "\n",
    "h, y_hat = model.run_neural_dynamics(x, h, y_hat, y_one_hot, 1e-3, 20, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08199a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.argmax(y_hat, dim=0).squeeze() - y.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c2c03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "architecture = [784, 500, 10]\n",
    "\n",
    "x,y = next(iter(train_loader))\n",
    "x = x.view(x.size(0),-1).to(device).T\n",
    "y_one_hot = F.one_hot(y, 10).to(device).T\n",
    "\n",
    "lambda_h = 1e-2\n",
    "lambda_y = 1e-2\n",
    "epsilon = 1e-2\n",
    "one_over_epsilon = 1 / epsilon\n",
    "lr = 1e-3\n",
    "\n",
    "model = TwoLayerCorInfoMax(architecture = architecture, lambda_h = lambda_h, lambda_y = lambda_y, \n",
    "                           epsilon = epsilon, activation = activation)\n",
    "\n",
    "Wff = model.Wff\n",
    "Wfb = model.Wfb\n",
    "B = model.B\n",
    "\n",
    "h, y_hat = model.init_neurons(x.size(1), device = model.device)\n",
    "\n",
    "h, y_hat = model.run_neural_dynamics(x, h, y_hat, y_one_hot, 1e-3, 20, 0)\n",
    "neurons1 = [h, y_hat].copy()\n",
    "\n",
    "error_hx_free = h - (Wff[0]['weight'] @ x + Wff[0]['bias'])\n",
    "error_xh_free = x - (Wfb[0]['weight'] @ h + Wfb[0]['bias'])\n",
    "\n",
    "error_yh_free = y_hat - (Wff[1]['weight'] @ h + Wff[1]['bias'])\n",
    "error_hy_free = h - (Wfb[1]['weight'] @ y_hat + Wfb[1]['bias'])\n",
    "\n",
    "h, y_hat = model.run_neural_dynamics(x, h, y_hat, y_one_hot, 1e-3, 4, 1)\n",
    "neurons2 = [h, y_hat].copy()\n",
    "\n",
    "error_hx_nudged = h - (Wff[0]['weight'] @ x + Wff[0]['bias'])\n",
    "error_xh_nudged = x - (Wfb[0]['weight'] @ h + Wfb[0]['bias'])\n",
    "\n",
    "error_yh_nudged = y_hat - (Wff[1]['weight'] @ h + Wff[1]['bias'])\n",
    "error_hy_nudged = h - (Wfb[1]['weight'] @ y_hat + Wfb[1]['bias'])\n",
    "\n",
    "\n",
    "Wff[0]['weight'] = Wff[0]['weight'] - lr * torch.mean(outer_prod_broadcasting((error_hx_free - error_hx_nudged).T, x.T), axis = 0)\n",
    "Wfb[0]['weight'] = Wfb[0]['weight'] - lr * torch.mean(outer_prod_broadcasting(error_xh_free.T, neurons1[0].T) - outer_prod_broadcasting(error_xh_nudged.T, neurons2[0].T), axis = 0)\n",
    "Wff[1]['weight'] = Wff[1]['weight'] - lr * torch.mean(outer_prod_broadcasting(error_yh_free.T, neurons1[0].T) - outer_prod_broadcasting(error_yh_nudged.T, neurons2[0].T), axis = 0)\n",
    "Wfb[1]['weight'] = Wfb[1]['weight'] - lr * torch.mean(outer_prod_broadcasting(error_hy_free.T, neurons1[1].T) - outer_prod_broadcasting(error_hy_nudged.T, neurons2[1].T), axis = 0)\n",
    "\n",
    "Wff[0]['bias'] = Wff[0]['bias'] - lr * torch.mean(error_hx_nudged - error_hx_free, axis = 1, keepdims = True)\n",
    "Wfb[0]['bias'] = Wfb[0]['bias'] - lr * torch.mean(error_xh_nudged - error_xh_free, axis = 1, keepdims = True)\n",
    "Wff[1]['bias'] = Wff[1]['bias'] - lr * torch.mean(error_yh_nudged - error_yh_free, axis = 1, keepdims = True)\n",
    "Wfb[1]['bias'] = Wfb[1]['bias'] - lr * torch.mean(error_hy_nudged - error_hy_free, axis = 1, keepdims = True)\n",
    "\n",
    "B[0]['weight'] = B[0]['weight'] - lr * (torch.mean(outer_prod_broadcasting(neurons2[0].T, neurons2[0].T), axis = 0) - torch.mean(outer_prod_broadcasting(neurons1[0].T, neurons1[0].T), axis = 0))\n",
    "B[1]['weight'] = B[1]['weight'] - lr * (torch.mean(outer_prod_broadcasting(neurons2[1].T, neurons2[1].T), axis = 0) - torch.mean(outer_prod_broadcasting(neurons1[1].T, neurons1[1].T), axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49a9d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "Wff[0]['bias'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f950f8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mean(error_hx_nudged - error_hx_free, axis = 1, keepdims = True).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183b7412",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_hx_free.shape, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ef03b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mean(outer_prod_broadcasting(error_hx_free.T, x.T), axis = 0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb453fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "torch.norm(outer_prod_broadcasting(error_hx_free.T, x.T)[k] - (torch.outer(error_hx_free[:,k], x[:,k])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e087d460",
   "metadata": {},
   "outputs": [],
   "source": [
    "(torch.outer(error_hx_free[0], x[0])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1829580",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.argmax(y_hat, dim=0).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b72090",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mean(outer_prod_broadcasting(h.T, h.T), axis = 0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37bb581",
   "metadata": {},
   "outputs": [],
   "source": [
    "architecture = [784, 500, 10]\n",
    "\n",
    "# # Feedforward Synapses Initialization\n",
    "# Wff = torch.nn.ModuleList()\n",
    "# for idx in range(len(architecture)-1):\n",
    "#     m = torch.nn.Linear(architecture[idx], architecture[idx+1], bias=True)\n",
    "#     torch.nn.init.xavier_uniform_(m.weight)\n",
    "#     # m.weight.data.mul_(torch.tensor([1]))\n",
    "#     if m.bias is not None:\n",
    "#         m.bias.data.mul_(0)\n",
    "#     Wff.append(m)\n",
    "\n",
    "# # Feedback Synapses Initialization\n",
    "# Wfb = torch.nn.ModuleList()\n",
    "# for idx in range(len(architecture)-1):\n",
    "#     m = torch.nn.Linear(architecture[idx+1], architecture[idx], bias=True)\n",
    "#     torch.nn.init.xavier_uniform_(m.weight)\n",
    "#     # m.weight.data.mul_(torch.tensor([1]))\n",
    "#     if m.bias is not None:\n",
    "#         m.bias.data.mul_(0)\n",
    "#     Wfb.append(m)\n",
    "    \n",
    "# # Lateral Synapses Initialization\n",
    "# B = torch.nn.ModuleList()\n",
    "# for idx in range(1,len(architecture)-1):\n",
    "#     m = torch.nn.Linear(architecture[idx], architecture[idx], bias = False)\n",
    "#     torch.nn.init.xavier_uniform_(m.weight)\n",
    "#     m.weight.data = m.weight.data @ m.weight.data.T\n",
    "#     B.append(m)\n",
    "    \n",
    "# Feedforward Synapses Initialization\n",
    "Wff = []\n",
    "for idx in range(len(architecture)-1):\n",
    "    weight = torch.randn(architecture[idx + 1], architecture[idx], requires_grad = False).to(device)\n",
    "    torch.nn.init.xavier_uniform_(weight)\n",
    "    bias = torch.zeros(architecture[idx + 1], 1, requires_grad = False).to(device)\n",
    "    Wff.append({'weight': weight, 'bias': bias})\n",
    "    \n",
    "# Feedback Synapses Initialization\n",
    "Wfb = []\n",
    "for idx in range(len(architecture)-1):\n",
    "    weight = torch.randn(architecture[idx], architecture[idx + 1], requires_grad = False).to(device)\n",
    "    torch.nn.init.xavier_uniform_(weight)\n",
    "    bias = torch.zeros(architecture[idx], 1, requires_grad = False).to(device)\n",
    "    Wfb.append({'weight': weight, 'bias': bias})\n",
    "    \n",
    "# Lateral Synapses Initialization\n",
    "B = []\n",
    "for idx in range(len(architecture)-1):\n",
    "    weight = torch.randn(architecture[idx + 1], architecture[idx + 1], requires_grad = False).to(device)\n",
    "    torch.nn.init.xavier_uniform_(weight)\n",
    "    weight = weight @ weight.T\n",
    "    B.append({'weight': weight})\n",
    "    \n",
    "    \n",
    "# Wff = Wff.to(device)\n",
    "# Wfb = Wfb.to(device)\n",
    "# B = B.to(device)\n",
    "\n",
    "a1 = 1\n",
    "a2 = 1\n",
    "b1 = 1\n",
    "b2 = 1\n",
    "beta = 0\n",
    "\n",
    "lambda_h = 1e-2\n",
    "lambda_y = 1e-2\n",
    "epsilon = 1e-1\n",
    "one_over_epsilon = 1 / epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2565e7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_neurons(mbs, architecture, random_initialize = False, device = 'cuda'):\n",
    "    # Initializing the neurons\n",
    "    if random_initialize:\n",
    "        neurons = []\n",
    "        append = neurons.append\n",
    "        for size in architecture[1:]:  \n",
    "            append(torch.randn((mbs, size), requires_grad=False, device=device).T)       \n",
    "    else:\n",
    "        neurons = []\n",
    "        append = neurons.append\n",
    "        for size in architecture[1:]:  \n",
    "            append(torch.zeros((mbs, size), requires_grad=False, device=device).T)\n",
    "    return neurons\n",
    "\n",
    "def calculate_neural_dynamics_grad(x, h, y_hat, Wff, Wfb, B, one_over_epsilon, lambda_h, lambda_y, beta):\n",
    "\n",
    "    grad_h = 0.5*(one_over_epsilon * Wfb[0]['weight'].T @ (x - (Wfb[0]['weight'] @ h + Wfb[0]['bias'])) + \n",
    "         ((1 - lambda_h) / lambda_h) * B[0]['weight'] @ h -\n",
    "         one_over_epsilon * (h - (Wff[0]['weight'] @ x - Wff[0]['bias'])))\n",
    "\n",
    "    grad_y = 0.5*(one_over_epsilon * Wfb[1]['weight'].T @ (h - (Wfb[1]['weight'] @ y_hat + Wfb[1]['bias'])) +\n",
    "         ((1 - lambda_y) / lambda_y) * B[1]['weight'] @ y_hat - \n",
    "         one_over_epsilon * (y_hat - (Wff[1]['weight'] @ h + Wff[1]['bias']))) + 2 * beta * (y - y_hat)\n",
    "    \n",
    "    return grad_h, grad_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb4a93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(train_loader))\n",
    "x = x.view(x.size(0),-1).to(device).T\n",
    "y_one_hot = F.one_hot(y, 10).to(device).T\n",
    "\n",
    "h,y_hat = init_neurons(x.size(1), architecture, random_initialize = True, device = 'cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e91d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape, h.shape, y_hat.shape, y_one_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763fa42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_h, grad_y = calculate_neural_dynamics_grad(x, h, y_hat, Wff, Wfb, B, one_over_epsilon, lambda_h, lambda_y, beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0720bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_dynamic_iterations = 20\n",
    "neural_lr = 1e-3\n",
    "for iter_count in range(neural_dynamic_iterations):\n",
    "    with torch.no_grad():\n",
    "        grad_h, grad_y = calculate_neural_dynamics_grad(x, h, y_hat, Wff, Wfb, B, one_over_epsilon, lambda_h, lambda_y, beta)\n",
    "        h = activation(h - neural_lr * grad_h)\n",
    "        y_hat = activation(y_hat - neural_lr * grad_y)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794fa18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Wfb[1]['weight'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7ea615",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_h = 0.5*(one_over_epsilon * Wfb[0]['weight'].T @ (x - (Wfb[0]['weight'] @ h + Wfb[0]['bias'])) + \n",
    "         ((1 - lambda_h) / lambda_h) * B[0]['weight'] @ h -\n",
    "         one_over_epsilon * (h - (Wff[0]['weight'] @ x - Wff[0]['bias'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e8d125",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_y = 0.5*(one_over_epsilon * Wfb[1]['weight'].T @ (h - (Wfb[1]['weight'] @ y_hat + Wfb[1]['bias'])) +\n",
    "         ((1 - lambda_y) / lambda_y) * B[1]['weight'] @ y_hat - \n",
    "         one_over_epsilon * (y_hat - (Wff[1]['weight'] @ h + Wff[1]['bias']))) + 2 * beta * (y - y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06563a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_h.shape, grad_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883d1a0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Wfb[0].weight.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c35484e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(Wfb[0].weight.data @ h.T).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801f6927",
   "metadata": {},
   "outputs": [],
   "source": [
    "Wfb[0].bias.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adc9c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.norm(Wfb[0](h) - (Wfb[0].weight.data @ h.T + Wfb[0].bias.data.view(-1,1)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97dbca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc1b6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Wff[0](x) - (Wff[0].weight.data @ x.T).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc28c74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape, my_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c214f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "W[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141b534c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.norm(x @ W[0].weight.data.T - W[0](x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172b2f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_dict = [{'weight': np.ones(3), 'bias': np.array([0])}, {'weight': np.zeros(3), 'bias': np.array([1])}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796cc5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_dict[0]['weight'] = list_of_dict[0]['weight'] - 1e-3 * np.ones(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcfccba",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b090b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class foo:\n",
    "    def __init__(self, l):\n",
    "        self.l = l\n",
    "        \n",
    "    def step(self):\n",
    "        list_of_dict[0]['weight'] = list_of_dict[0]['weight'] - 1e-3 * np.ones(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9300042b",
   "metadata": {},
   "outputs": [],
   "source": [
    "myfoo = foo(list_of_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7914b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "myfoo.l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd90512",
   "metadata": {},
   "outputs": [],
   "source": [
    "myfoo.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28861a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "myfoo.l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d506d37b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
