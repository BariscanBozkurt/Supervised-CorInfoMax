{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fd7911f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import glob\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "from itertools import repeat\n",
    "from torch.nn.parameter import Parameter\n",
    "import collections\n",
    "import matplotlib\n",
    "from torch_utils import *\n",
    "from models import *\n",
    "from visualization import *\n",
    "# matplotlib.use('Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0481fdbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94c4836a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(), \n",
    "                                            torchvision.transforms.Normalize(mean=(0.0,), std=(1.0,))])\n",
    "\n",
    "mnist_dset_train = torchvision.datasets.MNIST('./data', train=True, transform=transform, target_transform=None, download=True)\n",
    "train_loader = torch.utils.data.DataLoader(mnist_dset_train, batch_size=20, shuffle=True, num_workers=0)\n",
    "\n",
    "mnist_dset_test = torchvision.datasets.MNIST('./data', train=False, transform=transform, target_transform=None, download=True)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_dset_test, batch_size=20, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd835cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_type = \"tanh\"\n",
    "architecture = [784, 500, 500, 10]\n",
    "\n",
    "x,y = next(iter(train_loader))\n",
    "x = x.view(x.size(0),-1).to(device).T\n",
    "y_one_hot = F.one_hot(y, 10).to(device).T\n",
    "lambda_ = 0.9999\n",
    "epsilon = 0.1#0.5\n",
    "neural_lr_start = 0.1/15\n",
    "neural_lr_stop = 0.0001\n",
    "neural_lr_rule = \"constant\"\n",
    "neural_lr_decay_multiplier = 0.01\n",
    "neural_dynamic_iterations = 50\n",
    "\n",
    "lr_start = {'ff' : 0.01, \"fb\": 0.001}\n",
    "# lr_start = {'ff' : 0.001, \"fb\": 0.001}\n",
    "\n",
    "model = CorInfoMaxV3(architecture, lambda_, epsilon, activation_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f252142",
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons = model.fast_forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1fac702",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [x] + neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d249082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 20])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3a90fa53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., device='cuda:0')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(F.softmax(x, 0)[:,0] - F.softmax(x[:,0], 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "02274ef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([784, 784])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmaX = F.softmax(x[:,0], 0)\n",
    "J1 = (torch.diag(sigmaX) - torch.outer(sigmaX, sigmaX))\n",
    "J1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f9ba8e2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 784, 784])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmaX = F.softmax(x, 0)\n",
    "J2 = torch.diag_embed(sigmaX.T) - torch.einsum('ij, ik -> ijk', sigmaX.T, sigmaX.T)\n",
    "J2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "12b9a727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., device='cuda:0')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(J1 - J2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3706abaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 784, 1])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmaX.T.unsqueeze(2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "397ca1c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([784, 784])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1b716c6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07,  2.2196e-06,  3.9501e-06, -3.1774e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -2.5850e-07,\n",
       "        -1.7610e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,  1.7381e-08,\n",
       "         4.5996e-06,  1.5825e-06, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07,  2.8275e-07,  3.6311e-06,  1.8696e-06, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07,  1.7353e-06,  4.8155e-06,  1.0158e-06,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,  1.3696e-06,\n",
       "         4.8155e-06,  1.8517e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "         1.5336e-06,  4.8155e-06,  4.2990e-08, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07,  1.1956e-06,  4.8155e-06,  1.7616e-06,\n",
       "        -3.5286e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07,  4.1588e-07,  4.8155e-06,\n",
       "         4.2990e-08, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -2.8716e-07,  3.5437e-06,  4.8155e-06, -2.3281e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07,  1.7353e-06,  3.5005e-06, -3.3781e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,  3.0133e-06,\n",
       "         4.8155e-06, -2.3281e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,  1.7353e-06,\n",
       "         3.3736e-06, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -2.7786e-07,  3.5437e-06,  4.8155e-06, -2.3281e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07,  1.7353e-06,  3.3736e-06, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.1212e-08,\n",
       "         4.8155e-06,  4.8155e-06, -2.3281e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "         9.2278e-07,  3.3736e-06, -3.6357e-07, -3.6357e-07, -1.9966e-07,\n",
       "         5.6576e-07,  2.3136e-06,  2.7894e-06,  4.8155e-06,  4.8155e-06,\n",
       "         4.1588e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07,  9.6958e-08,  4.8155e-06,\n",
       "         1.7882e-06,  4.3406e-06,  4.7066e-06,  4.8155e-06,  4.8155e-06,\n",
       "         4.8155e-06,  4.8155e-06,  4.8155e-06,  4.8155e-06,  8.1722e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -1.4492e-07,  4.1418e-06,  4.8155e-06,  4.5996e-06,\n",
       "         1.6578e-06,  1.1339e-06,  1.0937e-06,  6.9507e-08,  3.9973e-06,\n",
       "         4.8155e-06,  1.3923e-06,  3.9048e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.1774e-07,  2.9420e-07, -3.4165e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07,  3.0133e-06,  4.8155e-06, -2.3281e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "         7.8345e-07,  4.8155e-06, -2.3281e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07,  5.6576e-07,  4.8155e-06,\n",
       "        -6.1738e-08, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -2.4843e-07,  4.8155e-06,  9.4101e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.0063e-07,\n",
       "         4.8155e-06,  3.5872e-06, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.3391e-07,  2.8258e-06,  4.7608e-06,\n",
       "         3.4354e-08, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07,  3.0578e-07,  4.8155e-06,  8.7702e-08, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,  5.1727e-08,\n",
       "         4.8707e-06,  8.7703e-08, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.0500e-07,  3.7201e-06,  8.7702e-08,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07,\n",
       "        -3.6357e-07, -3.6357e-07, -3.6357e-07, -3.6357e-07], device='cuda:0')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J1 @ F.softmax(x[:,0], 0).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "025231eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0002, device='cuda:0')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(torch.bmm(J2, sigmaX.T.unsqueeze(2))[0], J1 @ F.softmax(x[:,0], 0).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "920f71c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 784, 1])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.bmm(J2, sigmaX.T.unsqueeze(2)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2da2efc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 784, 784])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.diag_embed(x.T) - torch.einsum('ij, ik -> ijk', x.T, x.T)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41771576",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [03:17, 15.18it/s]\n",
      "1it [00:00,  9.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1, Train Accuracy : 0.8418, Test Accuracy : 0.8501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "153it [00:09, 15.99it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_103173/217638194.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0my_one_hot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0my_one_hot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.94\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0my_one_hot\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.03\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0my_one_hot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         _ = model.batch_step( x, y_one_hot, lr, neural_lr_start, neural_lr_stop, neural_lr_rule,\n\u001b[0m\u001b[1;32m     15\u001b[0m                               \u001b[0mneural_lr_decay_multiplier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneural_dynamic_iterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"sgd\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                             )\n",
      "\u001b[0;32m/scratch/users/bbozkurt15/CorInfoMaxSupervised/Supervised-CorInfoMax/src/models.py\u001b[0m in \u001b[0;36mbatch_step\u001b[0;34m(self, x, y, lr, neural_lr_start, neural_lr_stop, neural_lr_rule, neural_lr_decay_multiplier, neural_dynamic_iterations, beta, mode, optimizer, adam_opt_params)\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0mneurons\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1060\u001b[0;31m         neurons = self.run_neural_dynamics(x, y, neurons, neural_lr_start, neural_lr_stop, neural_lr_rule, \n\u001b[0m\u001b[1;32m   1061\u001b[0m                                            neural_lr_decay_multiplier, neural_dynamic_iterations, beta)\n\u001b[1;32m   1062\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/users/bbozkurt15/CorInfoMaxSupervised/Supervised-CorInfoMax/src/models.py\u001b[0m in \u001b[0;36mrun_neural_dynamics\u001b[0;34m(self, x, y, neurons, neural_lr_start, neural_lr_stop, lr_rule, lr_decay_multiplier, neural_dynamic_iterations, beta, mode)\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1025\u001b[0;31m                 \u001b[0mneuron_grads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_neural_dynamics_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneurons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1026\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mneuron_iter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneurons\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m                     \u001b[0mneurons\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mneuron_iter\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneurons\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mneuron_iter\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mneural_lr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mneuron_grads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mneuron_iter\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/users/bbozkurt15/CorInfoMaxSupervised/Supervised-CorInfoMax/src/models.py\u001b[0m in \u001b[0;36mcalculate_neural_dynamics_grad\u001b[0;34m(self, x, y, neurons, beta, mode)\u001b[0m\n\u001b[1;32m    991\u001b[0m         \u001b[0minit_grads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mneurons_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mneurons_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mneurons\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m         \u001b[0;31m# layers_after_activation = [list(self.activation_func(layers[jj], self.activation_type)) for jj in range(len(layers))]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 993\u001b[0;31m         \u001b[0mlayers_after_activation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mjj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mjj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mneurons\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    994\u001b[0m         \u001b[0;31m## Compute forward errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m         \u001b[0mforward_errors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mjj\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mWff\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mjj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mlayers_after_activation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mjj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mWff\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mjj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bias'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mjj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/users/bbozkurt15/CorInfoMaxSupervised/Supervised-CorInfoMax/src/models.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    991\u001b[0m         \u001b[0minit_grads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mneurons_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mneurons_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mneurons\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m         \u001b[0;31m# layers_after_activation = [list(self.activation_func(layers[jj], self.activation_type)) for jj in range(len(layers))]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 993\u001b[0;31m         \u001b[0mlayers_after_activation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mjj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mjj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mneurons\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    994\u001b[0m         \u001b[0;31m## Compute forward errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m         \u001b[0mforward_errors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mjj\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mWff\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mjj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mlayers_after_activation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mjj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mWff\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mjj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bias'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mjj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/users/bbozkurt15/CorInfoMaxSupervised/Supervised-CorInfoMax/src/models.py\u001b[0m in \u001b[0;36mactivation_func\u001b[0;34m(self, x, type_)\u001b[0m\n\u001b[1;32m    938\u001b[0m             \u001b[0mfp_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtype_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"tanh\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 940\u001b[0;31m             \u001b[0mf_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    941\u001b[0m             \u001b[0mfp_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mf_x\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtype_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"sigmoid\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trn_acc_list = []\n",
    "tst_acc_list = []\n",
    "\n",
    "n_epochs = 10\n",
    "lr = lr_start\n",
    "for epoch_ in range(n_epochs):\n",
    "    lr = {'ff' : lr_start['ff'] * (0.9)**epoch_, 'fb' : lr_start['fb'] * (0.9)**epoch_}\n",
    "    for idx, (x, y) in tqdm(enumerate(train_loader)):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        #x = activation_inverse(x.view(x.size(0),-1).T, activation_type)\n",
    "        x = x.view(x.size(0),-1).T\n",
    "        y_one_hot = F.one_hot(y, 10).to(device).T\n",
    "        y_one_hot = 0.94 * y_one_hot + 0.03 * torch.ones(*y_one_hot.shape, device = device)\n",
    "        _ = model.batch_step( x, y_one_hot, lr, neural_lr_start, neural_lr_stop, neural_lr_rule,\n",
    "                              neural_lr_decay_multiplier, neural_dynamic_iterations, optimizer = \"sgd\"\n",
    "                            )\n",
    "\n",
    "    trn_acc = evaluatePC(model, train_loader, device, apply_activation_inverse = False, activation_type = activation_type, printing = False)\n",
    "    tst_acc = evaluatePC(model, test_loader, device, apply_activation_inverse = False, activation_type = activation_type, printing = False)\n",
    "    trn_acc_list.append(trn_acc)\n",
    "    tst_acc_list.append(tst_acc)\n",
    "    \n",
    "    print(\"Epoch : {}, Train Accuracy : {}, Test Accuracy : {}\".format(epoch_+1, trn_acc, tst_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202708bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_convergence_plot(trn_acc_list, xlabel = 'Number of Epochs', ylabel = 'Accuracy %',\n",
    "                      title = 'PC Train Accuracy w.r.t. Epochs', \n",
    "                      figsize = (12,8), fontsize = 25, linewidth = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63978453",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_convergence_plot(tst_acc_list, xlabel = 'Number of Epochs', ylabel = 'Accuracy %',\n",
    "                      title = 'PC Test Accuracy w.r.t. Epochs', \n",
    "                      figsize = (12,8), fontsize = 25, linewidth = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8b2979",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (7,7))\n",
    "plt.imshow(torch2numpy(model.B[0][\"weight\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a00169",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (7,7))\n",
    "plt.imshow(torch2numpy(model.Bsigma[1][\"weight\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a21245",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.Bsigma[1][\"weight\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
