{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fd7911f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import glob\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "from itertools import repeat\n",
    "from torch.nn.parameter import Parameter\n",
    "import collections\n",
    "import matplotlib\n",
    "from torch_utils import *\n",
    "from ExplicitModels import *\n",
    "from visualization import *\n",
    "# matplotlib.use('Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0481fdbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94c4836a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(),])\n",
    "\n",
    "mnist_dset_train = torchvision.datasets.MNIST('./data', train=True, transform=transform, target_transform=None, download=True)\n",
    "train_loader = torch.utils.data.DataLoader(mnist_dset_train, batch_size=20, shuffle=True, num_workers=0)\n",
    "\n",
    "mnist_dset_test = torchvision.datasets.MNIST('./data', train=False, transform=transform, target_transform=None, download=True)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_dset_test, batch_size=20, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd835cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# activation = F.relu\n",
    "# architecture = [784, 128, 64, 10]\n",
    "# lambda_ = 0.99999\n",
    "# epsilon = 0.2\n",
    "# supervised_lambda_weight = 1e-3\n",
    "# neural_lr_start = 0.001 \n",
    "# neural_lr_stop = 0.0005 \n",
    "# neural_lr_rule = \"constant\"\n",
    "# neural_lr_decay_multiplier = 0.005\n",
    "# neural_dynamic_iterations = 50\n",
    "activation = F.relu\n",
    "architecture = [784, 128, 64, 10]\n",
    "lambda_ = 1\n",
    "epsilon = 0.01\n",
    "supervised_lambda_weight = 1e-3\n",
    "neural_lr_start = 0.1 \n",
    "neural_lr_stop = 0.0005 \n",
    "neural_lr_rule = \"constant\"\n",
    "neural_lr_decay_multiplier = 0.005\n",
    "neural_dynamic_iterations = 1\n",
    "\n",
    "model = CorInfoMaxBiDirectionalNudged(architecture, lambda_, epsilon, activation, use_stepLR = True, \n",
    "                                      sgd_nesterov = False, optimizer_type = \"sgd\", \n",
    "                                      optim_lr_ff = 1.0, optim_lr_fb = 1.0, stepLR_step_size = 10*3000,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c1c3cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:07,  7.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1, Train Accuracy : 0.0993, Test Accuracy : 0.1032\n",
      "B_1 update difference : 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [00:15,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1, Train Accuracy : 0.09871666666666666, Test Accuracy : 0.098\n",
      "B_1 update difference : nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:16,  1.69s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_45033/1334900252.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m                         )\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             trn_acc = evaluatePC(model, train_loader, device, False, \n\u001b[0m\u001b[1;32m     23\u001b[0m                                  printing = False)\n\u001b[1;32m     24\u001b[0m             tst_acc = evaluatePC(model, test_loader, device, False, \n",
      "\u001b[0;32m/scratch/users/bbozkurt15/CorInfoMaxSupervised/Supervised-CorInfoMax/src/torch_utils.py\u001b[0m in \u001b[0;36mevaluatePC\u001b[0;34m(model, loader, device, apply_activation_inverse, activation_type, printing)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0mneurons\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfast_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneurons\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/users/bbozkurt15/CorInfoMaxSupervised/Supervised-CorInfoMax/src/ExplicitModels.py\u001b[0m in \u001b[0;36mfast_forward\u001b[0;34m(self, x, no_grad)\u001b[0m\n\u001b[1;32m    922\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mjj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mjj\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m                     \u001b[0mneurons\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWff\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mjj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mWff\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mjj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bias'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m                     \u001b[0mneurons\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWff\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mjj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneurons\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mWff\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mjj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bias'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trn_acc_list = []\n",
    "tst_acc_list = []\n",
    "random_sign = False\n",
    "n_epochs = 50\n",
    "\n",
    "for epoch_ in range(n_epochs):\n",
    "    Bcopy = torch.clone(model.B[0][\"weight\"])\n",
    "    for idx, (x, y) in tqdm(enumerate(train_loader)):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        x = x.to(device).view(x.size(0),-1).T\n",
    "        y_one_hot = F.one_hot(y, 10).to(device).T\n",
    "        #y_one_hot = 0.94 * y_one_hot + 0.03 * torch.ones(*y_one_hot.shape, device = device)\n",
    "        if random_sign:\n",
    "            rnd_sgn = 2*np.random.randint(2) - 1\n",
    "            supervised_lambda_weight = rnd_sgn * supervised_lambda_weight\n",
    "\n",
    "        model.batch_step(  x, y_one_hot, supervised_lambda_weight,\n",
    "                           neural_lr_start, neural_lr_stop, neural_lr_rule,\n",
    "                           neural_lr_decay_multiplier, neural_dynamic_iterations,\n",
    "                        )\n",
    "        if idx % 1 == 0:\n",
    "            trn_acc = evaluatePC(model, train_loader, device, False, \n",
    "                                 printing = False)\n",
    "            tst_acc = evaluatePC(model, test_loader, device, False, \n",
    "                                 printing = False)\n",
    "            trn_acc_list.append(trn_acc)\n",
    "            tst_acc_list.append(tst_acc)\n",
    "\n",
    "            print(\"Epoch : {}, Train Accuracy : {}, Test Accuracy : {}\".format(epoch_+1, trn_acc, tst_acc))\n",
    "            print(\"B_1 update difference : {}\".format(torch.norm(model.B[0]['weight'] - Bcopy)))\n",
    "        \n",
    "        \n",
    "    trn_acc = evaluatePC(model, train_loader, device, False, \n",
    "                         printing = False)\n",
    "    tst_acc = evaluatePC(model, test_loader, device, False, \n",
    "                         printing = False)\n",
    "    trn_acc_list.append(trn_acc)\n",
    "    tst_acc_list.append(tst_acc)\n",
    "    \n",
    "    print(\"Epoch : {}, Train Accuracy : {}, Test Accuracy : {}\".format(epoch_+1, trn_acc, tst_acc))\n",
    "    print(\"B_1 update difference : {}\".format(torch.norm(model.B[0]['weight'] - Bcopy)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da4c8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.Wff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845b41ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(torch2numpy(model.B[0]['weight']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951e0d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch2numpy(model.B[0]['weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a86f051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
       "        [nan, nan, nan,  ..., nan, nan, nan],\n",
       "        [nan, nan, nan,  ..., nan, nan, nan],\n",
       "        ...,\n",
       "        [nan, nan, nan,  ..., nan, nan, nan],\n",
       "        [nan, nan, nan,  ..., nan, nan, nan],\n",
       "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(128,128).to('cuda') + 0.0*model.B[0]['weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4b5528",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876fd719",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c3d59ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-0.1182, -0.2738, -0.1414,  ..., -0.0847,  0.0058, -0.4658],\n",
       "         [-0.5830,  0.3235,  0.2114,  ...,  0.0414, -0.1767, -0.0274],\n",
       "         [-0.0964, -0.1394, -1.0852,  ...,  0.0103, -0.4806, -0.4961],\n",
       "         ...,\n",
       "         [-0.7570,  0.2953, -0.1379,  ...,  0.2147,  0.2571, -0.3191],\n",
       "         [-0.4147,  0.0109, -0.3434,  ..., -0.5843, -0.8091, -0.6236],\n",
       "         [-0.3929, -0.1974, -0.4347,  ..., -0.1661,  0.0517, -0.5392]],\n",
       "        device='cuda:0', requires_grad=True),\n",
       " tensor([[ 0.1010,  0.0707, -0.2729,  ...,  0.1449, -0.1843,  0.1068],\n",
       "         [-0.8148, -0.5566, -0.2989,  ..., -0.2424,  0.4361, -0.2299],\n",
       "         [-0.4215,  0.1320, -0.4752,  ..., -0.1623, -0.7825, -0.1080],\n",
       "         ...,\n",
       "         [-0.1272,  0.2122, -0.2905,  ..., -0.2768, -0.3176, -0.0832],\n",
       "         [ 0.4737,  0.2753, -0.2721,  ..., -0.1342, -0.1076, -0.0320],\n",
       "         [ 0.8081,  0.3926, -0.0470,  ..., -0.0111, -0.2150,  0.0753]],\n",
       "        device='cuda:0', requires_grad=True),\n",
       " tensor([[ 3.2593e-02, -1.4696e-01,  3.9810e-01,  2.0723e-01,  3.5480e-01,\n",
       "           2.4854e-01,  7.1525e-01,  3.6676e-01,  1.6400e-01,  3.8456e-01,\n",
       "           3.0201e-01, -4.8689e-02,  3.1159e-01,  5.3521e-01,  4.5716e-01,\n",
       "           9.6085e-02,  2.5753e-02,  6.5213e-02,  6.0126e-01,  3.3711e-01],\n",
       "         [-3.7720e-01, -1.4727e-01, -3.2928e-01, -5.0271e-01, -3.2444e-01,\n",
       "          -3.5506e-01, -4.5717e-01, -3.4219e-01, -2.3117e-01,  1.1404e-01,\n",
       "          -2.6146e-01, -3.4737e-01, -6.1229e-01, -5.1474e-01, -5.6368e-01,\n",
       "          -4.5583e-01, -9.0784e-01, -6.2503e-01, -8.6990e-01, -5.2081e-01],\n",
       "         [-4.7504e-01,  2.2278e-03, -4.5938e-01, -5.3066e-01, -2.8972e-01,\n",
       "          -4.5746e-01, -7.5685e-01, -3.7699e-01, -3.3614e-01, -7.1634e-01,\n",
       "          -3.8846e-01, -1.9777e-01, -3.9438e-01, -4.0362e-01, -4.9384e-01,\n",
       "          -1.4416e-01,  2.8450e-01, -3.4139e-01, -3.7965e-01, -3.5620e-01],\n",
       "         [ 1.3931e-01,  3.5902e-01,  2.7420e-01,  3.8754e-01, -8.9614e-02,\n",
       "           3.9582e-01,  4.3545e-01, -1.9802e-02, -1.7290e-01,  5.4929e-02,\n",
       "           2.6049e-01, -2.5708e-01,  1.8576e-01,  1.9918e-01,  3.8006e-01,\n",
       "           2.3895e-01,  1.1857e-01, -1.0249e-01,  4.7887e-02, -1.5468e-01],\n",
       "         [ 3.2392e-01,  7.6535e-02,  3.3626e-01,  9.3682e-02,  1.1691e-01,\n",
       "           4.0999e-01,  2.3989e-02,  2.7358e-01,  3.0389e-01,  4.3997e-02,\n",
       "           1.6258e-01, -3.9038e-01, -3.7082e-02,  2.9272e-01,  4.1619e-01,\n",
       "          -2.5016e-01,  1.9095e-01, -5.3087e-01,  5.0787e-01,  2.0206e-01],\n",
       "         [-3.6108e-01,  4.7375e-01, -1.8012e-01, -1.0819e-01,  9.5687e-02,\n",
       "          -1.0982e-01, -2.2212e-01,  5.4687e-01, -1.7062e-01,  1.4675e-02,\n",
       "          -4.4564e-01,  1.4557e-02, -1.5158e-01,  1.0254e-01,  5.1621e-01,\n",
       "           3.0610e-01, -1.9031e-01, -7.7431e-02, -4.9427e-01, -3.0938e-01],\n",
       "         [ 5.1214e-01,  2.0287e-01,  3.2308e-01,  2.5211e-01, -8.3078e-02,\n",
       "           1.4391e-01, -5.1111e-01,  1.5411e-01,  3.0413e-01,  1.3651e-01,\n",
       "           3.4418e-01,  8.5196e-02,  2.4016e-01,  2.9692e-01, -5.9906e-02,\n",
       "           3.4328e-01,  4.4535e-01, -1.1541e-01,  1.5058e-01,  2.3076e-01],\n",
       "         [-5.1531e-01, -5.7832e-01, -6.9898e-01, -7.0588e-01, -5.6389e-01,\n",
       "          -6.0120e-01, -9.1659e-01, -6.1828e-01, -1.4143e-01, -6.5875e-01,\n",
       "          -4.9499e-01, -1.0187e+00, -5.6012e-01, -6.8194e-01, -4.2120e-01,\n",
       "          -1.1882e+00, -2.3791e-01, -1.1248e+00, -9.2733e-01, -4.1675e-01],\n",
       "         [-2.4699e-02,  2.3260e-01,  2.6143e-02, -3.0221e-01, -1.3663e-01,\n",
       "           3.6391e-01,  3.3900e-01, -2.6221e-01,  5.0616e-02, -6.9682e-02,\n",
       "          -1.0559e-01, -2.8587e-01, -1.7860e-01, -2.0414e-04,  1.5601e-01,\n",
       "           1.9020e-01, -1.3091e-01, -5.2456e-01,  6.6101e-02, -7.4524e-02],\n",
       "         [ 4.1867e-02, -9.4003e-02, -1.6887e-01,  7.6205e-03, -1.5571e-01,\n",
       "           3.9588e-03,  1.1779e-01,  3.3294e-01, -1.7978e-01,  2.5768e-01,\n",
       "          -6.8243e-02, -5.1508e-01, -3.0191e-01, -7.7931e-02, -2.5366e-01,\n",
       "          -1.1674e-01,  3.8441e-02, -5.0293e-01, -7.9856e-02, -1.0608e-01]],\n",
       "        device='cuda:0', requires_grad=True)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# activation = F.relu\n",
    "# architecture = [784, 128, 64, 10]\n",
    "# lambda_ = 0.9999\n",
    "# epsilon = 0.01\n",
    "# supervised_lambda_weight = 1e-3\n",
    "# neural_lr_start = 0.001 \n",
    "# neural_lr_stop = 0.0005 \n",
    "# neural_lr_rule = \"constant\"\n",
    "# neural_lr_decay_multiplier = 0.005\n",
    "# neural_dynamic_iterations = 50\n",
    "\n",
    "# model = CorInfoMaxBiDirectionalNudged(architecture, lambda_, epsilon, activation, use_stepLR = True, \n",
    "#                                       sgd_nesterov = False, optimizer_type = \"sgd\", \n",
    "#                                       optim_lr_ff = 1, optim_lr_fb = 0.1, stepLR_step_size = 10*3000,)\n",
    "\n",
    "activation = F.relu\n",
    "architecture = [784, 128, 64, 10]\n",
    "lambda_ = 0.99999\n",
    "epsilon = 0.01\n",
    "supervised_lambda_weight = 1e-3\n",
    "neural_lr_start = 0.1 \n",
    "neural_lr_stop = 0.0005 \n",
    "neural_lr_rule = \"constant\"\n",
    "neural_lr_decay_multiplier = 0.005\n",
    "neural_dynamic_iterations = 50\n",
    "\n",
    "model = CorInfoMaxBiDirectionalNudged(architecture, lambda_, epsilon, activation, use_stepLR = True, \n",
    "                                      sgd_nesterov = False, optimizer_type = \"sgd\", \n",
    "                                      optim_lr_ff = 1, optim_lr_fb = 0.5, stepLR_step_size = 10*3000,)\n",
    "\n",
    "model = CorInfoMaxNudged(architecture, lambda_, epsilon, activation, use_stepLR = True, \n",
    "                         sgd_nesterov = False, optimizer_type = \"sgd\", \n",
    "                         optim_lr = 1, stepLR_step_size = 10*3000,)\n",
    "\n",
    "x, y = next(iter(train_loader))\n",
    "x, y = x.to(device), y.to(device)\n",
    "x = x.to(device).view(x.size(0),-1).T\n",
    "y_one_hot = F.one_hot(y, 10).to(device).T\n",
    "\n",
    "neurons = model.fast_forward(x, no_grad = True)\n",
    "# for jj in range(len(neurons)):\n",
    "#     neurons[jj] = neurons[jj].requires_grad_()\n",
    "    \n",
    "# layers = [x] + neurons\n",
    "\n",
    "# layers_copy = model.copy_neurons(layers)\n",
    "neurons = model.fast_forward(x, no_grad = True)\n",
    "neurons = model.run_neural_dynamics(x, y_one_hot, neurons, supervised_lambda_weight, \n",
    "                          neural_lr_start, neural_lr_stop, lr_rule = neural_lr_rule, \n",
    "                          lr_decay_multiplier = neural_lr_decay_multiplier, \n",
    "                          neural_dynamic_iterations = neural_dynamic_iterations)\n",
    "\n",
    "# corinfo_cost = model.CorInfo_Cost(x, y, neurons).sum()\n",
    "# corinfo_cost.backward()\n",
    "\n",
    "# (model.Wff[0]['weight'].grad)\n",
    "neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "44d2826f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([6, 5, 0, 3, 0, 4, 0, 5, 6, 0, 6, 6, 0, 0, 5, 6, 6, 0, 0, 0],\n",
       "        device='cuda:0'),\n",
       " tensor([6, 1, 7, 6, 8, 7, 3, 2, 1, 6, 9, 4, 5, 7, 1, 7, 0, 4, 7, 7],\n",
       "        device='cuda:0'))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(neurons[-1], 0), y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49285f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(torch2numpy((model.Wff[0]['weight'].grad)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa3d5df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a7e317",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab4bf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "mbs = x.size(1)\n",
    "for jj in range(len(neurons)):\n",
    "    neurons[jj] = neurons[jj].requires_grad_()\n",
    "corinfo_cost = model.CorInfo_Cost(x, y, neurons)\n",
    "init_grads = torch.tensor([1 for i in range(mbs)], dtype=torch.float, device=device, requires_grad=True) #Initializing gradients\n",
    "grads = torch.autograd.grad(corinfo_cost, neurons, grad_outputs=init_grads, create_graph=False) # dPhi/ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2b99d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_over_epsilon = model.one_over_epsilon\n",
    "gam_ = model.gam_\n",
    "\n",
    "x, y = next(iter(train_loader))\n",
    "x, y = x.to(device), y.to(device)\n",
    "x = x.to(device).view(x.size(0),-1).T\n",
    "y_one_hot = F.one_hot(y, 10).to(device).T\n",
    "\n",
    "Wff = model.Wff\n",
    "B = model.B\n",
    "\n",
    "neurons = model.fast_forward(x, no_grad = True)\n",
    "\n",
    "layers = [x] + neurons\n",
    "for jj in range(len(Wff)):\n",
    "    if jj == 0:\n",
    "        error = - one_over_epsilon * (layers[jj + 1] - (Wff[jj]['weight'] @ layers[jj] + Wff[jj]['bias'])) \n",
    "    else:\n",
    "        error = - one_over_epsilon * (layers[jj + 1] - (Wff[jj]['weight'] @ model.activation(layers[jj]) + Wff[jj]['bias']))\n",
    "\n",
    "    lateral_term = gam_ * 0.5 * (layers[jj + 1].T @ B[jj]['weight'] @ layers[jj + 1])\n",
    "    corinfo_cost = torch.sum(error * error, 0)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7159306a",
   "metadata": {},
   "outputs": [],
   "source": [
    "error.shape\n",
    "torch.sum(error * error, 0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3592a711",
   "metadata": {},
   "outputs": [],
   "source": [
    "outer_prod_broadcasting((B[jj]['weight'] @ layers[jj + 1]), layers[jj + 1].T).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac8cf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers[jj + 1][:,2].T @ B[jj]['weight'] @ layers[jj + 1][:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c09111",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sum((B[jj]['weight'] @ layers[jj + 1]) * layers[jj + 1], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb89c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(B[jj]['weight'] @ layers[jj + 1]).shape, layers[jj + 1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d5baa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_acc_list = []\n",
    "tst_acc_list = []\n",
    "random_sign = False\n",
    "n_epochs = 50\n",
    "\n",
    "for epoch_ in range(n_epochs):\n",
    "    for idx, (x, y) in tqdm(enumerate(train_loader)):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        x = x.to(device).view(x.size(0),-1).T\n",
    "        y_one_hot = F.one_hot(y, 10).to(device).T\n",
    "        #y_one_hot = 0.94 * y_one_hot + 0.03 * torch.ones(*y_one_hot.shape, device = device)\n",
    "        if random_sign:\n",
    "            rnd_sgn = 2*np.random.randint(2) - 1\n",
    "            supervised_lambda_weight = rnd_sgn * supervised_lambda_weight\n",
    "\n",
    "        model.batch_step(  x, y_one_hot, supervised_lambda_weight,\n",
    "                           neural_lr_start, neural_lr_stop, neural_lr_rule,\n",
    "                           neural_lr_decay_multiplier, neural_dynamic_iterations,\n",
    "                        )\n",
    "\n",
    "    trn_acc = evaluatePC(model, train_loader, device, False, \n",
    "                         printing = False)\n",
    "    tst_acc = evaluatePC(model, test_loader, device, False, \n",
    "                         printing = False)\n",
    "    trn_acc_list.append(trn_acc)\n",
    "    tst_acc_list.append(tst_acc)\n",
    "    \n",
    "    print(\"Epoch : {}, Train Accuracy : {}, Test Accuracy : {}\".format(epoch_+1, trn_acc, tst_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
