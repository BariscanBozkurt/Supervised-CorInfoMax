{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fd7911f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import glob\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "from itertools import repeat\n",
    "from torch.nn.parameter import Parameter\n",
    "import collections\n",
    "import matplotlib\n",
    "from torch_utils import *\n",
    "from ExplicitModels import *\n",
    "from visualization import *\n",
    "# matplotlib.use('Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0481fdbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94c4836a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(),])\n",
    "\n",
    "mnist_dset_train = torchvision.datasets.MNIST('./data', train=True, transform=transform, target_transform=None, download=True)\n",
    "train_loader = torch.utils.data.DataLoader(mnist_dset_train, batch_size=20, shuffle=True, num_workers=0)\n",
    "\n",
    "mnist_dset_test = torchvision.datasets.MNIST('./data', train=False, transform=transform, target_transform=None, download=True)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_dset_test, batch_size=20, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd835cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# activation = F.relu\n",
    "# architecture = [784, 128, 64, 10]\n",
    "# lambda_ = 0.99999\n",
    "# epsilon = 0.2\n",
    "# supervised_lambda_weight = 1e-3\n",
    "# neural_lr_start = 0.001 \n",
    "# neural_lr_stop = 0.0005 \n",
    "# neural_lr_rule = \"constant\"\n",
    "# neural_lr_decay_multiplier = 0.005\n",
    "# neural_dynamic_iterations = 50\n",
    "activation = F.relu\n",
    "architecture = [784, 128, 64, 10]\n",
    "lambda_ = 0.99999\n",
    "epsilon = 0.01\n",
    "supervised_lambda_weight = 1e-1\n",
    "neural_lr_start = 0.001 \n",
    "neural_lr_stop = 0.0 \n",
    "neural_lr_rule = \"constant\"\n",
    "neural_lr_decay_multiplier = 0.005\n",
    "neural_dynamic_iterations = 15\n",
    "\n",
    "model = CorInfoMaxBiDirectionalNudged(architecture, lambda_, epsilon, activation, use_stepLR = True, \n",
    "                                      sgd_nesterov = False, optimizer_type = \"sgd\", \n",
    "                                      optim_lr_ff = 0.01, optim_lr_fb = 0.01, stepLR_step_size = 10*3000,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c1c3cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [01:37, 30.87it/s]\n",
      "3it [00:00, 27.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1, Train Accuracy : 0.09871666666666666, Test Accuracy : 0.098\n",
      "B_1 update difference : nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [01:37, 30.71it/s]\n",
      "3it [00:00, 28.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 2, Train Accuracy : 0.09871666666666666, Test Accuracy : 0.098\n",
      "B_1 update difference : nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1488it [00:48, 30.60it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_149499/1908636024.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0msupervised_lambda_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd_sgn\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msupervised_lambda_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         model.batch_step(  x, y_one_hot, supervised_lambda_weight,\n\u001b[0m\u001b[1;32m     18\u001b[0m                            \u001b[0mneural_lr_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneural_lr_stop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneural_lr_rule\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                            \u001b[0mneural_lr_decay_multiplier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneural_dynamic_iterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/users/bbozkurt15/CorInfoMaxSupervised/Supervised-CorInfoMax/src/ExplicitModels.py\u001b[0m in \u001b[0;36mbatch_step\u001b[0;34m(self, x, y, lambda_weight, neural_lr_start, neural_lr_stop, neural_lr_rule, neural_lr_decay_multiplier, neural_dynamic_iterations, mode)\u001b[0m\n\u001b[1;32m   1029\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_ff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_fb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1031\u001b[0;31m         \u001b[0mcorinfo_cost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCorInfo_Cost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneurons\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#* (1 / lambda_weight)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1032\u001b[0m         \u001b[0mcorinfo_cost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_ff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/users/bbozkurt15/CorInfoMaxSupervised/Supervised-CorInfoMax/src/ExplicitModels.py\u001b[0m in \u001b[0;36mCorInfo_Cost\u001b[0;34m(self, x, y, neurons, lambda_weight)\u001b[0m\n\u001b[1;32m    946\u001b[0m                 \u001b[0mforward_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mjj\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mWff\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mjj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers_copy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mjj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mWff\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mjj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bias'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m             \u001b[0mlateral_term\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgam_\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mjj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mjj\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mjj\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m             \u001b[0mcorinfo_cost\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlateral_term\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforward_error\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mforward_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trn_acc_list = []\n",
    "tst_acc_list = []\n",
    "random_sign = False\n",
    "n_epochs = 50\n",
    "\n",
    "for epoch_ in range(n_epochs):\n",
    "    Bcopy = torch.clone(model.B[0][\"weight\"])\n",
    "    for idx, (x, y) in tqdm(enumerate(train_loader)):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        x = x.to(device).view(x.size(0),-1).T\n",
    "        y_one_hot = F.one_hot(y, 10).to(device).T\n",
    "        #y_one_hot = 0.94 * y_one_hot + 0.03 * torch.ones(*y_one_hot.shape, device = device)\n",
    "        if random_sign:\n",
    "            rnd_sgn = 2*np.random.randint(2) - 1\n",
    "            supervised_lambda_weight = rnd_sgn * supervised_lambda_weight\n",
    "\n",
    "        model.batch_step(  x, y_one_hot, supervised_lambda_weight,\n",
    "                           neural_lr_start, neural_lr_stop, neural_lr_rule,\n",
    "                           neural_lr_decay_multiplier, neural_dynamic_iterations,\n",
    "                        )\n",
    "\n",
    "    trn_acc = evaluatePC(model, train_loader, device, False, \n",
    "                         printing = False)\n",
    "    tst_acc = evaluatePC(model, test_loader, device, False, \n",
    "                         printing = False)\n",
    "    trn_acc_list.append(trn_acc)\n",
    "    tst_acc_list.append(tst_acc)\n",
    "    \n",
    "    print(\"Epoch : {}, Train Accuracy : {}, Test Accuracy : {}\".format(epoch_+1, trn_acc, tst_acc))\n",
    "    print(\"B_1 update difference : {}\".format(torch.norm(model.B[0]['weight'] - Bcopy)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3cc633",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.Wff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845b41ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(torch2numpy(model.B[0]['weight']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951e0d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch2numpy(model.B[0]['weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a86f051",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.B.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4b5528",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876fd719",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3d59ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# activation = F.relu\n",
    "# architecture = [784, 128, 64, 10]\n",
    "# lambda_ = 0.9999\n",
    "# epsilon = 0.01\n",
    "# supervised_lambda_weight = 1e-3\n",
    "# neural_lr_start = 0.001 \n",
    "# neural_lr_stop = 0.0005 \n",
    "# neural_lr_rule = \"constant\"\n",
    "# neural_lr_decay_multiplier = 0.005\n",
    "# neural_dynamic_iterations = 50\n",
    "\n",
    "# model = CorInfoMaxBiDirectionalNudged(architecture, lambda_, epsilon, activation, use_stepLR = True, \n",
    "#                                       sgd_nesterov = False, optimizer_type = \"sgd\", \n",
    "#                                       optim_lr_ff = 1, optim_lr_fb = 0.1, stepLR_step_size = 10*3000,)\n",
    "\n",
    "activation = F.relu\n",
    "architecture = [784, 128, 64, 10]\n",
    "lambda_ = 0.99999\n",
    "epsilon = 0.1\n",
    "supervised_lambda_weight = 1e-3\n",
    "neural_lr_start = 0.001 \n",
    "neural_lr_stop = 0.0005 \n",
    "neural_lr_rule = \"constant\"\n",
    "neural_lr_decay_multiplier = 0.005\n",
    "neural_dynamic_iterations = 50\n",
    "\n",
    "model = CorInfoMaxBiDirectionalNudged(architecture, lambda_, epsilon, activation, use_stepLR = True, \n",
    "                                      sgd_nesterov = False, optimizer_type = \"sgd\", \n",
    "                                      optim_lr_ff = 1, optim_lr_fb = 0.5, stepLR_step_size = 10*3000,)\n",
    "\n",
    "x, y = next(iter(train_loader))\n",
    "x, y = x.to(device), y.to(device)\n",
    "x = x.to(device).view(x.size(0),-1).T\n",
    "y_one_hot = F.one_hot(y, 10).to(device).T\n",
    "\n",
    "neurons = model.fast_forward(x, no_grad = True)\n",
    "# for jj in range(len(neurons)):\n",
    "#     neurons[jj] = neurons[jj].requires_grad_()\n",
    "    \n",
    "# layers = [x] + neurons\n",
    "\n",
    "# layers_copy = model.copy_neurons(layers)\n",
    "neurons = model.fast_forward(x, no_grad = True)\n",
    "neurons = model.run_neural_dynamics(x, y_one_hot, neurons, supervised_lambda_weight, \n",
    "                          neural_lr_start, neural_lr_stop, lr_rule = neural_lr_rule, \n",
    "                          lr_decay_multiplier = neural_lr_decay_multiplier, \n",
    "                          neural_dynamic_iterations = neural_dynamic_iterations)\n",
    "\n",
    "corinfo_cost = model.CorInfo_Cost(x, y, neurons).sum()\n",
    "corinfo_cost.backward()\n",
    "\n",
    "(model.Wff[0]['weight'].grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27efebbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(torch2numpy((model.Wff[0]['weight'].grad)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ff3ba6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af61bd12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab4bf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "mbs = x.size(1)\n",
    "for jj in range(len(neurons)):\n",
    "    neurons[jj] = neurons[jj].requires_grad_()\n",
    "corinfo_cost = model.CorInfo_Cost(x, y, neurons)\n",
    "init_grads = torch.tensor([1 for i in range(mbs)], dtype=torch.float, device=device, requires_grad=True) #Initializing gradients\n",
    "grads = torch.autograd.grad(corinfo_cost, neurons, grad_outputs=init_grads, create_graph=False) # dPhi/ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2b99d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_over_epsilon = model.one_over_epsilon\n",
    "gam_ = model.gam_\n",
    "\n",
    "x, y = next(iter(train_loader))\n",
    "x, y = x.to(device), y.to(device)\n",
    "x = x.to(device).view(x.size(0),-1).T\n",
    "y_one_hot = F.one_hot(y, 10).to(device).T\n",
    "\n",
    "Wff = model.Wff\n",
    "B = model.B\n",
    "\n",
    "neurons = model.fast_forward(x, no_grad = True)\n",
    "\n",
    "layers = [x] + neurons\n",
    "for jj in range(len(Wff)):\n",
    "    if jj == 0:\n",
    "        error = - one_over_epsilon * (layers[jj + 1] - (Wff[jj]['weight'] @ layers[jj] + Wff[jj]['bias'])) \n",
    "    else:\n",
    "        error = - one_over_epsilon * (layers[jj + 1] - (Wff[jj]['weight'] @ model.activation(layers[jj]) + Wff[jj]['bias']))\n",
    "\n",
    "    lateral_term = gam_ * 0.5 * (layers[jj + 1].T @ B[jj]['weight'] @ layers[jj + 1])\n",
    "    corinfo_cost = torch.sum(error * error, 0)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7159306a",
   "metadata": {},
   "outputs": [],
   "source": [
    "error.shape\n",
    "torch.sum(error * error, 0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3592a711",
   "metadata": {},
   "outputs": [],
   "source": [
    "outer_prod_broadcasting((B[jj]['weight'] @ layers[jj + 1]), layers[jj + 1].T).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac8cf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers[jj + 1][:,2].T @ B[jj]['weight'] @ layers[jj + 1][:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c09111",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sum((B[jj]['weight'] @ layers[jj + 1]) * layers[jj + 1], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb89c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(B[jj]['weight'] @ layers[jj + 1]).shape, layers[jj + 1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d5baa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_acc_list = []\n",
    "tst_acc_list = []\n",
    "random_sign = False\n",
    "n_epochs = 50\n",
    "\n",
    "for epoch_ in range(n_epochs):\n",
    "    for idx, (x, y) in tqdm(enumerate(train_loader)):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        x = x.to(device).view(x.size(0),-1).T\n",
    "        y_one_hot = F.one_hot(y, 10).to(device).T\n",
    "        #y_one_hot = 0.94 * y_one_hot + 0.03 * torch.ones(*y_one_hot.shape, device = device)\n",
    "        if random_sign:\n",
    "            rnd_sgn = 2*np.random.randint(2) - 1\n",
    "            supervised_lambda_weight = rnd_sgn * supervised_lambda_weight\n",
    "\n",
    "        model.batch_step(  x, y_one_hot, supervised_lambda_weight,\n",
    "                           neural_lr_start, neural_lr_stop, neural_lr_rule,\n",
    "                           neural_lr_decay_multiplier, neural_dynamic_iterations,\n",
    "                        )\n",
    "\n",
    "    trn_acc = evaluatePC(model, train_loader, device, False, \n",
    "                         printing = False)\n",
    "    tst_acc = evaluatePC(model, test_loader, device, False, \n",
    "                         printing = False)\n",
    "    trn_acc_list.append(trn_acc)\n",
    "    tst_acc_list.append(tst_acc)\n",
    "    \n",
    "    print(\"Epoch : {}, Train Accuracy : {}, Test Accuracy : {}\".format(epoch_+1, trn_acc, tst_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
