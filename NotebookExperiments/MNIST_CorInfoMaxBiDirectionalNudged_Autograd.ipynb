{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fd7911f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import glob\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "from itertools import repeat\n",
    "from torch.nn.parameter import Parameter\n",
    "import collections\n",
    "import matplotlib\n",
    "from torch_utils import *\n",
    "from ExplicitModels import *\n",
    "from visualization import *\n",
    "# matplotlib.use('Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0481fdbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94c4836a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(),])\n",
    "\n",
    "mnist_dset_train = torchvision.datasets.MNIST('./data', train=True, transform=transform, target_transform=None, download=True)\n",
    "train_loader = torch.utils.data.DataLoader(mnist_dset_train, batch_size=20, shuffle=True, num_workers=0)\n",
    "\n",
    "mnist_dset_test = torchvision.datasets.MNIST('./data', train=False, transform=transform, target_transform=None, download=True)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_dset_test, batch_size=20, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd835cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# activation = F.relu\n",
    "# architecture = [784, 128, 64, 10]\n",
    "# lambda_ = 0.99999\n",
    "# epsilon = 0.2\n",
    "# supervised_lambda_weight = 1e-3\n",
    "# neural_lr_start = 0.001 \n",
    "# neural_lr_stop = 0.0005 \n",
    "# neural_lr_rule = \"constant\"\n",
    "# neural_lr_decay_multiplier = 0.005\n",
    "# neural_dynamic_iterations = 50\n",
    "activation = F.relu\n",
    "architecture = [784, 128, 64, 10]\n",
    "lambda_ = 1\n",
    "epsilon = 0.01\n",
    "supervised_lambda_weight = 1e-3\n",
    "neural_lr_start = 0.1 \n",
    "neural_lr_stop = 0.0005 \n",
    "neural_lr_rule = \"constant\"\n",
    "neural_lr_decay_multiplier = 0.005\n",
    "neural_dynamic_iterations = 1\n",
    "\n",
    "model = CorInfoMaxBiDirectionalNudged(architecture, lambda_, epsilon, activation, use_stepLR = True, \n",
    "                                      sgd_nesterov = False, optimizer_type = \"sgd\", \n",
    "                                      optim_lr_ff = 1.0, optim_lr_fb = 1.0, stepLR_step_size = 10*3000,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c1c3cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:07,  7.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1, Train Accuracy : 0.09751666666666667, Test Accuracy : 0.0974\n",
      "B_1 update difference : 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:15,  7.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1, Train Accuracy : 0.09915, Test Accuracy : 0.1009\n",
      "B_1 update difference : 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [00:23,  7.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1, Train Accuracy : 0.09871666666666666, Test Accuracy : 0.098\n",
      "B_1 update difference : nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:27,  9.19s/it]\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/kuacc/users/bbozkurt15/.conda/envs/bbozkurt15/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3444, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_46960/2798578348.py\", line 22, in <module>\n",
      "    trn_acc = evaluatePC(model, train_loader, device, False,\n",
      "  File \"../src/torch_utils.py\", line 162, in evaluatePC\n",
      "    for x, y in loader:\n",
      "  File \"/kuacc/users/bbozkurt15/.conda/envs/bbozkurt15/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 530, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"/kuacc/users/bbozkurt15/.conda/envs/bbozkurt15/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 570, in _next_data\n",
      "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "  File \"/kuacc/users/bbozkurt15/.conda/envs/bbozkurt15/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/kuacc/users/bbozkurt15/.conda/envs/bbozkurt15/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/kuacc/users/bbozkurt15/.conda/envs/bbozkurt15/lib/python3.8/site-packages/torchvision/datasets/mnist.py\", line 142, in __getitem__\n",
      "    img = Image.fromarray(img.numpy(), mode=\"L\")\n",
      "  File \"/kuacc/users/bbozkurt15/.conda/envs/bbozkurt15/lib/python3.8/site-packages/PIL/Image.py\", line 2949, in fromarray\n",
      "    return frombuffer(mode, size, obj, \"raw\", rawmode, 0, 1)\n",
      "  File \"/kuacc/users/bbozkurt15/.conda/envs/bbozkurt15/lib/python3.8/site-packages/PIL/Image.py\", line 2871, in frombuffer\n",
      "    im = new(mode, (1, 1))\n",
      "  File \"/kuacc/users/bbozkurt15/.conda/envs/bbozkurt15/lib/python3.8/site-packages/PIL/Image.py\", line 2765, in new\n",
      "    _check_size(size)\n",
      "  File \"/kuacc/users/bbozkurt15/.conda/envs/bbozkurt15/lib/python3.8/site-packages/PIL/Image.py\", line 2743, in _check_size\n",
      "    if size[0] < 0 or size[1] < 0:\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/kuacc/users/bbozkurt15/.conda/envs/bbozkurt15/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2064, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/kuacc/users/bbozkurt15/.conda/envs/bbozkurt15/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/kuacc/users/bbozkurt15/.conda/envs/bbozkurt15/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/kuacc/users/bbozkurt15/.conda/envs/bbozkurt15/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/kuacc/users/bbozkurt15/.conda/envs/bbozkurt15/lib/python3.8/inspect.py\", line 1515, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/kuacc/users/bbozkurt15/.conda/envs/bbozkurt15/lib/python3.8/inspect.py\", line 1473, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/kuacc/users/bbozkurt15/.conda/envs/bbozkurt15/lib/python3.8/inspect.py\", line 708, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/kuacc/users/bbozkurt15/.conda/envs/bbozkurt15/lib/python3.8/inspect.py\", line 751, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"/kuacc/users/bbozkurt15/.conda/envs/bbozkurt15/lib/python3.8/inspect.py\", line 720, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"/kuacc/users/bbozkurt15/.conda/envs/bbozkurt15/lib/python3.8/inspect.py\", line 705, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"/kuacc/users/bbozkurt15/.conda/envs/bbozkurt15/lib/python3.8/genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_46960/2798578348.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             trn_acc = evaluatePC(model, train_loader, device, False, \n\u001b[0m\u001b[1;32m     23\u001b[0m                                  printing = False)\n",
      "\u001b[0;32m/scratch/users/bbozkurt15/CorInfoMaxSupervised/Supervised-CorInfoMax/src/torch_utils.py\u001b[0m in \u001b[0;36mevaluatePC\u001b[0;34m(model, loader, device, apply_activation_inverse, activation_type, printing)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mapply_activation_inverse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/bbozkurt15/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    529\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/bbozkurt15/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/bbozkurt15/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/bbozkurt15/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/bbozkurt15/lib/python3.8/site-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;31m# to return a PIL Image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"L\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/bbozkurt15/lib/python3.8/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   2948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2949\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrombuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"raw\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrawmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/bbozkurt15/lib/python3.8/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfrombuffer\u001b[0;34m(mode, size, data, decoder_name, *args)\u001b[0m\n\u001b[1;32m   2870\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_MAPMODES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2871\u001b[0;31m             \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2872\u001b[0m             \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/bbozkurt15/lib/python3.8/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mnew\u001b[0;34m(mode, size, color)\u001b[0m\n\u001b[1;32m   2764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2765\u001b[0;31m     \u001b[0m_check_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/bbozkurt15/lib/python3.8/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36m_check_size\u001b[0;34m(size)\u001b[0m\n\u001b[1;32m   2742\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Size must be a tuple of length 2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2743\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2744\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Width and height must be >= 0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/.conda/envs/bbozkurt15/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2063\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2064\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2065\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/bbozkurt15/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2064\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2065\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2066\u001b[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[1;32m   2067\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[1;32m   2068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/bbozkurt15/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/bbozkurt15/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n",
      "\u001b[0;32m~/.conda/envs/bbozkurt15/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/bbozkurt15/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/bbozkurt15/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "trn_acc_list = []\n",
    "tst_acc_list = []\n",
    "random_sign = False\n",
    "n_epochs = 50\n",
    "\n",
    "for epoch_ in range(n_epochs):\n",
    "    Bcopy = torch.clone(model.B[0][\"weight\"])\n",
    "    for idx, (x, y) in tqdm(enumerate(train_loader)):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        x = x.to(device).view(x.size(0),-1).T\n",
    "        y_one_hot = F.one_hot(y, 10).to(device).T\n",
    "        #y_one_hot = 0.94 * y_one_hot + 0.03 * torch.ones(*y_one_hot.shape, device = device)\n",
    "        if random_sign:\n",
    "            rnd_sgn = 2*np.random.randint(2) - 1\n",
    "            supervised_lambda_weight = rnd_sgn * supervised_lambda_weight\n",
    "\n",
    "        model.batch_step(  x, y_one_hot, supervised_lambda_weight,\n",
    "                           neural_lr_start, neural_lr_stop, neural_lr_rule,\n",
    "                           neural_lr_decay_multiplier, neural_dynamic_iterations,\n",
    "                        )\n",
    "        if idx % 1 == 0:\n",
    "            trn_acc = evaluatePC(model, train_loader, device, False, \n",
    "                                 printing = False)\n",
    "            tst_acc = evaluatePC(model, test_loader, device, False, \n",
    "                                 printing = False)\n",
    "            trn_acc_list.append(trn_acc)\n",
    "            tst_acc_list.append(tst_acc)\n",
    "\n",
    "            print(\"Epoch : {}, Train Accuracy : {}, Test Accuracy : {}\".format(epoch_+1, trn_acc, tst_acc))\n",
    "            print(\"B_1 update difference : {}\".format(torch.norm(model.B[0]['weight'] - Bcopy)))\n",
    "        \n",
    "        \n",
    "    trn_acc = evaluatePC(model, train_loader, device, False, \n",
    "                         printing = False)\n",
    "    tst_acc = evaluatePC(model, test_loader, device, False, \n",
    "                         printing = False)\n",
    "    trn_acc_list.append(trn_acc)\n",
    "    tst_acc_list.append(tst_acc)\n",
    "    \n",
    "    print(\"Epoch : {}, Train Accuracy : {}, Test Accuracy : {}\".format(epoch_+1, trn_acc, tst_acc))\n",
    "    print(\"B_1 update difference : {}\".format(torch.norm(model.B[0]['weight'] - Bcopy)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da4c8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.Wff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845b41ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(torch2numpy(model.B[0]['weight']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951e0d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch2numpy(model.B[0]['weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a86f051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
       "        [nan, nan, nan,  ..., nan, nan, nan],\n",
       "        [nan, nan, nan,  ..., nan, nan, nan],\n",
       "        ...,\n",
       "        [nan, nan, nan,  ..., nan, nan, nan],\n",
       "        [nan, nan, nan,  ..., nan, nan, nan],\n",
       "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(128,128).to('cuda') + 0.0*model.B[0]['weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4b5528",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876fd719",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c3d59ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-0.1182, -0.2738, -0.1414,  ..., -0.0847,  0.0058, -0.4658],\n",
       "         [-0.5830,  0.3235,  0.2114,  ...,  0.0414, -0.1767, -0.0274],\n",
       "         [-0.0964, -0.1394, -1.0852,  ...,  0.0103, -0.4806, -0.4961],\n",
       "         ...,\n",
       "         [-0.7570,  0.2953, -0.1379,  ...,  0.2147,  0.2571, -0.3191],\n",
       "         [-0.4147,  0.0109, -0.3434,  ..., -0.5843, -0.8091, -0.6236],\n",
       "         [-0.3929, -0.1974, -0.4347,  ..., -0.1661,  0.0517, -0.5392]],\n",
       "        device='cuda:0', requires_grad=True),\n",
       " tensor([[ 0.1010,  0.0707, -0.2729,  ...,  0.1449, -0.1843,  0.1068],\n",
       "         [-0.8148, -0.5566, -0.2989,  ..., -0.2424,  0.4361, -0.2299],\n",
       "         [-0.4215,  0.1320, -0.4752,  ..., -0.1623, -0.7825, -0.1080],\n",
       "         ...,\n",
       "         [-0.1272,  0.2122, -0.2905,  ..., -0.2768, -0.3176, -0.0832],\n",
       "         [ 0.4737,  0.2753, -0.2721,  ..., -0.1342, -0.1076, -0.0320],\n",
       "         [ 0.8081,  0.3926, -0.0470,  ..., -0.0111, -0.2150,  0.0753]],\n",
       "        device='cuda:0', requires_grad=True),\n",
       " tensor([[ 3.2593e-02, -1.4696e-01,  3.9810e-01,  2.0723e-01,  3.5480e-01,\n",
       "           2.4854e-01,  7.1525e-01,  3.6676e-01,  1.6400e-01,  3.8456e-01,\n",
       "           3.0201e-01, -4.8689e-02,  3.1159e-01,  5.3521e-01,  4.5716e-01,\n",
       "           9.6085e-02,  2.5753e-02,  6.5213e-02,  6.0126e-01,  3.3711e-01],\n",
       "         [-3.7720e-01, -1.4727e-01, -3.2928e-01, -5.0271e-01, -3.2444e-01,\n",
       "          -3.5506e-01, -4.5717e-01, -3.4219e-01, -2.3117e-01,  1.1404e-01,\n",
       "          -2.6146e-01, -3.4737e-01, -6.1229e-01, -5.1474e-01, -5.6368e-01,\n",
       "          -4.5583e-01, -9.0784e-01, -6.2503e-01, -8.6990e-01, -5.2081e-01],\n",
       "         [-4.7504e-01,  2.2278e-03, -4.5938e-01, -5.3066e-01, -2.8972e-01,\n",
       "          -4.5746e-01, -7.5685e-01, -3.7699e-01, -3.3614e-01, -7.1634e-01,\n",
       "          -3.8846e-01, -1.9777e-01, -3.9438e-01, -4.0362e-01, -4.9384e-01,\n",
       "          -1.4416e-01,  2.8450e-01, -3.4139e-01, -3.7965e-01, -3.5620e-01],\n",
       "         [ 1.3931e-01,  3.5902e-01,  2.7420e-01,  3.8754e-01, -8.9614e-02,\n",
       "           3.9582e-01,  4.3545e-01, -1.9802e-02, -1.7290e-01,  5.4929e-02,\n",
       "           2.6049e-01, -2.5708e-01,  1.8576e-01,  1.9918e-01,  3.8006e-01,\n",
       "           2.3895e-01,  1.1857e-01, -1.0249e-01,  4.7887e-02, -1.5468e-01],\n",
       "         [ 3.2392e-01,  7.6535e-02,  3.3626e-01,  9.3682e-02,  1.1691e-01,\n",
       "           4.0999e-01,  2.3989e-02,  2.7358e-01,  3.0389e-01,  4.3997e-02,\n",
       "           1.6258e-01, -3.9038e-01, -3.7082e-02,  2.9272e-01,  4.1619e-01,\n",
       "          -2.5016e-01,  1.9095e-01, -5.3087e-01,  5.0787e-01,  2.0206e-01],\n",
       "         [-3.6108e-01,  4.7375e-01, -1.8012e-01, -1.0819e-01,  9.5687e-02,\n",
       "          -1.0982e-01, -2.2212e-01,  5.4687e-01, -1.7062e-01,  1.4675e-02,\n",
       "          -4.4564e-01,  1.4557e-02, -1.5158e-01,  1.0254e-01,  5.1621e-01,\n",
       "           3.0610e-01, -1.9031e-01, -7.7431e-02, -4.9427e-01, -3.0938e-01],\n",
       "         [ 5.1214e-01,  2.0287e-01,  3.2308e-01,  2.5211e-01, -8.3078e-02,\n",
       "           1.4391e-01, -5.1111e-01,  1.5411e-01,  3.0413e-01,  1.3651e-01,\n",
       "           3.4418e-01,  8.5196e-02,  2.4016e-01,  2.9692e-01, -5.9906e-02,\n",
       "           3.4328e-01,  4.4535e-01, -1.1541e-01,  1.5058e-01,  2.3076e-01],\n",
       "         [-5.1531e-01, -5.7832e-01, -6.9898e-01, -7.0588e-01, -5.6389e-01,\n",
       "          -6.0120e-01, -9.1659e-01, -6.1828e-01, -1.4143e-01, -6.5875e-01,\n",
       "          -4.9499e-01, -1.0187e+00, -5.6012e-01, -6.8194e-01, -4.2120e-01,\n",
       "          -1.1882e+00, -2.3791e-01, -1.1248e+00, -9.2733e-01, -4.1675e-01],\n",
       "         [-2.4699e-02,  2.3260e-01,  2.6143e-02, -3.0221e-01, -1.3663e-01,\n",
       "           3.6391e-01,  3.3900e-01, -2.6221e-01,  5.0616e-02, -6.9682e-02,\n",
       "          -1.0559e-01, -2.8587e-01, -1.7860e-01, -2.0414e-04,  1.5601e-01,\n",
       "           1.9020e-01, -1.3091e-01, -5.2456e-01,  6.6101e-02, -7.4524e-02],\n",
       "         [ 4.1867e-02, -9.4003e-02, -1.6887e-01,  7.6205e-03, -1.5571e-01,\n",
       "           3.9588e-03,  1.1779e-01,  3.3294e-01, -1.7978e-01,  2.5768e-01,\n",
       "          -6.8243e-02, -5.1508e-01, -3.0191e-01, -7.7931e-02, -2.5366e-01,\n",
       "          -1.1674e-01,  3.8441e-02, -5.0293e-01, -7.9856e-02, -1.0608e-01]],\n",
       "        device='cuda:0', requires_grad=True)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# activation = F.relu\n",
    "# architecture = [784, 128, 64, 10]\n",
    "# lambda_ = 0.9999\n",
    "# epsilon = 0.01\n",
    "# supervised_lambda_weight = 1e-3\n",
    "# neural_lr_start = 0.001 \n",
    "# neural_lr_stop = 0.0005 \n",
    "# neural_lr_rule = \"constant\"\n",
    "# neural_lr_decay_multiplier = 0.005\n",
    "# neural_dynamic_iterations = 50\n",
    "\n",
    "# model = CorInfoMaxBiDirectionalNudged(architecture, lambda_, epsilon, activation, use_stepLR = True, \n",
    "#                                       sgd_nesterov = False, optimizer_type = \"sgd\", \n",
    "#                                       optim_lr_ff = 1, optim_lr_fb = 0.1, stepLR_step_size = 10*3000,)\n",
    "\n",
    "activation = F.relu\n",
    "architecture = [784, 128, 64, 10]\n",
    "lambda_ = 0.99999\n",
    "epsilon = 0.01\n",
    "supervised_lambda_weight = 1e-3\n",
    "neural_lr_start = 0.1 \n",
    "neural_lr_stop = 0.0005 \n",
    "neural_lr_rule = \"constant\"\n",
    "neural_lr_decay_multiplier = 0.005\n",
    "neural_dynamic_iterations = 50\n",
    "\n",
    "model = CorInfoMaxBiDirectionalNudged(architecture, lambda_, epsilon, activation, use_stepLR = True, \n",
    "                                      sgd_nesterov = False, optimizer_type = \"sgd\", \n",
    "                                      optim_lr_ff = 1, optim_lr_fb = 0.5, stepLR_step_size = 10*3000,)\n",
    "\n",
    "model = CorInfoMaxNudged(architecture, lambda_, epsilon, activation, use_stepLR = True, \n",
    "                         sgd_nesterov = False, optimizer_type = \"sgd\", \n",
    "                         optim_lr = 1, stepLR_step_size = 10*3000,)\n",
    "\n",
    "x, y = next(iter(train_loader))\n",
    "x, y = x.to(device), y.to(device)\n",
    "x = x.to(device).view(x.size(0),-1).T\n",
    "y_one_hot = F.one_hot(y, 10).to(device).T\n",
    "\n",
    "neurons = model.fast_forward(x, no_grad = True)\n",
    "# for jj in range(len(neurons)):\n",
    "#     neurons[jj] = neurons[jj].requires_grad_()\n",
    "    \n",
    "# layers = [x] + neurons\n",
    "\n",
    "# layers_copy = model.copy_neurons(layers)\n",
    "neurons = model.fast_forward(x, no_grad = True)\n",
    "neurons = model.run_neural_dynamics(x, y_one_hot, neurons, supervised_lambda_weight, \n",
    "                          neural_lr_start, neural_lr_stop, lr_rule = neural_lr_rule, \n",
    "                          lr_decay_multiplier = neural_lr_decay_multiplier, \n",
    "                          neural_dynamic_iterations = neural_dynamic_iterations)\n",
    "\n",
    "# corinfo_cost = model.CorInfo_Cost(x, y, neurons).sum()\n",
    "# corinfo_cost.backward()\n",
    "\n",
    "# (model.Wff[0]['weight'].grad)\n",
    "neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b9e4a259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([6, 5, 0, 3, 0, 4, 0, 5, 6, 0, 6, 6, 0, 0, 5, 6, 6, 0, 0, 0],\n",
       "        device='cuda:0'),\n",
       " tensor([6, 1, 7, 6, 8, 7, 3, 2, 1, 6, 9, 4, 5, 7, 1, 7, 0, 4, 7, 7],\n",
       "        device='cuda:0'))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(neurons[-1], 0), y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49285f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(torch2numpy((model.Wff[0]['weight'].grad)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa3d5df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a7e317",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab4bf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "mbs = x.size(1)\n",
    "for jj in range(len(neurons)):\n",
    "    neurons[jj] = neurons[jj].requires_grad_()\n",
    "corinfo_cost = model.CorInfo_Cost(x, y, neurons)\n",
    "init_grads = torch.tensor([1 for i in range(mbs)], dtype=torch.float, device=device, requires_grad=True) #Initializing gradients\n",
    "grads = torch.autograd.grad(corinfo_cost, neurons, grad_outputs=init_grads, create_graph=False) # dPhi/ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2b99d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_over_epsilon = model.one_over_epsilon\n",
    "gam_ = model.gam_\n",
    "\n",
    "x, y = next(iter(train_loader))\n",
    "x, y = x.to(device), y.to(device)\n",
    "x = x.to(device).view(x.size(0),-1).T\n",
    "y_one_hot = F.one_hot(y, 10).to(device).T\n",
    "\n",
    "Wff = model.Wff\n",
    "B = model.B\n",
    "\n",
    "neurons = model.fast_forward(x, no_grad = True)\n",
    "\n",
    "layers = [x] + neurons\n",
    "for jj in range(len(Wff)):\n",
    "    if jj == 0:\n",
    "        error = - one_over_epsilon * (layers[jj + 1] - (Wff[jj]['weight'] @ layers[jj] + Wff[jj]['bias'])) \n",
    "    else:\n",
    "        error = - one_over_epsilon * (layers[jj + 1] - (Wff[jj]['weight'] @ model.activation(layers[jj]) + Wff[jj]['bias']))\n",
    "\n",
    "    lateral_term = gam_ * 0.5 * (layers[jj + 1].T @ B[jj]['weight'] @ layers[jj + 1])\n",
    "    corinfo_cost = torch.sum(error * error, 0)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7159306a",
   "metadata": {},
   "outputs": [],
   "source": [
    "error.shape\n",
    "torch.sum(error * error, 0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3592a711",
   "metadata": {},
   "outputs": [],
   "source": [
    "outer_prod_broadcasting((B[jj]['weight'] @ layers[jj + 1]), layers[jj + 1].T).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac8cf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers[jj + 1][:,2].T @ B[jj]['weight'] @ layers[jj + 1][:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c09111",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sum((B[jj]['weight'] @ layers[jj + 1]) * layers[jj + 1], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb89c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(B[jj]['weight'] @ layers[jj + 1]).shape, layers[jj + 1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d5baa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_acc_list = []\n",
    "tst_acc_list = []\n",
    "random_sign = False\n",
    "n_epochs = 50\n",
    "\n",
    "for epoch_ in range(n_epochs):\n",
    "    for idx, (x, y) in tqdm(enumerate(train_loader)):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        x = x.to(device).view(x.size(0),-1).T\n",
    "        y_one_hot = F.one_hot(y, 10).to(device).T\n",
    "        #y_one_hot = 0.94 * y_one_hot + 0.03 * torch.ones(*y_one_hot.shape, device = device)\n",
    "        if random_sign:\n",
    "            rnd_sgn = 2*np.random.randint(2) - 1\n",
    "            supervised_lambda_weight = rnd_sgn * supervised_lambda_weight\n",
    "\n",
    "        model.batch_step(  x, y_one_hot, supervised_lambda_weight,\n",
    "                           neural_lr_start, neural_lr_stop, neural_lr_rule,\n",
    "                           neural_lr_decay_multiplier, neural_dynamic_iterations,\n",
    "                        )\n",
    "\n",
    "    trn_acc = evaluatePC(model, train_loader, device, False, \n",
    "                         printing = False)\n",
    "    tst_acc = evaluatePC(model, test_loader, device, False, \n",
    "                         printing = False)\n",
    "    trn_acc_list.append(trn_acc)\n",
    "    tst_acc_list.append(tst_acc)\n",
    "    \n",
    "    print(\"Epoch : {}, Train Accuracy : {}, Test Accuracy : {}\".format(epoch_+1, trn_acc, tst_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
