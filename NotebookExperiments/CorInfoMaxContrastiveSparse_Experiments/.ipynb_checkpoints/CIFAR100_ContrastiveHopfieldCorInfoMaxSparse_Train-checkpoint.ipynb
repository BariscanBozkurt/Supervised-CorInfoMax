{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89b20c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../src\")\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import glob\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "from itertools import repeat\n",
    "from torch.nn.parameter import Parameter\n",
    "import collections\n",
    "import matplotlib\n",
    "from torch_utils import *\n",
    "from ContrastiveModels import ContrastiveCorInfoMaxHopfieldSparse\n",
    "from visualization import *\n",
    "# matplotlib.use('Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef0c0a15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "128dc72a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(), \n",
    "                                            torchvision.transforms.Normalize(mean=(0.4914, 0.4822, 0.4465), \n",
    "                                            std=(3*0.2023, 3*0.1994, 3*0.2010))])\n",
    "\n",
    "cifar_dset_train = torchvision.datasets.CIFAR100('../../data', train=True, transform=transform, target_transform=None, download=True)\n",
    "train_loader = torch.utils.data.DataLoader(cifar_dset_train, batch_size=20, shuffle=True, num_workers=0)\n",
    "\n",
    "cifar_dset_test = torchvision.datasets.CIFAR100('../../data', train=False, transform=transform, target_transform=None, download=True)\n",
    "test_loader = torch.utils.data.DataLoader(cifar_dset_test, batch_size=20, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c77e36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = hard_sigmoid\n",
    "architecture = architecture = [int(32*32*3), 2000, 1000, 10]\n",
    "\n",
    "STlambda_lr_list = [5*1e-6, 5*1e-6, 0.01]\n",
    "sparse_layers = [1, 2, 3]\n",
    "\n",
    "beta = 1\n",
    "lambda_ = 0.99999\n",
    "epsilon = 0.15\n",
    "one_over_epsilon = 1 / epsilon\n",
    "lr_start =  {'ff' : np.array([0.16, 0.13, 0.08]), 'fb': np.array([np.nan, 0.06, 0.04])}\n",
    "\n",
    "\n",
    "neural_lr_start = 0.06\n",
    "neural_lr_stop = 0.001\n",
    "neural_lr_rule = \"constant\"\n",
    "neural_lr_decay_multiplier = 0.01\n",
    "neural_dynamic_iterations_nudged = 20\n",
    "neural_dynamic_iterations_free = 50\n",
    "hopfield_g = 0.1\n",
    "use_random_sign_beta = True\n",
    "use_three_phase = False\n",
    "weight_decay = False\n",
    "\n",
    "model = ContrastiveCorInfoMaxHopfieldSparse(architecture = architecture, lambda_ = lambda_, \n",
    "                                            epsilon = epsilon, activation = activation, \n",
    "                                            sparse_layers = sparse_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3448d1d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy :\t 0.0108\n",
      "Sparsity for layers:  [0.5247186  0.53510994]\n"
     ]
    }
   ],
   "source": [
    "_ = evaluateContrastiveCorInfoMaxHopfieldSparse(model, test_loader, hopfield_g, neural_lr_start, \n",
    "                                                neural_lr_stop, STlambda_lr_list, neural_lr_rule, \n",
    "                                                neural_lr_decay_multiplier, \n",
    "                                                neural_dynamic_iterations_free, \n",
    "                                                device, printing = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89a5727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _ = evaluateContrastiveCorInfoMaxHopfieldSparse_topk( model, train_loader, hopfield_g,\n",
    "#                                                       neural_lr_start, neural_lr_stop, STlambda_lr, \n",
    "#                                                       neural_lr_rule, \n",
    "#                                                       neural_lr_decay_multiplier, \n",
    "#                                                       neural_dynamic_iterations_free, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c6107ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]../aten/src/ATen/native/cuda/ScatterGatherKernel.cu:276: operator(): block: [0,0,0], thread: [0,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/ScatterGatherKernel.cu:276: operator(): block: [0,0,0], thread: [2,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/ScatterGatherKernel.cu:276: operator(): block: [0,0,0], thread: [3,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/ScatterGatherKernel.cu:276: operator(): block: [0,0,0], thread: [4,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/ScatterGatherKernel.cu:276: operator(): block: [0,0,0], thread: [5,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/ScatterGatherKernel.cu:276: operator(): block: [0,0,0], thread: [6,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/ScatterGatherKernel.cu:276: operator(): block: [0,0,0], thread: [7,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/ScatterGatherKernel.cu:276: operator(): block: [0,0,0], thread: [8,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/ScatterGatherKernel.cu:276: operator(): block: [0,0,0], thread: [10,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/ScatterGatherKernel.cu:276: operator(): block: [0,0,0], thread: [11,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/ScatterGatherKernel.cu:276: operator(): block: [0,0,0], thread: [12,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/ScatterGatherKernel.cu:276: operator(): block: [0,0,0], thread: [13,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/ScatterGatherKernel.cu:276: operator(): block: [0,0,0], thread: [14,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/ScatterGatherKernel.cu:276: operator(): block: [0,0,0], thread: [15,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/ScatterGatherKernel.cu:276: operator(): block: [0,0,0], thread: [16,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/ScatterGatherKernel.cu:276: operator(): block: [0,0,0], thread: [18,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_129729/2482685486.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd_sgn\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         neurons = model.batch_step_hopfield( x, y_one_hot, hopfield_g, \n\u001b[0m\u001b[1;32m     21\u001b[0m                                              \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneural_lr_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneural_lr_stop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSTlambda_lr_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneural_lr_rule\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                                              \u001b[0mneural_lr_decay_multiplier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneural_dynamic_iterations_free\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/users/bbozkurt15/Supervised-CorInfoMax/src/ContrastiveModels.py\u001b[0m in \u001b[0;36mbatch_step_hopfield\u001b[0;34m(self, x, y, hopfield_g, lr, neural_lr_start, neural_lr_stop, STlambda_lr_list, neural_lr_rule, neural_lr_decay_multiplier, neural_dynamic_iterations_free, neural_dynamic_iterations_nudged, beta, use_three_phase, take_debug_logs, weight_decay)\u001b[0m\n\u001b[1;32m    743\u001b[0m          \u001b[0mfree_forward_info\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m          \u001b[0mfree_backward_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 745\u001b[0;31m         \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_neural_dynamics_hopfield\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneurons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhopfield_g\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneural_lr_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneural_lr_stop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSTlambda_lr_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneural_lr_rule\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    746\u001b[0m                                              neural_lr_decay_multiplier, neural_dynamic_iterations_free, 0, take_debug_logs)\n\u001b[1;32m    747\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/users/bbozkurt15/Supervised-CorInfoMax/src/ContrastiveModels.py\u001b[0m in \u001b[0;36mrun_neural_dynamics_hopfield\u001b[0;34m(self, x, y, neurons, hopfield_g, neural_lr_start, neural_lr_stop, STlambda_lr_list, lr_rule, lr_decay_multiplier, neural_dynamic_iterations, beta, take_debug_logs)\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0mmbs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             \u001b[0mSTLAMBD_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneurons\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m             \u001b[0mSTLAMBD_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTLAMBD_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/users/bbozkurt15/Supervised-CorInfoMax/src/ContrastiveModels.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0mmbs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             \u001b[0mSTLAMBD_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneurons\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m             \u001b[0mSTLAMBD_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTLAMBD_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "trn_acc_list = []\n",
    "tst_acc_list = []\n",
    "\n",
    "n_epochs = 30\n",
    "\n",
    "for epoch_ in range(n_epochs):\n",
    "    if epoch_ < 15:\n",
    "        lr = {'ff' : lr_start['ff'] * (0.95)**epoch_, 'fb' : lr_start['fb'] * (0.95)**epoch_}\n",
    "    else:\n",
    "        lr = {'ff' : lr_start['ff'] * (0.9)**epoch_, 'fb' : lr_start['fb'] * (0.9)**epoch_}\n",
    "    for idx, (x, y) in tqdm(enumerate(train_loader)):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        x = x.view(x.size(0),-1).T\n",
    "        y_one_hot = F.one_hot(y, 10).to(device).T\n",
    "        take_debug_logs_ = (idx % 500 == 0)\n",
    "        if use_random_sign_beta:\n",
    "            rnd_sgn = 2*np.random.randint(2) - 1\n",
    "            beta = rnd_sgn*beta\n",
    "            \n",
    "        neurons = model.batch_step_hopfield( x, y_one_hot, hopfield_g, \n",
    "                                             lr, neural_lr_start, neural_lr_stop, STlambda_lr_list, neural_lr_rule, \n",
    "                                             neural_lr_decay_multiplier, neural_dynamic_iterations_free,\n",
    "                                             neural_dynamic_iterations_nudged, beta, \n",
    "                                             use_three_phase, take_debug_logs_, weight_decay)\n",
    "    \n",
    "    trn_acc = evaluateContrastiveCorInfoMaxHopfieldSparse(model, test_loader, hopfield_g, neural_lr_start, \n",
    "                                                            neural_lr_stop, STlambda_lr_list, neural_lr_rule, \n",
    "                                                            neural_lr_decay_multiplier, \n",
    "                                                            neural_dynamic_iterations_free, \n",
    "                                                            device, printing = False)\n",
    "    tst_acc = evaluateContrastiveCorInfoMaxHopfieldSparse(  model, test_loader, \n",
    "                                                            hopfield_g, neural_lr_start, \n",
    "                                                            neural_lr_stop, STlambda_lr_list, \n",
    "                                                            neural_lr_rule, \n",
    "                                                            neural_lr_decay_multiplier, \n",
    "                                                            neural_dynamic_iterations_free, \n",
    "                                                            device, printing = False)\n",
    "    trn_acc_list.append(trn_acc)\n",
    "    tst_acc_list.append(tst_acc)\n",
    "    \n",
    "    print(\"Epoch : {}, Train Accuracy : {}, Test Accuracy : {}\".format(epoch_+1, trn_acc, tst_acc))\n",
    "    print(\"Layer sparsity : \", tst_sparsity_list[-1])\n",
    "    print(\"Free Information ratio: {}\".format(np.array(model.layerwise_forward_corinfo_list_free)[-1] / np.array(model.layerwise_backward_corinfo_list_free)[-1]))\n",
    "    print(\"Nudged Information ratio: {}\".format(np.array(model.layerwise_forward_corinfo_list_nudged)[-1] / np.array(model.layerwise_backward_corinfo_list_nudged)[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a655de05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def columnwise_sparsity(x, threshold = 0.01):\n",
    "    return (x < threshold).sum(0) / x.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f779a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(train_loader))\n",
    "x, y = x.to(device), y.to(device)\n",
    "\n",
    "x = x.view(x.size(0),-1).T\n",
    "y_one_hot = F.one_hot(y, 10).to(device).T\n",
    "neurons = model.init_neurons(x.size(1), device = model.device)\n",
    "\n",
    "neurons = model.run_neural_dynamics_hopfield(x, 0, neurons, hopfield_g, neural_lr_start, \n",
    "                                   neural_lr_stop, STlambda_lr_list, neural_lr_rule, \n",
    "                                   neural_lr_decay_multiplier, neural_dynamic_iterations_free, \n",
    "                                   0, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad78ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "columnwise_sparsity(neurons[0][0]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00da434d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model_weights(pickle_name = \"CorInfoTrial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3befa09",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = ContrastiveCorInfoMaxHopfieldSparse(architecture = architecture, lambda_ = lambda_, \n",
    "                                            epsilon = epsilon, activation = activation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87208d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.load_model_weights(\"CorInfoTrial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8191594",
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_acc = evaluateContrastiveCorInfoMaxHopfieldSparse(  model, test_loader, hopfield_g, neural_lr_start, \n",
    "                                                        neural_lr_stop, STlambda_lr_list, neural_lr_rule, \n",
    "                                                        neural_lr_decay_multiplier, \n",
    "                                                        neural_dynamic_iterations_free, \n",
    "                                                        device, printing = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84119c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_acc = evaluateContrastiveCorInfoMaxHopfieldSparse(  model2, test_loader, hopfield_g, neural_lr_start, \n",
    "                                                        neural_lr_stop, STlambda_lr_list, neural_lr_rule, \n",
    "                                                        neural_lr_decay_multiplier, \n",
    "                                                        neural_dynamic_iterations_free, \n",
    "                                                        device, printing = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ded4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(model.forward_backward_angles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe20a069",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_convergence_plot(trn_acc_list, xlabel = 'Number of Epochs', ylabel = 'Accuracy %',\n",
    "                      title = 'Contrastive CorInfoMax Train Accuracy w.r.t. Epochs', \n",
    "                      figsize = (12,8), fontsize = 25, linewidth = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e28c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_convergence_plot(tst_acc_list, xlabel = 'Number of Epochs', ylabel = 'Accuracy %',\n",
    "                      title = 'Contrastive CorInfoMax Test Accuracy w.r.t. Epochs', \n",
    "                      figsize = (12,8), fontsize = 25, linewidth = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8611a21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import Math, display\n",
    "# ########### LATEX Style Display Matrix ###############\n",
    "# def display_matrix(array):\n",
    "#     \"\"\"Display given numpy array with Latex format in Jupyter Notebook.\n",
    "#     Args:\n",
    "#         array (numpy array): Array to be displayed\n",
    "#     \"\"\"\n",
    "#     data = \"\"\n",
    "#     for line in array:\n",
    "#         if len(line) == 1:\n",
    "#             data += \" %.3f &\" % line + r\" \\\\\\n\"\n",
    "#             continue\n",
    "#         for element in line:\n",
    "#             data += \" %.3f &\" % element\n",
    "#         data += r\" \\\\\" + \"\\n\"\n",
    "#     display(Math(\"\\\\begin{bmatrix} \\n%s\\\\end{bmatrix}\" % data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e88fc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display_matrix(model.B[0]['weight'][:10,:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cac654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display_matrix(torch.linalg.inv(model.Rh1)[:10,:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f3192b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.norm(model.B[0]['weight'] - torch.linalg.inv(model.Rh1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865769b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display_matrix(torch.linalg.inv(model.Rh2)[:10,:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037434ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this section, we present the CorInfoMax network structure and corresponding neuronal dynamics for different selections of $\\displaystyle \\Pcal^{(k)}$. In particular, we can choose different presumed domain $\\displaystyle \\Pcal^{(k)}$ for each layer-$k$. To illustrate, consider $\\displaystyle \\Pcal^{(k)} = \\mathcal{B}_{1,+}=\\{\\rvr: \\|\\rvr\\|_1 \\leq 1, \\vzero \\leq \\rvr \\}$ that is the intersection of the $L1$ norm ball and the nonnegative orthant. To derive the network dynamics corresponding to $\\rvr^{(k)}[t]$, we consider the following constrained optimization similar to (\\ref{eq:objsysdynamics}),\n",
    "\n",
    "# \\begin{eqnarray}\n",
    "#     \\underset{\\rvr^{(k)}[t]}{\\text{maximize }} & \\Bigg( \\Bigg.\\frac{1}{2}(\\log \\det (\\hat{\\rmR}_{\\rvr^{(k)}}[t]+ \\epsilon_{k-1} \\mI)+\\log \\det (\\hat{\\rmR}_{\\rvr^{(k)}}[t]+ \\epsilon_{k} \\mI))\\nonumber\\\\  &-\\frac{1}{2\\epsilon_{k-1}}\\left\\|\\overset{\\rightarrow}{\\rve}^{(k)}[t]\\right\\|_2^2-\\frac{1}{2\\epsilon_k}\\left\\|\\overset{\\leftarrow}{\\rve}^{(k)}[t]\\right\\|_2^2\\Bigg. \\Bigg)\\label{eq:objsysdynamicsSparse}\\\\\n",
    "#     \\text{subject to} &  \\|\\rvr^{(k)}[t]\\|_1 \\le 1,\\nonumber\\\\\n",
    "#     &   \\mathbf{0}\\le \\rvr^{(k)}[t],\\nonumber\n",
    "# \\end{eqnarray}\n",
    "\n",
    "# We can write down the Lagrangian min-max problem corresponding to this optimization as \n",
    "# \\begin{eqnarray}\n",
    "# \\underset{{q}_k[t] \\ge 0}{\\text{minimize }} \n",
    "#  \\underset{\\rvr^{(k)}[t] \\ge \\vzero}{\\text{maximize }}  L(\\rvr^{(k)}[t], {q}_k[t])=O(\\rvr^{(k)}[t])+{q}_k[t](\\|\\rvr^{(k)}[t]\\|_1 - 1)\n",
    "# \\end{eqnarray}\n",
    "# where $O(\\rvr^{(k)}[t])$ is the objective in (\\ref{eq:objsysdynamicsSparse}). Following the proximal gradient update for $\\displaystyle \\rvr^{(k)}[t]$ with the gradient expression (\\ref{eq:gradrk}), we can write the output dynamics for layer-$k$ as follows, \n",
    "\n",
    "# \\begin{align}\n",
    "#     &\\tau_{\\rvu}\\frac{d \\rvu^{(k)}[t;s]}{ds}=-g_{lk}\\rvu^{(k)}[t;s]+g_{A,k}(\\rvv^{(k)}_A[t;s]-\\rvu^{(k)}[t;s])+g_{B,k}(\\rvv^{(k)}_B[t;s]-\\rvu^{(k)}[t;s]), \\nonumber%\\label{eq:hiddynamicsSparse1}\n",
    "#     \\\\\n",
    "#   &\\rvr^{(k)}[t;s]= \\text{ReLU}(\\rvu^{(k)}[t;s] - q^{(k)}[t;s]) \\nonumber, %\\label{eq:hiddynamicsSparse2}\n",
    "#   \\end{align}\n",
    "  \n",
    "# % \\begin{eqnarray}\n",
    "# %     \\tau_{\\rvu}\\frac{d \\rvu^{(k)}[t;s]}{ds}&=&-g_{lk}\\rvu^{(k)}[t;s]+\\frac{1}{\\epsilon_k}\\mM^{(k)}[t]\\vr^{(k)}[t;s]-\\frac{1}{\\epsilon_{k-1}}\\overset{\\rightarrow}{\\rve}_u^{(k)}[t;s]-\\frac{1}{\\epsilon_{k}}\\overset{\\leftarrow}{\\rve}_u^{(k)}[t;s], \\nonumber\\\\\n",
    "# %    \\overset{\\rightarrow}{\\rve}_u^{(k)}[t;s]&=&\\rvu^{(k)}[t;s]-\\mW^{(k-1)}_{ff}[t]\\rvr^{(k-1)}[t;s], \\nonumber\\\\\n",
    "# % \\overset{\\leftarrow}{\\rve}_u^{(k)}[t;s]&=&\\rvu^{(k)}[t;s]-\\mW^{(k)}_{fb}[t]\\rvr^{(k+1)}[t;s],\\nonumber\\\\\n",
    "# % \\rvr^{(k)}[t;s]&=& \\text{ReLU}(\\rvu^{(k)}[t;s] - q^{(k)}[t;s]) \\nonumber,\n",
    "# % \\end{eqnarray} \n",
    "\n",
    "# where we utilized the intermediate variable $\\displaystyle \\rvu^{(k)}$, and $\\text{ReLU}$ is the element-wise rectified linear unit.\n",
    "# The update corresponding to the Lagrangian variable $q_1[t;s]$ can be written based on the dual minimization,\n",
    "\n",
    "# \\begin{align}\n",
    "#     \\frac{d a_k[t;s]}{ds} = -a_k[t;s] + \\sum_{j = 1}^{N_k} \\rvr_j^{(k)}[t;s] - 1 + q^{(k)}[t;s], \\quad q^{(k)}[t;s] = \\text{ReLU}(a_k[t;s]) \\nonumber\n",
    "# \\end{align}\n",
    "\n",
    "# The Lagrangian variable $\\displaystyle q^{(k)}$ in the above formulation corresponds to an additional inhibition inter-neuron that takes input from the whole neurons of layer-$k$ and produces an inhibition signal."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
