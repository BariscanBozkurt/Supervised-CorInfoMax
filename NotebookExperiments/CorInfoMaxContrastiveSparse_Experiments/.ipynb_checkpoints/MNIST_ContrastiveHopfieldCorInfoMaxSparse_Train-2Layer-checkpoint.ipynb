{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89b20c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../src\")\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import glob\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "from itertools import repeat\n",
    "from torch.nn.parameter import Parameter\n",
    "import collections\n",
    "import matplotlib\n",
    "from torch_utils import *\n",
    "from ContrastiveModels import ContrastiveCorInfoMaxHopfieldSparse\n",
    "from visualization import *\n",
    "# matplotlib.use('Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef0c0a15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "128dc72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(), \n",
    "                                            torchvision.transforms.Normalize(mean=(0.0,), std=(1.0,))])\n",
    "\n",
    "mnist_dset_train = torchvision.datasets.MNIST('../../data', train=True, transform=transform, target_transform=None, download=True)\n",
    "train_loader = torch.utils.data.DataLoader(mnist_dset_train, batch_size=20, shuffle=True, num_workers=0)\n",
    "\n",
    "mnist_dset_test = torchvision.datasets.MNIST('../../data', train=False, transform=transform, target_transform=None, download=True)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_dset_test, batch_size=20, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c77e36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Best Hyperparameters so far\n",
    "# activation = hard_sigmoid\n",
    "# architecture = [784, 500, 10]\n",
    "\n",
    "# beta = 1\n",
    "# lambda_ = 0.99999\n",
    "# epsilon = 0.15\n",
    "# one_over_epsilon = 1 / epsilon\n",
    "# lr_start = {'ff' : np.array([1, 0.75]), 'fb': np.array([0.15, 0.12])}\n",
    "\n",
    "# neural_lr_start = 0.05\n",
    "# neural_lr_stop = 0.001\n",
    "# neural_lr_rule = \"constant\"\n",
    "# neural_lr_decay_multiplier = 0.01\n",
    "# neural_dynamic_iterations_nudged = 5\n",
    "# neural_dynamic_iterations_free = 30\n",
    "# hopfield_g = 0.5\n",
    "# use_random_sign_beta = True\n",
    "# use_three_phase = False\n",
    "# weight_decay = False\n",
    "\n",
    "# activation = hard_sigmoid\n",
    "# architecture = [784, 500, 10]\n",
    "\n",
    "# beta = 1\n",
    "# lambda_ = 0.999999\n",
    "# epsilon = 0.15\n",
    "# one_over_epsilon = 1 / epsilon\n",
    "# lr_start = {'ff' : np.array([0.12, 0.04]), 'fb': np.array([0.15, 0.02])}\n",
    "\n",
    "# neural_lr_start = 0.01\n",
    "# neural_lr_stop = 0.001\n",
    "# STlambda_lr_list = [0.0001, 0.000001]\n",
    "# neural_lr_rule = \"divide_by_slow_loop_index\"\n",
    "# neural_lr_decay_multiplier = 0.01\n",
    "# neural_dynamic_iterations_nudged = 10\n",
    "# neural_dynamic_iterations_free = 20\n",
    "# hopfield_g = 0.1\n",
    "# use_random_sign_beta = True\n",
    "# use_three_phase = False\n",
    "# weight_decay = False\n",
    "\n",
    "activation = hard_sigmoid\n",
    "architecture = [784, 500, 10]\n",
    "\n",
    "beta = 1\n",
    "lambda_ = 0.99999\n",
    "epsilon = 0.15\n",
    "one_over_epsilon = 1 / epsilon\n",
    "lr_start = {'ff' : np.array([1, 0.75]), 'fb': np.array([0.15, 0.12])}\n",
    "\n",
    "STlambda_lr_list = [1e-6, 0.01]\n",
    "sparse_layers = [1, 2]\n",
    "neural_lr_start = 0.05\n",
    "neural_lr_stop = 0.001\n",
    "neural_lr_rule = \"divide_by_slow_loop_index\"\n",
    "neural_lr_decay_multiplier = 0.01\n",
    "neural_dynamic_iterations_nudged = 4\n",
    "neural_dynamic_iterations_free = 20\n",
    "hopfield_g = 0.5\n",
    "use_random_sign_beta = True\n",
    "use_three_phase = False\n",
    "weight_decay = False\n",
    "\n",
    "model = ContrastiveCorInfoMaxHopfieldSparse(architecture = architecture, lambda_ = lambda_, \n",
    "                                            epsilon = epsilon, activation = activation, sparse_layers = sparse_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3448d1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = evaluateContrastiveCorInfoMaxHopfieldSparse(model, train_loader, hopfield_g,\n",
    "                                                neural_lr_start, neural_lr_stop, STlambda_lr_list, neural_lr_rule, \n",
    "                                                neural_lr_decay_multiplier, neural_dynamic_iterations_free, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89a5727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _ = evaluateContrastiveCorInfoMaxHopfieldSparse_topk( model, train_loader, hopfield_g,\n",
    "#                                                       neural_lr_start, neural_lr_stop, STlambda_lr, \n",
    "#                                                       neural_lr_rule, \n",
    "#                                                       neural_lr_decay_multiplier, \n",
    "#                                                       neural_dynamic_iterations_free, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6107ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_acc_list = []\n",
    "tst_acc_list = []\n",
    "\n",
    "n_epochs = 30\n",
    "\n",
    "for epoch_ in range(n_epochs):\n",
    "    if epoch_ < 15:\n",
    "        lr = {'ff' : lr_start['ff'] * (0.95)**epoch_, 'fb' : lr_start['fb'] * (0.95)**epoch_}\n",
    "    else:\n",
    "        lr = {'ff' : lr_start['ff'] * (0.9)**epoch_, 'fb' : lr_start['fb'] * (0.9)**epoch_}\n",
    "    for idx, (x, y) in tqdm(enumerate(train_loader)):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        x = x.view(x.size(0),-1).T\n",
    "        y_one_hot = F.one_hot(y, 10).to(device).T\n",
    "        take_debug_logs_ = (idx % 500 == 0)\n",
    "        if use_random_sign_beta:\n",
    "            rnd_sgn = 2*np.random.randint(2) - 1\n",
    "            beta = rnd_sgn*beta\n",
    "            \n",
    "        neurons = model.batch_step_hopfield( x, y_one_hot, hopfield_g, \n",
    "                                             lr, neural_lr_start, neural_lr_stop, STlambda_lr_list, neural_lr_rule, \n",
    "                                             neural_lr_decay_multiplier, neural_dynamic_iterations_free,\n",
    "                                             neural_dynamic_iterations_nudged, beta, \n",
    "                                             use_three_phase, take_debug_logs_, weight_decay)\n",
    "    \n",
    "    trn_acc = evaluateContrastiveCorInfoMaxHopfieldSparse(  model, train_loader, hopfield_g, neural_lr_start, \n",
    "                                                            neural_lr_stop, STlambda_lr_list, neural_lr_rule, \n",
    "                                                            neural_lr_decay_multiplier, \n",
    "                                                            neural_dynamic_iterations_free, \n",
    "                                                            device, printing = False)\n",
    "    tst_acc = evaluateContrastiveCorInfoMaxHopfieldSparse(  model, test_loader, hopfield_g, neural_lr_start, \n",
    "                                                            neural_lr_stop, STlambda_lr_list, neural_lr_rule, \n",
    "                                                            neural_lr_decay_multiplier, \n",
    "                                                            neural_dynamic_iterations_free, \n",
    "                                                            device, printing = False)\n",
    "    trn_acc_list.append(trn_acc)\n",
    "    tst_acc_list.append(tst_acc)\n",
    "    \n",
    "    print(\"Epoch : {}, Train Accuracy : {}, Test Accuracy : {}\".format(epoch_+1, trn_acc, tst_acc))\n",
    "    print(\"Free Information ratio: {}\".format(np.array(model.layerwise_forward_corinfo_list_free)[-1] / np.array(model.layerwise_backward_corinfo_list_free)[-1]))\n",
    "    print(\"Nudged Information ratio: {}\".format(np.array(model.layerwise_forward_corinfo_list_nudged)[-1] / np.array(model.layerwise_backward_corinfo_list_nudged)[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00da434d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model_weights(pickle_name = \"CorInfoTrial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3befa09",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = ContrastiveCorInfoMaxHopfieldSparse(architecture = architecture, lambda_ = lambda_, \n",
    "                                            epsilon = epsilon, activation = activation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87208d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.load_model_weights(\"CorInfoTrial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8191594",
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_acc = evaluateContrastiveCorInfoMaxHopfieldSparse(  model, test_loader, hopfield_g, neural_lr_start, \n",
    "                                                        neural_lr_stop, STlambda_lr_list, neural_lr_rule, \n",
    "                                                        neural_lr_decay_multiplier, \n",
    "                                                        neural_dynamic_iterations_free, \n",
    "                                                        device, printing = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84119c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_acc = evaluateContrastiveCorInfoMaxHopfieldSparse(  model2, test_loader, hopfield_g, neural_lr_start, \n",
    "                                                        neural_lr_stop, STlambda_lr_list, neural_lr_rule, \n",
    "                                                        neural_lr_decay_multiplier, \n",
    "                                                        neural_dynamic_iterations_free, \n",
    "                                                        device, printing = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ded4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(model.forward_backward_angles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe20a069",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_convergence_plot(trn_acc_list, xlabel = 'Number of Epochs', ylabel = 'Accuracy %',\n",
    "                      title = 'Contrastive CorInfoMax Train Accuracy w.r.t. Epochs', \n",
    "                      figsize = (12,8), fontsize = 25, linewidth = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e28c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_convergence_plot(tst_acc_list, xlabel = 'Number of Epochs', ylabel = 'Accuracy %',\n",
    "                      title = 'Contrastive CorInfoMax Test Accuracy w.r.t. Epochs', \n",
    "                      figsize = (12,8), fontsize = 25, linewidth = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8611a21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import Math, display\n",
    "# ########### LATEX Style Display Matrix ###############\n",
    "# def display_matrix(array):\n",
    "#     \"\"\"Display given numpy array with Latex format in Jupyter Notebook.\n",
    "#     Args:\n",
    "#         array (numpy array): Array to be displayed\n",
    "#     \"\"\"\n",
    "#     data = \"\"\n",
    "#     for line in array:\n",
    "#         if len(line) == 1:\n",
    "#             data += \" %.3f &\" % line + r\" \\\\\\n\"\n",
    "#             continue\n",
    "#         for element in line:\n",
    "#             data += \" %.3f &\" % element\n",
    "#         data += r\" \\\\\" + \"\\n\"\n",
    "#     display(Math(\"\\\\begin{bmatrix} \\n%s\\\\end{bmatrix}\" % data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e88fc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display_matrix(model.B[0]['weight'][:10,:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cac654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display_matrix(torch.linalg.inv(model.Rh1)[:10,:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f3192b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.norm(model.B[0]['weight'] - torch.linalg.inv(model.Rh1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865769b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display_matrix(torch.linalg.inv(model.Rh2)[:10,:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037434ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this section, we present the CorInfoMax network structure and corresponding neuronal dynamics for different selections of $\\displaystyle \\Pcal^{(k)}$. In particular, we can choose different presumed domain $\\displaystyle \\Pcal^{(k)}$ for each layer-$k$. To illustrate, consider $\\displaystyle \\Pcal^{(k)} = \\mathcal{B}_{1,+}=\\{\\rvr: \\|\\rvr\\|_1 \\leq 1, \\vzero \\leq \\rvr \\}$ that is the intersection of the $L1$ norm ball and the nonnegative orthant. To derive the network dynamics corresponding to $\\rvr^{(k)}[t]$, we consider the following constrained optimization similar to (\\ref{eq:objsysdynamics}),\n",
    "\n",
    "# \\begin{eqnarray}\n",
    "#     \\underset{\\rvr^{(k)}[t]}{\\text{maximize }} & \\Bigg( \\Bigg.\\frac{1}{2}(\\log \\det (\\hat{\\rmR}_{\\rvr^{(k)}}[t]+ \\epsilon_{k-1} \\mI)+\\log \\det (\\hat{\\rmR}_{\\rvr^{(k)}}[t]+ \\epsilon_{k} \\mI))\\nonumber\\\\  &-\\frac{1}{2\\epsilon_{k-1}}\\left\\|\\overset{\\rightarrow}{\\rve}^{(k)}[t]\\right\\|_2^2-\\frac{1}{2\\epsilon_k}\\left\\|\\overset{\\leftarrow}{\\rve}^{(k)}[t]\\right\\|_2^2\\Bigg. \\Bigg)\\label{eq:objsysdynamicsSparse}\\\\\n",
    "#     \\text{subject to} &  \\|\\rvr^{(k)}[t]\\|_1 \\le 1,\\nonumber\\\\\n",
    "#     &   \\mathbf{0}\\le \\rvr^{(k)}[t],\\nonumber\n",
    "# \\end{eqnarray}\n",
    "\n",
    "# We can write down the Lagrangian min-max problem corresponding to this optimization as \n",
    "# \\begin{eqnarray}\n",
    "# \\underset{{q}_k[t] \\ge 0}{\\text{minimize }} \n",
    "#  \\underset{\\rvr^{(k)}[t] \\ge \\vzero}{\\text{maximize }}  L(\\rvr^{(k)}[t], {q}_k[t])=O(\\rvr^{(k)}[t])+{q}_k[t](\\|\\rvr^{(k)}[t]\\|_1 - 1)\n",
    "# \\end{eqnarray}\n",
    "# where $O(\\rvr^{(k)}[t])$ is the objective in (\\ref{eq:objsysdynamicsSparse}). Following the proximal gradient update for $\\displaystyle \\rvr^{(k)}[t]$ with the gradient expression (\\ref{eq:gradrk}), we can write the output dynamics for layer-$k$ as follows, \n",
    "\n",
    "# \\begin{align}\n",
    "#     &\\tau_{\\rvu}\\frac{d \\rvu^{(k)}[t;s]}{ds}=-g_{lk}\\rvu^{(k)}[t;s]+g_{A,k}(\\rvv^{(k)}_A[t;s]-\\rvu^{(k)}[t;s])+g_{B,k}(\\rvv^{(k)}_B[t;s]-\\rvu^{(k)}[t;s]), \\nonumber%\\label{eq:hiddynamicsSparse1}\n",
    "#     \\\\\n",
    "#   &\\rvr^{(k)}[t;s]= \\text{ReLU}(\\rvu^{(k)}[t;s] - q^{(k)}[t;s]) \\nonumber, %\\label{eq:hiddynamicsSparse2}\n",
    "#   \\end{align}\n",
    "  \n",
    "# % \\begin{eqnarray}\n",
    "# %     \\tau_{\\rvu}\\frac{d \\rvu^{(k)}[t;s]}{ds}&=&-g_{lk}\\rvu^{(k)}[t;s]+\\frac{1}{\\epsilon_k}\\mM^{(k)}[t]\\vr^{(k)}[t;s]-\\frac{1}{\\epsilon_{k-1}}\\overset{\\rightarrow}{\\rve}_u^{(k)}[t;s]-\\frac{1}{\\epsilon_{k}}\\overset{\\leftarrow}{\\rve}_u^{(k)}[t;s], \\nonumber\\\\\n",
    "# %    \\overset{\\rightarrow}{\\rve}_u^{(k)}[t;s]&=&\\rvu^{(k)}[t;s]-\\mW^{(k-1)}_{ff}[t]\\rvr^{(k-1)}[t;s], \\nonumber\\\\\n",
    "# % \\overset{\\leftarrow}{\\rve}_u^{(k)}[t;s]&=&\\rvu^{(k)}[t;s]-\\mW^{(k)}_{fb}[t]\\rvr^{(k+1)}[t;s],\\nonumber\\\\\n",
    "# % \\rvr^{(k)}[t;s]&=& \\text{ReLU}(\\rvu^{(k)}[t;s] - q^{(k)}[t;s]) \\nonumber,\n",
    "# % \\end{eqnarray} \n",
    "\n",
    "# where we utilized the intermediate variable $\\displaystyle \\rvu^{(k)}$, and $\\text{ReLU}$ is the element-wise rectified linear unit.\n",
    "# The update corresponding to the Lagrangian variable $q_1[t;s]$ can be written based on the dual minimization,\n",
    "\n",
    "# \\begin{align}\n",
    "#     \\frac{d a_k[t;s]}{ds} = -a_k[t;s] + \\sum_{j = 1}^{N_k} \\rvr_j^{(k)}[t;s] - 1 + q^{(k)}[t;s], \\quad q^{(k)}[t;s] = \\text{ReLU}(a_k[t;s]) \\nonumber\n",
    "# \\end{align}\n",
    "\n",
    "# The Lagrangian variable $\\displaystyle q^{(k)}$ in the above formulation corresponds to an additional inhibition inter-neuron that takes input from the whole neurons of layer-$k$ and produces an inhibition signal."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
