{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89b20c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../src\")\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import glob\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "from itertools import repeat\n",
    "from torch.nn.parameter import Parameter\n",
    "import collections\n",
    "import matplotlib\n",
    "from torch_utils import *\n",
    "from ContrastiveModels import ContrastiveCorInfoMaxHopfieldSparse\n",
    "from visualization import *\n",
    "# matplotlib.use('Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef0c0a15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "128dc72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(), \n",
    "                                            torchvision.transforms.Normalize(mean=(0.0,), std=(1.0,))])\n",
    "\n",
    "mnist_dset_train = torchvision.datasets.FashionMNIST('../../data', train=True, transform=transform, target_transform=None, download=True)\n",
    "train_loader = torch.utils.data.DataLoader(mnist_dset_train, batch_size=20, shuffle=True, num_workers=0)\n",
    "\n",
    "mnist_dset_test = torchvision.datasets.FashionMNIST('../../data', train=False, transform=transform, target_transform=None, download=True)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_dset_test, batch_size=20, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c77e36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = hard_sigmoid\n",
    "architecture = [784, 500, 10]\n",
    "\n",
    "beta = 1\n",
    "lambda_ = 0.99999\n",
    "epsilon = 0.15\n",
    "one_over_epsilon = 1 / epsilon\n",
    "lr_start = {'ff' : np.array([0.35, 0.23]), 'fb': np.array([np.nan, 0.06])}\n",
    "\n",
    "STlambda_lr_list = [1e-6, 0.01]\n",
    "sparse_layers = [1, 2]\n",
    "neural_lr_start = 0.045\n",
    "neural_lr_stop = 0.001\n",
    "neural_lr_rule = \"divide_by_slow_loop_index\"\n",
    "neural_lr_decay_multiplier = 0.01\n",
    "neural_dynamic_iterations_nudged = 10\n",
    "neural_dynamic_iterations_free = 20\n",
    "hopfield_g = 0.2\n",
    "use_random_sign_beta = True\n",
    "use_three_phase = False\n",
    "weight_decay = False\n",
    "\n",
    "model = ContrastiveCorInfoMaxHopfieldSparse(architecture = architecture, lambda_ = lambda_, \n",
    "                                            epsilon = epsilon, activation = activation, sparse_layers = sparse_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3448d1d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy :\t 0.10815\n"
     ]
    }
   ],
   "source": [
    "_ = evaluateContrastiveCorInfoMaxHopfieldSparse(model, train_loader, hopfield_g,\n",
    "                                                neural_lr_start, neural_lr_stop, STlambda_lr_list, neural_lr_rule, \n",
    "                                                neural_lr_decay_multiplier, neural_dynamic_iterations_free, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6107ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [00:58, 51.27it/s]\n",
      "1it [00:00,  5.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1, Train Accuracy : 0.8259, Test Accuracy : 0.8127\n",
      "Free Information ratio: [0.04873858]\n",
      "Nudged Information ratio: [0.04873812]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [00:55, 53.87it/s]\n",
      "1it [00:00,  5.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 2, Train Accuracy : 0.8521, Test Accuracy : 0.8376\n",
      "Free Information ratio: [0.0590845]\n",
      "Nudged Information ratio: [0.05908349]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [00:58, 51.55it/s]\n",
      "1it [00:00,  5.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 3, Train Accuracy : 0.86175, Test Accuracy : 0.8475\n",
      "Free Information ratio: [0.05975243]\n",
      "Nudged Information ratio: [0.05975066]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [00:56, 52.99it/s]\n",
      "1it [00:00,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 4, Train Accuracy : 0.8638, Test Accuracy : 0.8483\n",
      "Free Information ratio: [0.06615075]\n",
      "Nudged Information ratio: [0.06614759]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [00:55, 53.84it/s]\n",
      "1it [00:00,  6.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 5, Train Accuracy : 0.8661333333333333, Test Accuracy : 0.8505\n",
      "Free Information ratio: [0.07721809]\n",
      "Nudged Information ratio: [0.07721459]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [00:56, 53.35it/s]\n",
      "1it [00:00,  5.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 6, Train Accuracy : 0.8643166666666666, Test Accuracy : 0.8505\n",
      "Free Information ratio: [0.06144955]\n",
      "Nudged Information ratio: [0.06144567]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [00:55, 53.84it/s]\n",
      "1it [00:00,  5.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 7, Train Accuracy : 0.8790166666666667, Test Accuracy : 0.8603\n",
      "Free Information ratio: [0.06212263]\n",
      "Nudged Information ratio: [0.06211893]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [00:55, 53.76it/s]\n",
      "1it [00:00,  5.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 8, Train Accuracy : 0.8657166666666667, Test Accuracy : 0.8482\n",
      "Free Information ratio: [0.05544107]\n",
      "Nudged Information ratio: [0.05543596]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [00:58, 51.65it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 9, Train Accuracy : 0.8782166666666666, Test Accuracy : 0.8605\n",
      "Free Information ratio: [0.0570869]\n",
      "Nudged Information ratio: [0.05708121]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1864it [00:55, 26.75it/s]"
     ]
    }
   ],
   "source": [
    "trn_acc_list = []\n",
    "tst_acc_list = []\n",
    "\n",
    "n_epochs = 30\n",
    "\n",
    "for epoch_ in range(n_epochs):\n",
    "    if epoch_ < 15:\n",
    "        lr = {'ff' : lr_start['ff'] * (0.95)**epoch_, 'fb' : lr_start['fb'] * (0.95)**epoch_}\n",
    "    else:\n",
    "        lr = {'ff' : lr_start['ff'] * (0.9)**epoch_, 'fb' : lr_start['fb'] * (0.9)**epoch_}\n",
    "    for idx, (x, y) in tqdm(enumerate(train_loader)):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        x = x.view(x.size(0),-1).T\n",
    "        y_one_hot = F.one_hot(y, 10).to(device).T\n",
    "        take_debug_logs_ = (idx % 500 == 0)\n",
    "        if use_random_sign_beta:\n",
    "            rnd_sgn = 2*np.random.randint(2) - 1\n",
    "            beta = rnd_sgn*beta\n",
    "            \n",
    "        neurons = model.batch_step_hopfield( x, y_one_hot, hopfield_g, \n",
    "                                             lr, neural_lr_start, neural_lr_stop, STlambda_lr_list, neural_lr_rule, \n",
    "                                             neural_lr_decay_multiplier, neural_dynamic_iterations_free,\n",
    "                                             neural_dynamic_iterations_nudged, beta, \n",
    "                                             use_three_phase, take_debug_logs_, weight_decay)\n",
    "    \n",
    "    trn_acc = evaluateContrastiveCorInfoMaxHopfieldSparse(  model, train_loader, hopfield_g, neural_lr_start, \n",
    "                                                            neural_lr_stop, STlambda_lr_list, neural_lr_rule, \n",
    "                                                            neural_lr_decay_multiplier, \n",
    "                                                            neural_dynamic_iterations_free, \n",
    "                                                            device, printing = False)\n",
    "    tst_acc = evaluateContrastiveCorInfoMaxHopfieldSparse(  model, test_loader, hopfield_g, neural_lr_start, \n",
    "                                                            neural_lr_stop, STlambda_lr_list, neural_lr_rule, \n",
    "                                                            neural_lr_decay_multiplier, \n",
    "                                                            neural_dynamic_iterations_free, \n",
    "                                                            device, printing = False)\n",
    "    trn_acc_list.append(trn_acc)\n",
    "    tst_acc_list.append(tst_acc)\n",
    "    \n",
    "    print(\"Epoch : {}, Train Accuracy : {}, Test Accuracy : {}\".format(epoch_+1, trn_acc, tst_acc))\n",
    "    print(\"Free Information ratio: {}\".format(np.array(model.layerwise_forward_corinfo_list_free)[-1] / np.array(model.layerwise_backward_corinfo_list_free)[-1]))\n",
    "    print(\"Nudged Information ratio: {}\".format(np.array(model.layerwise_forward_corinfo_list_nudged)[-1] / np.array(model.layerwise_backward_corinfo_list_nudged)[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe20a069",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_convergence_plot(trn_acc_list, xlabel = 'Number of Epochs', ylabel = 'Accuracy %',\n",
    "                      title = 'Contrastive CorInfoMax Train Accuracy w.r.t. Epochs', \n",
    "                      figsize = (12,8), fontsize = 25, linewidth = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e28c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_convergence_plot(tst_acc_list, xlabel = 'Number of Epochs', ylabel = 'Accuracy %',\n",
    "                      title = 'Contrastive CorInfoMax Test Accuracy w.r.t. Epochs', \n",
    "                      figsize = (12,8), fontsize = 25, linewidth = 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
