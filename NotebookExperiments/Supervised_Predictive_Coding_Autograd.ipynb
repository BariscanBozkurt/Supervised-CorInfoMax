{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fd7911f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import glob\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "from itertools import repeat\n",
    "from torch.nn.parameter import Parameter\n",
    "import collections\n",
    "import matplotlib\n",
    "from torch_utils import *\n",
    "from PC import *\n",
    "from visualization import *\n",
    "# matplotlib.use('Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56d87a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluatePC(model, loader, neural_lr_start, neural_lr_stop, neural_lr_rule, \n",
    "                         neural_lr_decay_multiplier,\n",
    "                         neural_dynamic_iterations, device, printing = True):\n",
    "    # Evaluate the model on a dataloader with T steps for the dynamics\n",
    "    #model.eval()\n",
    "    correct=0\n",
    "    phase = 'Train' if loader.dataset.train else 'Test'\n",
    "    \n",
    "    for x, y in loader:\n",
    "        x = activation_inverse(2*x.view(x.size(0),-1).to(device).T - 1, \"sigmoid\")\n",
    "#         x = activation_inverse(x.view(x.size(0),-1).T, \"sigmoid\").to(device)\n",
    "#         x = x.view(x.size(0),-1).T.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        neurons = model.forward(x)\n",
    "        \n",
    "#         # dynamics for T time steps\n",
    "#         neurons = model.run_neural_dynamics(x, y_one_hot, neurons, neural_lr_start, neural_lr_stop, \n",
    "#                                             neural_lr_rule,\n",
    "#                                             neural_lr_decay_multiplier, neural_dynamic_iterations, 0, \"test\")\n",
    "        pred = torch.argmax(neurons[-1], dim=0).squeeze()  # in this case prediction is done directly on the last (output) layer of neurons\n",
    "        correct += (y == pred).sum().item()\n",
    "\n",
    "    acc = correct/len(loader.dataset) \n",
    "    if printing:\n",
    "        print(phase+' accuracy :\\t', acc)   \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0481fdbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94c4836a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(), \n",
    "                                            torchvision.transforms.Normalize(mean=(0.0,), std=(1.0,))])\n",
    "\n",
    "mnist_dset_train = torchvision.datasets.MNIST('./data', train=True, transform=transform, target_transform=None, download=True)\n",
    "train_loader = torch.utils.data.DataLoader(mnist_dset_train, batch_size=20, shuffle=True, num_workers=0)\n",
    "\n",
    "mnist_dset_test = torchvision.datasets.MNIST('./data', train=False, transform=transform, target_transform=None, download=True)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_dset_test, batch_size=20, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd835cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = torch.sigmoid\n",
    "architecture = [784, 500, 500, 10]\n",
    "\n",
    "neural_lr_start = 0.1\n",
    "neural_lr_stop = 0.05\n",
    "neural_lr_rule = \"constant\"\n",
    "neural_lr_decay_multiplier = 0.01\n",
    "neural_dynamic_iterations = 50\n",
    "\n",
    "lr_start = {'ff' : 0.001}\n",
    "\n",
    "model = SupervisedPredictiveCodingV2(architecture, activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fe66593",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_params = []\n",
    "for idx in range(len(model.Wff)):\n",
    "    for key_ in [\"weight\", \"bias\"]:\n",
    "        optim_params.append(  {'params': model.Wff[idx][key_], 'lr': lr_start[\"ff\"]}  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7526f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(optim_params, maximize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e07503a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [02:49, 17.72it/s]\n",
      "2it [00:00, 16.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1, Train Accuracy : 0.9029666666666667, Test Accuracy : 0.9075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [02:50, 17.56it/s]\n",
      "2it [00:00, 15.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 2, Train Accuracy : 0.9094333333333333, Test Accuracy : 0.9101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [02:48, 17.76it/s]\n",
      "2it [00:00, 16.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 3, Train Accuracy : 0.9372833333333334, Test Accuracy : 0.937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [02:49, 17.70it/s]\n",
      "2it [00:00, 16.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 4, Train Accuracy : 0.93495, Test Accuracy : 0.9336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [02:51, 17.46it/s]\n",
      "2it [00:00, 16.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 5, Train Accuracy : 0.9492, Test Accuracy : 0.9505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [02:49, 17.69it/s]\n",
      "2it [00:00, 15.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 6, Train Accuracy : 0.9494, Test Accuracy : 0.9484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [02:49, 17.71it/s]\n",
      "2it [00:00, 15.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 7, Train Accuracy : 0.9530666666666666, Test Accuracy : 0.9513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [02:51, 17.47it/s]\n",
      "2it [00:00, 16.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 8, Train Accuracy : 0.96295, Test Accuracy : 0.9611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [02:50, 17.65it/s]\n",
      "2it [00:00, 15.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 9, Train Accuracy : 0.9626, Test Accuracy : 0.9608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [02:50, 17.64it/s]\n",
      "2it [00:00, 15.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 10, Train Accuracy : 0.9591833333333334, Test Accuracy : 0.9524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [02:52, 17.42it/s]\n",
      "2it [00:00, 16.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 11, Train Accuracy : 0.9661666666666666, Test Accuracy : 0.9606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [02:50, 17.57it/s]\n",
      "2it [00:00, 15.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 12, Train Accuracy : 0.96465, Test Accuracy : 0.9548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [02:51, 17.48it/s]\n",
      "2it [00:00, 15.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 13, Train Accuracy : 0.9678833333333333, Test Accuracy : 0.963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [02:52, 17.43it/s]\n",
      "2it [00:00, 15.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 14, Train Accuracy : 0.9655, Test Accuracy : 0.9612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [02:50, 17.58it/s]\n",
      "2it [00:00, 16.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 15, Train Accuracy : 0.9545166666666667, Test Accuracy : 0.9492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [02:50, 17.58it/s]\n",
      "2it [00:00, 15.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 16, Train Accuracy : 0.9581166666666666, Test Accuracy : 0.9548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [02:52, 17.37it/s]\n",
      "2it [00:00, 15.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 17, Train Accuracy : 0.9562333333333334, Test Accuracy : 0.9509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [02:50, 17.57it/s]\n",
      "2it [00:00, 15.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 18, Train Accuracy : 0.9292, Test Accuracy : 0.927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [02:51, 17.53it/s]\n",
      "2it [00:00, 15.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 19, Train Accuracy : 0.9459333333333333, Test Accuracy : 0.9429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [02:52, 17.36it/s]\n",
      "2it [00:00, 16.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 20, Train Accuracy : 0.9517833333333333, Test Accuracy : 0.9485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [02:50, 17.57it/s]\n",
      "2it [00:00, 15.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 21, Train Accuracy : 0.8996333333333333, Test Accuracy : 0.8952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [02:51, 17.47it/s]\n",
      "2it [00:00, 16.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 22, Train Accuracy : 0.932, Test Accuracy : 0.9312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [02:52, 17.43it/s]\n",
      "2it [00:00, 15.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 23, Train Accuracy : 0.9356833333333333, Test Accuracy : 0.9321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [02:50, 17.62it/s]\n",
      "2it [00:00, 15.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 24, Train Accuracy : 0.9248166666666666, Test Accuracy : 0.9198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [02:31, 19.86it/s]\n",
      "2it [00:00, 14.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 25, Train Accuracy : 0.9239166666666667, Test Accuracy : 0.9214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [02:17, 21.81it/s]\n",
      "2it [00:00, 14.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 26, Train Accuracy : 0.9081333333333333, Test Accuracy : 0.9081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [02:18, 21.66it/s]\n",
      "2it [00:00, 15.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 27, Train Accuracy : 0.8918166666666667, Test Accuracy : 0.8873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [02:18, 21.59it/s]\n",
      "2it [00:00, 15.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 28, Train Accuracy : 0.89995, Test Accuracy : 0.8961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [02:18, 21.62it/s]\n",
      "2it [00:00, 14.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 29, Train Accuracy : 0.9102833333333333, Test Accuracy : 0.9096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [02:18, 21.71it/s]\n",
      "2it [00:00, 15.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 30, Train Accuracy : 0.89125, Test Accuracy : 0.8913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [02:20, 21.38it/s]\n",
      "2it [00:00, 13.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 31, Train Accuracy : 0.9251333333333334, Test Accuracy : 0.9214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [02:21, 21.13it/s]\n",
      "2it [00:00, 15.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 32, Train Accuracy : 0.9272, Test Accuracy : 0.9251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [02:21, 21.20it/s]\n",
      "2it [00:00, 14.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 33, Train Accuracy : 0.8973, Test Accuracy : 0.8916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [02:22, 21.10it/s]\n",
      "2it [00:00, 14.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 34, Train Accuracy : 0.89775, Test Accuracy : 0.8998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [02:23, 20.96it/s]\n",
      "2it [00:00, 12.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 35, Train Accuracy : 0.9133666666666667, Test Accuracy : 0.9119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [02:22, 21.03it/s]\n",
      "2it [00:00, 14.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 36, Train Accuracy : 0.8977833333333334, Test Accuracy : 0.8919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [02:22, 21.03it/s]\n",
      "2it [00:00, 14.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 37, Train Accuracy : 0.9089333333333334, Test Accuracy : 0.9061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [02:18, 21.66it/s]\n",
      "2it [00:00, 15.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 38, Train Accuracy : 0.9290166666666667, Test Accuracy : 0.9254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [02:18, 21.68it/s]\n",
      "2it [00:00, 14.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 39, Train Accuracy : 0.9357833333333333, Test Accuracy : 0.9347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [02:18, 21.68it/s]\n",
      "2it [00:00, 14.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 40, Train Accuracy : 0.8966666666666666, Test Accuracy : 0.8938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [02:18, 21.67it/s]\n",
      "2it [00:00, 13.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 41, Train Accuracy : 0.8866166666666667, Test Accuracy : 0.8803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [02:18, 21.62it/s]\n",
      "2it [00:00, 14.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 42, Train Accuracy : 0.94215, Test Accuracy : 0.9394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [02:18, 21.64it/s]\n",
      "2it [00:00, 14.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 43, Train Accuracy : 0.9009, Test Accuracy : 0.8888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [02:18, 21.66it/s]\n",
      "2it [00:00, 14.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 44, Train Accuracy : 0.9351333333333334, Test Accuracy : 0.931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [02:17, 21.75it/s]\n",
      "2it [00:00, 14.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 45, Train Accuracy : 0.9378833333333333, Test Accuracy : 0.9345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [02:18, 21.66it/s]\n",
      "2it [00:00, 14.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 46, Train Accuracy : 0.9357666666666666, Test Accuracy : 0.9316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [02:18, 21.68it/s]\n",
      "2it [00:00, 14.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 47, Train Accuracy : 0.8747166666666667, Test Accuracy : 0.8744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [02:17, 21.77it/s]\n",
      "2it [00:00, 15.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 48, Train Accuracy : 0.9394833333333333, Test Accuracy : 0.9385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [02:17, 21.77it/s]\n",
      "2it [00:00, 15.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 49, Train Accuracy : 0.9047166666666666, Test Accuracy : 0.8994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [02:18, 21.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 50, Train Accuracy : 0.9436166666666667, Test Accuracy : 0.9401\n"
     ]
    }
   ],
   "source": [
    "trn_acc_list = []\n",
    "tst_acc_list = []\n",
    "\n",
    "n_epochs = 50\n",
    "lr = lr_start\n",
    "for epoch_ in range(n_epochs):\n",
    "#     lr = {'ff' : lr_start['ff'] * (0.999)**epoch_}\n",
    "    for idx, (x, y) in tqdm(enumerate(train_loader)):\n",
    "#         x = x.view(x.size(0),-1).T#.to(device)\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        x = activation_inverse(2*x.view(x.size(0),-1).T - 1, \"sigmoid\")\n",
    "#         x = activation_inverse(x.view(x.size(0),-1).T, \"sigmoid\")\n",
    "        y_one_hot = F.one_hot(y, 10).to(device).T\n",
    "        y_one_hot = 0.94 * y_one_hot + 0.03 * torch.ones(*y_one_hot.shape, device = device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        model.batch_step(  x, y_one_hot, lr, neural_lr_start, neural_lr_stop, neural_lr_rule,\n",
    "                               neural_lr_decay_multiplier, neural_dynamic_iterations,\n",
    "                               )\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "    trn_acc = evaluatePC(  model, train_loader, neural_lr_start, neural_lr_stop, neural_lr_rule, \n",
    "                           neural_lr_decay_multiplier,\n",
    "                           neural_dynamic_iterations, device, printing = False)\n",
    "    tst_acc = evaluatePC(  model, test_loader, neural_lr_start, neural_lr_stop, neural_lr_rule, \n",
    "                           neural_lr_decay_multiplier,\n",
    "                           neural_dynamic_iterations, device, printing = False)\n",
    "    trn_acc_list.append(trn_acc)\n",
    "    tst_acc_list.append(tst_acc)\n",
    "    \n",
    "    print(\"Epoch : {}, Train Accuracy : {}, Test Accuracy : {}\".format(epoch_+1, trn_acc, tst_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12ee1dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Wff_init = torch.clone(model.Wff[0]['weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2054607e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([784, 20])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y = next(iter(train_loader))\n",
    "# x = x.view(x.size(0),-1).to(device).T\n",
    "y_one_hot = F.one_hot(y, 10).to(device).T\n",
    "x = activation_inverse(x.view(x.size(0),-1).T, \"sigmoid\").to(device)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49804ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.batch_step(x, y_one_hot, lr_start, neural_lr_start, neural_lr_stop, neural_lr_rule, \n",
    "                   neural_lr_decay_multiplier, neural_dynamic_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91d93f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3386adf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0451, device='cuda:0', grad_fn=<CopyBackwards>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(model.Wff[0][\"weight\"] - Wff_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2bba3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons = model.forward(x, no_grad = False)\n",
    "neurons[-1] = y_one_hot.to(torch.float)\n",
    "neurons2 = model.run_neural_dynamics(x, y, neurons, neural_lr_start, neural_lr_stop, lr_rule = neural_lr_rule,\n",
    "                          lr_decay_multiplier = neural_lr_decay_multiplier, \n",
    "                            neural_dynamic_iterations = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26303cb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 34.6358,  36.5416,  37.6643,  ...,  35.5534,  35.6299,  34.6885],\n",
       "         [-35.7291, -34.8083, -36.8174,  ..., -34.2573, -37.4625, -33.6485],\n",
       "         [ 32.1466,  33.3480,  33.1700,  ...,  32.3953,  32.9427,  32.1870],\n",
       "         ...,\n",
       "         [-29.4734, -30.1304, -30.0850,  ..., -29.8606, -29.7603, -29.5905],\n",
       "         [-27.0878, -25.3572, -25.0104,  ..., -25.5114, -25.4776, -25.5118],\n",
       "         [-23.9726, -22.7487, -23.1222,  ..., -24.3451, -25.2882, -22.5572]],\n",
       "        device='cuda:0', requires_grad=True),\n",
       " tensor([[ 5.9757e+02,  5.9757e+02,  5.9758e+02,  ...,  5.9757e+02,\n",
       "           5.9757e+02,  5.9761e+02],\n",
       "         [ 4.7166e+02,  4.7165e+02,  4.7166e+02,  ...,  4.7166e+02,\n",
       "           4.7166e+02,  4.7168e+02],\n",
       "         [-1.9773e-01, -1.3857e-01, -1.9575e-01,  ..., -1.1359e-01,\n",
       "          -2.0894e-01, -1.2648e-01],\n",
       "         ...,\n",
       "         [-5.1652e+02, -5.1651e+02, -5.1652e+02,  ..., -5.1651e+02,\n",
       "          -5.1651e+02, -5.1655e+02],\n",
       "         [-5.2754e+02, -5.2753e+02, -5.2754e+02,  ..., -5.2754e+02,\n",
       "          -5.2754e+02, -5.2757e+02],\n",
       "         [-5.9412e+02, -5.9411e+02, -5.9412e+02,  ..., -5.9412e+02,\n",
       "          -5.9412e+02, -5.9419e+02]], device='cuda:0', requires_grad=True),\n",
       " tensor([[0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          1., 0.],\n",
       "         [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0.],\n",
       "         [1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
       "          0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
       "          0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "          0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0.],\n",
       "         [0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0.,\n",
       "          0., 1.]], device='cuda:0')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neurons2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51dce9c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., device='cuda:0', grad_fn=<CopyBackwards>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(neurons[1] - neurons2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af4a8f3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.8870e-03, -5.4945e-13, -2.8870e-03,  ..., -6.9556e-11,\n",
       "         -2.1319e-10, -3.1035e-10],\n",
       "        [-1.3245e-03, -2.1212e-13, -1.3245e-03,  ..., -3.1860e-11,\n",
       "         -5.2922e-11, -6.6940e-11],\n",
       "        [ 1.9955e-01, -1.1831e-11,  1.9955e-01,  ..., -1.2546e-10,\n",
       "          4.5661e-08, -1.2444e-08],\n",
       "        ...,\n",
       "        [ 3.5828e-03,  5.7774e-13,  3.5828e-03,  ...,  8.5537e-11,\n",
       "          4.9043e-10,  4.3372e-10],\n",
       "        [ 1.8738e-03,  3.7105e-13,  1.8738e-03,  ...,  4.5327e-11,\n",
       "          1.9336e-10,  1.2972e-10],\n",
       "        [ 3.8940e-03,  6.5016e-13,  3.8940e-03,  ...,  9.3730e-11,\n",
       "          4.0010e-10,  5.2361e-10]], device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neurons = model.forward(x)\n",
    "neurons[-1] = y_one_hot.to(torch.float)\n",
    "pc_loss = model.PC_loss(x, neurons).mean()\n",
    "pc_loss.backward()\n",
    "model.Wff[1]['weight'].grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "966153a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(22.1732, device='cuda:0')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(model.Wff[1]['weight'].grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "21bbcee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "F = 0\n",
    "Wff = model.Wff\n",
    "layers = [x] + neurons\n",
    "for jj in range(len(Wff)):\n",
    "    error = (layers[jj + 1] - (Wff[jj]['weight'] @ model.activation(layers[jj]) + Wff[jj]['bias'])) / model.variances[jj]\n",
    "    # print(error.shape, torch.sum(error * error, 0).shape)\n",
    "    F -= model.variances[jj + 1] * torch.sum(error * error, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a8f74cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'),\n",
       " tensor([[ 34.6358,  36.5416,  37.6643,  ...,  35.5534,  35.6299,  34.6885],\n",
       "         [-35.7291, -34.8083, -36.8174,  ..., -34.2573, -37.4625, -33.6485],\n",
       "         [ 32.1466,  33.3480,  33.1700,  ...,  32.3953,  32.9427,  32.1870],\n",
       "         ...,\n",
       "         [-29.4734, -30.1304, -30.0850,  ..., -29.8606, -29.7603, -29.5905],\n",
       "         [-27.0878, -25.3572, -25.0104,  ..., -25.5114, -25.4776, -25.5118],\n",
       "         [-23.9726, -22.7487, -23.1222,  ..., -24.3451, -25.2882, -22.5572]],\n",
       "        device='cuda:0', grad_fn=<AddBackward0>),\n",
       " tensor([[ 5.9757e+02,  5.9757e+02,  5.9758e+02,  ...,  5.9757e+02,\n",
       "           5.9757e+02,  5.9761e+02],\n",
       "         [ 4.7166e+02,  4.7165e+02,  4.7166e+02,  ...,  4.7166e+02,\n",
       "           4.7166e+02,  4.7168e+02],\n",
       "         [-1.7217e-01, -1.6990e-01, -1.6974e-01,  ..., -1.7094e-01,\n",
       "          -1.7154e-01, -1.8162e-01],\n",
       "         ...,\n",
       "         [-5.1652e+02, -5.1651e+02, -5.1652e+02,  ..., -5.1651e+02,\n",
       "          -5.1651e+02, -5.1655e+02],\n",
       "         [-5.2754e+02, -5.2753e+02, -5.2754e+02,  ..., -5.2754e+02,\n",
       "          -5.2754e+02, -5.2757e+02],\n",
       "         [-5.9412e+02, -5.9411e+02, -5.9412e+02,  ..., -5.9412e+02,\n",
       "          -5.9412e+02, -5.9419e+02]], device='cuda:0', grad_fn=<AddBackward0>),\n",
       " tensor([[0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          1., 0.],\n",
       "         [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0.],\n",
       "         [1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
       "          0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
       "          0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "          0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0.],\n",
       "         [0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0.,\n",
       "          0., 1.]], device='cuda:0')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "83967d18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(22.1732, device='cuda:0')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(model.Wff[1]['weight'].grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "28f09954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 34.6358,  36.5416,  37.6643,  ...,  35.5534,  35.6299,  34.6885],\n",
       "        [-35.7291, -34.8083, -36.8174,  ..., -34.2573, -37.4625, -33.6485],\n",
       "        [ 32.1466,  33.3480,  33.1700,  ...,  32.3953,  32.9427,  32.1870],\n",
       "        ...,\n",
       "        [-29.4734, -30.1304, -30.0850,  ..., -29.8606, -29.7603, -29.5905],\n",
       "        [-27.0878, -25.3572, -25.0104,  ..., -25.5114, -25.4776, -25.5118],\n",
       "        [-23.9726, -22.7487, -23.1222,  ..., -24.3451, -25.2882, -22.5572]],\n",
       "       device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neurons[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad21db09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0997,  0.0660, -0.1457,  ..., -0.1604,  0.2353,  0.0943],\n",
       "        [-0.0935,  0.0213,  0.1141,  ...,  0.0240, -0.0926, -0.2190],\n",
       "        [ 0.1823,  0.0187,  0.1770,  ..., -0.1504, -0.1178,  0.0643],\n",
       "        ...,\n",
       "        [ 0.1172,  0.1195,  0.1770,  ..., -0.1164, -0.1110, -0.3403],\n",
       "        [-0.2720,  0.0665, -0.2049,  ..., -0.0628,  0.1066, -0.2318],\n",
       "        [ 0.0061,  0.1548,  0.1897,  ...,  0.0848, -0.0991,  0.0012]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.Wff[0]['weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3e54805e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00],\n",
       "        [7.6547e-16, 7.6547e-16, 7.6547e-16,  ..., 7.6547e-16, 7.6547e-16,\n",
       "         7.6547e-16],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00],\n",
       "        ...,\n",
       "        [2.3083e-14, 2.3083e-14, 2.3083e-14,  ..., 2.3083e-14, 2.3083e-14,\n",
       "         2.3083e-14],\n",
       "        [7.6947e-07, 7.6947e-07, 7.6947e-07,  ..., 7.6947e-07, 7.6947e-07,\n",
       "         7.6947e-07],\n",
       "        [2.5572e-08, 2.5572e-08, 2.5572e-08,  ..., 2.5572e-08, 2.5572e-08,\n",
       "         2.5572e-08]], device='cuda:0')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss2 = (model.Wff[0]['weight'] @ x).sum()\n",
    "loss2.backward()\n",
    "model.Wff[0]['weight'].grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "253c2a73",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_104289/4199440700.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpc_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWff\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/bbozkurt15/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/bbozkurt15/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
     ]
    }
   ],
   "source": [
    "pc_loss.backward()\n",
    "model.Wff[0]['weight'].grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5126d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.norm(neurons[-1] - neurons2[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109c30ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons = model.forward(x, no_grad = True)\n",
    "neurons = model.run_neural_dynamics(x, y, neurons, neural_lr_start, neural_lr_stop, lr_rule = neural_lr_rule,\n",
    "                          lr_decay_multiplier = neural_lr_decay_multiplier, \n",
    "                            neural_dynamic_iterations = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03d9abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_loss = model.PC_loss(x, neurons).mean()\n",
    "pc_loss.backward()\n",
    "model.Wff[1]['weight'].grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb21854",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.norm(model.Wff[1]['weight'].grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002d448a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31578f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "F = 0\n",
    "Wff = model.Wff\n",
    "layers = [x] + neurons\n",
    "for jj in range(len(Wff)):\n",
    "    error = (layers[jj + 1] - (Wff[jj]['weight'] @ model.activation(layers[jj]) + Wff[jj]['bias'])) / model.variances[jj]\n",
    "    # print(error.shape, torch.sum(error * error, 0).shape)\n",
    "    F -= model.variances[jj + 1] * torch.sum(error * error, 0)\n",
    "    \n",
    "F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9665c811",
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons = model.forward(x)\n",
    "for jj in range(len(neurons) - 1):\n",
    "    neurons[jj] = neurons[jj].requires_grad_()\n",
    "pc_loss = model.PC_loss(x, neurons)\n",
    "init_grads = torch.tensor([1 for i in range(20)], dtype=torch.float, device=device, requires_grad=True) #Initializing gradients\n",
    "grads = torch.autograd.grad(pc_loss, neurons[:-1], grad_outputs=init_grads, create_graph=False) # dPhi/ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94637a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889e768d",
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons[1].requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2d8c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sum(error * error, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41771576",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_acc_list = []\n",
    "tst_acc_list = []\n",
    "\n",
    "n_epochs = 50\n",
    "lr = lr_start\n",
    "for epoch_ in range(n_epochs):\n",
    "#     lr = {'ff' : lr_start['ff'] * (0.999)**epoch_}\n",
    "    for idx, (x, y) in tqdm(enumerate(train_loader)):\n",
    "#         x = x.view(x.size(0),-1).T#.to(device)\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        x = activation_inverse(2*x.view(x.size(0),-1).T - 1, \"sigmoid\")\n",
    "#         x = activation_inverse(x.view(x.size(0),-1).T, \"sigmoid\")\n",
    "        y_one_hot = F.one_hot(y, 10).to(device).T\n",
    "        y_one_hot = 0.94 * y_one_hot + 0.03 * torch.ones(*y_one_hot.shape, device = device)\n",
    "        _ = model.batch_step(  x, y_one_hot, lr, neural_lr_start, neural_lr_stop, neural_lr_rule,\n",
    "                               neural_lr_decay_multiplier, neural_dynamic_iterations,\n",
    "                               optimizer = \"adam\")\n",
    "\n",
    "    trn_acc = evaluatePC(  model, train_loader, neural_lr_start, neural_lr_stop, neural_lr_rule, \n",
    "                           neural_lr_decay_multiplier,\n",
    "                           neural_dynamic_iterations, device, printing = False)\n",
    "    tst_acc = evaluatePC(  model, test_loader, neural_lr_start, neural_lr_stop, neural_lr_rule, \n",
    "                           neural_lr_decay_multiplier,\n",
    "                           neural_dynamic_iterations, device, printing = False)\n",
    "    trn_acc_list.append(trn_acc)\n",
    "    tst_acc_list.append(tst_acc)\n",
    "    \n",
    "    print(\"Epoch : {}, Train Accuracy : {}, Test Accuracy : {}\".format(epoch_+1, trn_acc, tst_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32af0328",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(train_loader))\n",
    "x, y = x.to(device), y.to(device)\n",
    "x = activation_inverse(x.view(x.size(0),-1).T, \"sigmoid\")\n",
    "y_one_hot = F.one_hot(y, 10).to(device).T\n",
    "y_one_hot = 0.94 * y_one_hot + 0.03 * torch.ones(*y_one_hot.shape, device = device)\n",
    "\n",
    "neurons = model.fast_forward(x)\n",
    "mode = \"train\"\n",
    "if mode == \"train\":\n",
    "    neurons[-1] = y_one_hot.to(torch.float)\n",
    "    \n",
    "neurons = model.run_neural_dynamics( x, y, neurons, neural_lr_start, neural_lr_stop, neural_lr_rule, \n",
    "                                            neural_lr_decay_multiplier, neural_dynamic_iterations)\n",
    "\n",
    "layers = [x] + neurons  # concatenate the input to other layers\n",
    "layers_after_activation = [list(model.activation_func(layers[jj], model.activation_type)) for jj in range(len(layers))]\n",
    "error_layers = [(layers[jj+1] - (model.Wff[jj]['weight'] @ layers_after_activation[jj][0] + model.Wff[jj]['bias'])) / model.variances[jj + 1] for jj in range(len(layers) - 1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586e76d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_layers[2].shape, layers_after_activation[2][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f543e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "(1/20) * (error_layers[jj] @ layers_after_activation[0][0].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7174cabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "jj = 0\n",
    "torch.mean(outer_prod_broadcasting(error_layers[jj].T, layers_after_activation[jj][0].T), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0a50f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_layers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb40346",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.Wff[0][\"weight\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f0b61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.Wff[0]['weight'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f49eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.activation_func(x, model.activation_type)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa96c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons = model.fast_forward(activation_func(x, \"sigmoid\")[0])\n",
    "neurons[-1] = y_one_hot.to(torch.float)\n",
    "neurons = model.run_neural_dynamics(x, y, neurons, neural_lr_start, neural_lr_stop, neural_lr_rule, \n",
    "                          neural_lr_decay_multiplier, neural_dynamic_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079682c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_acc = evaluatePC(  model, test_loader, neural_lr_start, neural_lr_stop, neural_lr_rule, \n",
    "                                 neural_lr_decay_multiplier,\n",
    "                                 neural_dynamic_iterations, device, printing = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aaa4c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "Wff = model.Wff\n",
    "Wff[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb827e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.batch_step(x, y_one_hot, lr_start, neural_lr_start, neural_lr_stop, neural_lr_rule, \n",
    "                          neural_lr_decay_multiplier, neural_dynamic_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928d0b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.Wff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf57e8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "evalua"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8019626",
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons = model.fast_forward(activation_func(x, \"sigmoid\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1d14ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_after_activation, error_layers, grads = model.calculate_neural_dynamics_grad(x, y, neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8abae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af48ee54",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(layers_after_activation), len(error_layers), len(grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12557bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_after_activation[jj + 1][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8ff5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "jj = 0\n",
    "error_layers[jj + 1].shape, model.Wff[jj + 1]['weight'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3393a286",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(layers_after_activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa5f678",
   "metadata": {},
   "outputs": [],
   "source": [
    "jj = 0\n",
    "Wff[jj]['weight'] @ layers_after_activation[jj][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29385774",
   "metadata": {},
   "outputs": [],
   "source": [
    "variances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d023f50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Wff = model.Wff\n",
    "variances = model.variances\n",
    "layers = [x] + neurons\n",
    "\n",
    "[(layers[jj+1] - (Wff[jj]['weight'] @ layers_after_activation[jj][0] + Wff[jj]['bias'])) / variances[jj + 1] for jj in range(len(layers) - 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733ecc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation_func(x, type_ = \"linear\"):\n",
    "    if type_ == \"linear\":\n",
    "        f_x = x\n",
    "        fp_x = torch.ones(*x.shape, device = x.device)\n",
    "    elif type_ == \"tanh\":\n",
    "        f_x = torch.tanh(x)\n",
    "        fp_x = torch.ones(*x.shape, device = x.device) - f_x ** 2\n",
    "    elif type_ == \"sigmoid\":\n",
    "        ones_vec = torch.ones(*x.shape, device = x.device)\n",
    "        f_x = 1 / (ones_vec + torch.exp(-x))\n",
    "        fp_x = f_x * (ones_vec - f_x)\n",
    "    elif type_ == \"relu\":\n",
    "        f_x = torch.maximum(x, torch.tensor([0], device = x.device))\n",
    "        fp_x = 1 * (x > 0)\n",
    "    elif type_ == \"exp\":\n",
    "        f_x = torch.exp(x)\n",
    "        fp_x = f_x\n",
    "    else: # Use linear\n",
    "        f_x = x\n",
    "        fp_x = torch.ones(*x.shape, device = x.device)\n",
    "        \n",
    "    return f_x, fp_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f70d42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(3,1, device = \"cuda\")\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659c95a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(3,1, device = \"cuda\")\n",
    "print(x)\n",
    "activation_func(x, type_ = \"sigmoid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0616a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5be9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "(2 * torch.rand(3, 3, requires_grad = False).to(device) - 1) * (4 * np.sqrt(6 / (3 + 3)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
