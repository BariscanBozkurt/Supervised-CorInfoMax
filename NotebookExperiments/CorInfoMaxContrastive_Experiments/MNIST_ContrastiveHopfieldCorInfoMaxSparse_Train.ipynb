{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89b20c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../src\")\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import glob\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "from itertools import repeat\n",
    "from torch.nn.parameter import Parameter\n",
    "import collections\n",
    "import matplotlib\n",
    "from torch_utils import *\n",
    "from ContrastiveModels import ContrastiveCorInfoMaxHopfieldSparse\n",
    "from visualization import *\n",
    "# matplotlib.use('Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef0c0a15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "128dc72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(), \n",
    "                                            torchvision.transforms.Normalize(mean=(0.0,), std=(1.0,))])\n",
    "\n",
    "mnist_dset_train = torchvision.datasets.MNIST('../../data', train=True, transform=transform, target_transform=None, download=True)\n",
    "train_loader = torch.utils.data.DataLoader(mnist_dset_train, batch_size=20, shuffle=True, num_workers=0)\n",
    "\n",
    "mnist_dset_test = torchvision.datasets.MNIST('../../data', train=False, transform=transform, target_transform=None, download=True)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_dset_test, batch_size=20, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c77e36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Best Hyperparameters so far\n",
    "# activation = hard_sigmoid\n",
    "# architecture = [784, 500, 10]\n",
    "\n",
    "# beta = 1\n",
    "# lambda_ = 0.99999\n",
    "# epsilon = 0.15\n",
    "# one_over_epsilon = 1 / epsilon\n",
    "# lr_start = {'ff' : np.array([1, 0.75]), 'fb': np.array([0.15, 0.12])}\n",
    "\n",
    "# neural_lr_start = 0.05\n",
    "# neural_lr_stop = 0.001\n",
    "# neural_lr_rule = \"constant\"\n",
    "# neural_lr_decay_multiplier = 0.01\n",
    "# neural_dynamic_iterations_nudged = 5\n",
    "# neural_dynamic_iterations_free = 30\n",
    "# hopfield_g = 0.5\n",
    "# use_random_sign_beta = True\n",
    "# use_three_phase = False\n",
    "# weight_decay = False\n",
    "\n",
    "activation = hard_sigmoid\n",
    "architecture = [784, 500, 10]\n",
    "\n",
    "beta = 1\n",
    "lambda_ = 0.99999\n",
    "epsilon = 0.15\n",
    "one_over_epsilon = 1 / epsilon\n",
    "lr_start = {'ff' : np.array([0.5, 0.25]), 'fb': np.array([0.15, 0.1])}\n",
    "\n",
    "neural_lr_start = 0.1\n",
    "neural_lr_stop = 0.001\n",
    "STlambda_lr = 0.001\n",
    "neural_lr_rule = \"divide_by_slow_loop_index\"\n",
    "neural_lr_decay_multiplier = 0.01\n",
    "neural_dynamic_iterations_nudged = 10\n",
    "neural_dynamic_iterations_free = 30\n",
    "hopfield_g = 0.25\n",
    "use_random_sign_beta = True\n",
    "use_three_phase = False\n",
    "weight_decay = False\n",
    "\n",
    "\n",
    "model = ContrastiveCorInfoMaxHopfieldSparse(architecture = architecture, lambda_ = lambda_, \n",
    "                                            epsilon = epsilon, activation = activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3448d1d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy :\t 0.08503333333333334\n"
     ]
    }
   ],
   "source": [
    "_ = evaluateContrastiveCorInfoMaxHopfieldSparse(model, train_loader, hopfield_g,\n",
    "                                          neural_lr_start, neural_lr_stop, STlambda_lr, neural_lr_rule, \n",
    "                                          neural_lr_decay_multiplier, neural_dynamic_iterations_free, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c89a5727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy :\t [0.08503333]\n"
     ]
    }
   ],
   "source": [
    "_ = evaluateContrastiveCorInfoMaxHopfieldSparse_topk( model, train_loader, hopfield_g,\n",
    "                                                      neural_lr_start, neural_lr_stop, STlambda_lr, \n",
    "                                                      neural_lr_rule, \n",
    "                                                      neural_lr_decay_multiplier, \n",
    "                                                      neural_dynamic_iterations_free, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c6107ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [02:47, 17.95it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1, Train Accuracy : 0.8909166666666667, Test Accuracy : 0.8981\n",
      "Free Information ratio: [0.07272815]\n",
      "Nudged Information ratio: [0.07272758]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [02:40, 18.68it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 2, Train Accuracy : 0.9481666666666667, Test Accuracy : 0.9471\n",
      "Free Information ratio: [0.0827662]\n",
      "Nudged Information ratio: [0.08276522]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [03:01, 16.55it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 3, Train Accuracy : 0.9616, Test Accuracy : 0.9575\n",
      "Free Information ratio: [0.08089834]\n",
      "Nudged Information ratio: [0.08089676]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [02:24, 20.76it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 4, Train Accuracy : 0.967, Test Accuracy : 0.9624\n",
      "Free Information ratio: [0.07931589]\n",
      "Nudged Information ratio: [0.07931417]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [02:44, 18.20it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 5, Train Accuracy : 0.9700166666666666, Test Accuracy : 0.9644\n",
      "Free Information ratio: [0.06716541]\n",
      "Nudged Information ratio: [0.06716334]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [02:49, 17.70it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 6, Train Accuracy : 0.9744833333333334, Test Accuracy : 0.9692\n",
      "Free Information ratio: [0.06529249]\n",
      "Nudged Information ratio: [0.06529031]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [02:42, 18.44it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 7, Train Accuracy : 0.9767333333333333, Test Accuracy : 0.9709\n",
      "Free Information ratio: [0.05807787]\n",
      "Nudged Information ratio: [0.05807549]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [03:03, 16.34it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 8, Train Accuracy : 0.9773833333333334, Test Accuracy : 0.9714\n",
      "Free Information ratio: [0.05644403]\n",
      "Nudged Information ratio: [0.05644168]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [02:31, 19.75it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 9, Train Accuracy : 0.9782333333333333, Test Accuracy : 0.971\n",
      "Free Information ratio: [0.06421381]\n",
      "Nudged Information ratio: [0.0642115]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [03:08, 15.93it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 10, Train Accuracy : 0.9794833333333334, Test Accuracy : 0.9725\n",
      "Free Information ratio: [0.0579295]\n",
      "Nudged Information ratio: [0.05792695]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [02:24, 20.75it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 11, Train Accuracy : 0.9808833333333333, Test Accuracy : 0.9741\n",
      "Free Information ratio: [0.0430798]\n",
      "Nudged Information ratio: [0.04307673]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [03:08, 15.95it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 12, Train Accuracy : 0.9795833333333334, Test Accuracy : 0.971\n",
      "Free Information ratio: [0.04320855]\n",
      "Nudged Information ratio: [0.04320554]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [02:24, 20.74it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 13, Train Accuracy : 0.9815833333333334, Test Accuracy : 0.9732\n",
      "Free Information ratio: [0.04316537]\n",
      "Nudged Information ratio: [0.04316242]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [03:08, 15.91it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 14, Train Accuracy : 0.98155, Test Accuracy : 0.9729\n",
      "Free Information ratio: [0.03674217]\n",
      "Nudged Information ratio: [0.03673954]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [02:24, 20.75it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 15, Train Accuracy : 0.9820166666666666, Test Accuracy : 0.972\n",
      "Free Information ratio: [0.03948595]\n",
      "Nudged Information ratio: [0.03948346]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [03:03, 16.31it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 16, Train Accuracy : 0.9820833333333333, Test Accuracy : 0.9729\n",
      "Free Information ratio: [0.03793857]\n",
      "Nudged Information ratio: [0.03793596]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [02:32, 19.69it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 17, Train Accuracy : 0.9817833333333333, Test Accuracy : 0.9713\n",
      "Free Information ratio: [0.03596206]\n",
      "Nudged Information ratio: [0.03595957]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [03:06, 16.12it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 18, Train Accuracy : 0.9816, Test Accuracy : 0.9703\n",
      "Free Information ratio: [0.03212943]\n",
      "Nudged Information ratio: [0.03212662]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [02:43, 18.33it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 19, Train Accuracy : 0.9811666666666666, Test Accuracy : 0.9701\n",
      "Free Information ratio: [0.02837979]\n",
      "Nudged Information ratio: [0.02837744]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [02:55, 17.08it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 20, Train Accuracy : 0.9810166666666666, Test Accuracy : 0.9711\n",
      "Free Information ratio: [0.02959819]\n",
      "Nudged Information ratio: [0.02959573]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [02:54, 17.22it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 21, Train Accuracy : 0.9802666666666666, Test Accuracy : 0.9698\n",
      "Free Information ratio: [0.02998589]\n",
      "Nudged Information ratio: [0.02998344]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [02:44, 18.22it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 22, Train Accuracy : 0.9807333333333333, Test Accuracy : 0.9707\n",
      "Free Information ratio: [0.02492137]\n",
      "Nudged Information ratio: [0.02491908]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [03:04, 16.24it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 23, Train Accuracy : 0.9802, Test Accuracy : 0.97\n",
      "Free Information ratio: [0.02311184]\n",
      "Nudged Information ratio: [0.02310976]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [02:34, 19.45it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 24, Train Accuracy : 0.9799, Test Accuracy : 0.9699\n",
      "Free Information ratio: [0.02121543]\n",
      "Nudged Information ratio: [0.02121329]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [03:08, 15.90it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 25, Train Accuracy : 0.9797666666666667, Test Accuracy : 0.9686\n",
      "Free Information ratio: [0.0212251]\n",
      "Nudged Information ratio: [0.021223]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [02:24, 20.71it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 26, Train Accuracy : 0.97945, Test Accuracy : 0.9694\n",
      "Free Information ratio: [0.01636603]\n",
      "Nudged Information ratio: [0.01636404]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [03:07, 16.00it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 27, Train Accuracy : 0.9796, Test Accuracy : 0.9697\n",
      "Free Information ratio: [0.01507299]\n",
      "Nudged Information ratio: [0.01507103]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [02:25, 20.67it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 28, Train Accuracy : 0.97895, Test Accuracy : 0.9696\n",
      "Free Information ratio: [0.01747392]\n",
      "Nudged Information ratio: [0.01747176]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [03:08, 15.89it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 29, Train Accuracy : 0.9786833333333333, Test Accuracy : 0.9686\n",
      "Free Information ratio: [0.01603772]\n",
      "Nudged Information ratio: [0.01603576]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [02:25, 20.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 30, Train Accuracy : 0.9786666666666667, Test Accuracy : 0.9695\n",
      "Free Information ratio: [0.01928197]\n",
      "Nudged Information ratio: [0.01927981]\n"
     ]
    }
   ],
   "source": [
    "trn_acc_list = []\n",
    "tst_acc_list = []\n",
    "\n",
    "n_epochs = 30\n",
    "\n",
    "for epoch_ in range(n_epochs):\n",
    "    lr = {'ff' : lr_start['ff'] * (0.95)**epoch_, 'fb' : lr_start['fb'] * (0.95)**epoch_}\n",
    "    for idx, (x, y) in tqdm(enumerate(train_loader)):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        x = x.view(x.size(0),-1).T\n",
    "        y_one_hot = F.one_hot(y, 10).to(device).T\n",
    "        take_debug_logs_ = (idx % 500 == 0)\n",
    "        if use_random_sign_beta:\n",
    "            rnd_sgn = 2*np.random.randint(2) - 1\n",
    "            beta = rnd_sgn*beta\n",
    "            \n",
    "        neurons = model.batch_step_hopfield( x, y_one_hot, hopfield_g, \n",
    "                                             lr, neural_lr_start, neural_lr_stop, STlambda_lr, neural_lr_rule, \n",
    "                                             neural_lr_decay_multiplier, neural_dynamic_iterations_free,\n",
    "                                             neural_dynamic_iterations_nudged, beta, \n",
    "                                             use_three_phase, take_debug_logs_, weight_decay)\n",
    "    \n",
    "    trn_acc = evaluateContrastiveCorInfoMaxHopfieldSparse(  model, train_loader, hopfield_g, neural_lr_start, \n",
    "                                                            neural_lr_stop, STlambda_lr, neural_lr_rule, \n",
    "                                                            neural_lr_decay_multiplier, \n",
    "                                                            neural_dynamic_iterations_free, \n",
    "                                                            device, printing = False)\n",
    "    tst_acc = evaluateContrastiveCorInfoMaxHopfieldSparse(  model, test_loader, hopfield_g, neural_lr_start, \n",
    "                                                            neural_lr_stop, STlambda_lr, neural_lr_rule, \n",
    "                                                            neural_lr_decay_multiplier, \n",
    "                                                            neural_dynamic_iterations_free, \n",
    "                                                            device, printing = False)\n",
    "    trn_acc_list.append(trn_acc)\n",
    "    tst_acc_list.append(tst_acc)\n",
    "    \n",
    "    print(\"Epoch : {}, Train Accuracy : {}, Test Accuracy : {}\".format(epoch_+1, trn_acc, tst_acc))\n",
    "    print(\"Free Information ratio: {}\".format(np.array(model.layerwise_forward_corinfo_list_free)[-1] / np.array(model.layerwise_backward_corinfo_list_free)[-1]))\n",
    "    print(\"Nudged Information ratio: {}\".format(np.array(model.layerwise_forward_corinfo_list_nudged)[-1] / np.array(model.layerwise_backward_corinfo_list_nudged)[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00da434d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model_weights(pickle_name = \"CorInfoTrial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3befa09",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = ContrastiveCorInfoMaxHopfieldSparse(architecture = architecture, lambda_ = lambda_, \n",
    "                                            epsilon = epsilon, activation = activation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87208d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.load_model_weights(\"CorInfoTrial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8191594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy :\t 0.9695\n"
     ]
    }
   ],
   "source": [
    "tst_acc = evaluateContrastiveCorInfoMaxHopfieldSparse(  model, test_loader, hopfield_g, neural_lr_start, \n",
    "                                                        neural_lr_stop, STlambda_lr, neural_lr_rule, \n",
    "                                                        neural_lr_decay_multiplier, \n",
    "                                                        neural_dynamic_iterations_free, \n",
    "                                                        device, printing = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac2f990f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def topk_accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"\n",
    "    Computes the accuracy over the k top predictions for the specified values of k\n",
    "    Modified from: https://github.com/EPFL-LCN/pub-illing2021-neurips/blob/b66061eddaec9d9f41213c3640d3f0961d13cc7b/vision/CLAPPVision/utils/utils.py\n",
    "    output shape = (number of classes, batch size)\n",
    "    target size = (batch size)\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 0, True, True)\n",
    "        \n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "        correct_k_list = []\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
    "            correct_k_list.append(correct_k.item())\n",
    "            res.append(correct_k.mul(1.0 / batch_size).item())\n",
    "        return np.array(res), np.array(correct_k_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8dec7e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topk = (1,2)\n",
    "np.zeros(len(topk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bec40c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateContrastiveCorInfoMaxHopfieldSparse_topk(model, loader, hopfield_g, neural_lr_start, neural_lr_stop, STlambda_lr,\n",
    "                                                     neural_lr_rule, neural_lr_decay_multiplier,\n",
    "                                                     T, device, topk = (1,), printing = True):\n",
    "    # Evaluate the Contrastive CorInfoMax Hopfield model on a dataloader with T steps for the dynamics for the classification task\n",
    "    correct = np.zeros(len(topk))\n",
    "    phase = 'Train' if loader.dataset.train else 'Test'\n",
    "    \n",
    "    for x, y in loader:\n",
    "        x = x.view(x.size(0),-1).to(device).T\n",
    "        y = y.to(device)\n",
    "        \n",
    "        neurons = model.init_neurons(x.size(1), device = model.device)\n",
    "        \n",
    "        # dynamics for T time steps\n",
    "        neurons, _, _ = model.run_neural_dynamics_hopfield(x, 0, neurons, hopfield_g, neural_lr_start, neural_lr_stop, STlambda_lr, neural_lr_rule, neural_lr_decay_multiplier, T, beta = 0) \n",
    "        \n",
    "        # pred = torch.argmax(neurons[-1], dim=0).squeeze()  # in this case prediction is done directly on the last (output) layer of neurons\n",
    "        correct += topk_accuracy(neurons[-1], y, topk)[1]\n",
    "\n",
    "    acc = correct/len(loader.dataset) \n",
    "    if printing:\n",
    "        print(phase+' accuracy :\\t', acc)   \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ca306ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy :\t [0.9695 0.9871]\n"
     ]
    }
   ],
   "source": [
    "tst_acc = evaluateContrastiveCorInfoMaxHopfieldSparse_topk( model2, test_loader, hopfield_g, neural_lr_start, \n",
    "                                                            neural_lr_stop, STlambda_lr, neural_lr_rule, \n",
    "                                                            neural_lr_decay_multiplier, \n",
    "                                                            neural_dynamic_iterations_free, \n",
    "                                                            device, topk = (1,2), printing = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d664b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def topk_accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"\n",
    "    Computes the accuracy over the k top predictions for the specified values of k\n",
    "    Modified from: https://github.com/EPFL-LCN/pub-illing2021-neurips/blob/b66061eddaec9d9f41213c3640d3f0961d13cc7b/vision/CLAPPVision/utils/utils.py\n",
    "    output shape = (number of classes, batch size)\n",
    "    target size = (batch size)\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 0, True, True)\n",
    "        \n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul(1.0 / batch_size).item())\n",
    "        return np.array(res), correct_k.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63ce88f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 1.]), 20.0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(iter(train_loader))\n",
    "x, y = x.to(device), y.to(device)\n",
    "x = x.view(x.size(0),-1).T\n",
    "y_one_hot = F.one_hot(y, 10).to(device).T\n",
    "\n",
    "neurons = model.init_neurons(x.size(1), device = model.device)\n",
    "T = neural_dynamic_iterations_free\n",
    "neurons, _, _ = model.run_neural_dynamics_hopfield(x, 0, neurons, hopfield_g, \n",
    "                                                   neural_lr_start, neural_lr_stop, \n",
    "                                                   STlambda_lr, neural_lr_rule, \n",
    "                                                   neural_lr_decay_multiplier, \n",
    "                                                   T, beta = 0) \n",
    "topk_accuracy_, correct = topk_accuracy(neurons[-1], y, (1,2)) \n",
    "topk_accuracy_, correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a988564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c644bed",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'sum'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_70406/2407424277.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcorrect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'sum'"
     ]
    }
   ],
   "source": [
    "correct.sum(0).sum() / 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b275088d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.argmax(neurons[-1], dim=0).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29576ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "topk = (1,2)\n",
    "target = y\n",
    "output = neurons[-1]\n",
    "\n",
    "maxk = max(topk)\n",
    "batch_size = target.size(0)\n",
    "\n",
    "_, pred = output.topk(maxk, 0, True, True)\n",
    "# pred = pred.t()\n",
    "\n",
    "correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "res = []\n",
    "for k in topk:\n",
    "    correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
    "    res.append(correct_k.mul_(100.0 / batch_size).item())\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ce8e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.shape, output.shape, correct.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f070e21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Wff_save = []\n",
    "for idx in range(len(model.Wff)):\n",
    "    weight, bias = torch2numpy(model.Wff[idx]['weight']), torch2numpy(model.Wff[idx]['bias'])\n",
    "    Wff_save.append({'weight': weight, 'bias': bias})\n",
    "    \n",
    "Wfb_save = []\n",
    "for idx in range(len(model.Wfb)):\n",
    "    weight = torch2numpy(model.Wfb[idx]['weight'])\n",
    "    Wfb_save.append({'weight': weight})\n",
    "    \n",
    "B_save = []\n",
    "for idx in range(len(model.B)):\n",
    "    weight = torch2numpy(model.B[idx]['weight'])\n",
    "    B_save.append({'weight': weight})\n",
    "    \n",
    "model_params = pd.DataFrame(columns = ['Wff', 'Wfb', 'B'])\n",
    "\n",
    "model_params['Wff'] = Wff_save\n",
    "model_params['Wfb'] = Wfb_save\n",
    "model_params['B'] = B_save\n",
    "\n",
    "model_params.to_pickle(\"model_save_trial\" + \".pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b375bdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e96d3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params_load = pd.read_pickle(\"model_save_trial\" + \".pkl\")\n",
    "\n",
    "model2 = ContrastiveCorInfoMaxHopfieldSparse(architecture = architecture, lambda_ = lambda_, \n",
    "                                            epsilon = epsilon, activation = activation)\n",
    "\n",
    "for idx in range(len(model2.Wff)):\n",
    "    model2.Wff[idx]['weight'] = torch.tensor(model_params_load['Wff'].iloc[idx]['weight'], requires_grad = False).to(model2.device)\n",
    "    model2.Wff[idx]['bias'] = torch.tensor(model_params_load['Wff'].iloc[idx]['bias'], requires_grad = False).to(model2.device)\n",
    "    \n",
    "for idx in range(len(model2.Wfb)):\n",
    "    model2.Wfb[idx]['weight'] = torch.tensor(model_params_load['Wfb'].iloc[idx]['weight'], requires_grad = False).to(model2.device)\n",
    "       \n",
    "for idx in range(len(model2.B)):\n",
    "    model2.B[idx]['weight'] = torch.tensor(model_params_load['B'].iloc[idx]['weight'], requires_grad = False).to(model2.device)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254f2833",
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_acc = evaluateContrastiveCorInfoMaxHopfieldSparse(  model, test_loader, hopfield_g, neural_lr_start, \n",
    "                                                        neural_lr_stop, STlambda_lr, neural_lr_rule, \n",
    "                                                        neural_lr_decay_multiplier, \n",
    "                                                        neural_dynamic_iterations_free, \n",
    "                                                        device, printing = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10134999",
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_acc = evaluateContrastiveCorInfoMaxHopfieldSparse(  model2, test_loader, hopfield_g, neural_lr_start, \n",
    "                                                        neural_lr_stop, STlambda_lr, neural_lr_rule, \n",
    "                                                        neural_lr_decay_multiplier, \n",
    "                                                        neural_dynamic_iterations_free, \n",
    "                                                        device, printing = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834879bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = pd.DataFrame(columns = ['Wff', 'Wfb', 'B', 'epsilon', 'lambda_'])\n",
    "model_params['Wff'] = model.Wff\n",
    "model_params['Wfb'] = model.Wfb\n",
    "model_params['B'] = model.B\n",
    "model_params['epsilon'] = model.epsilon\n",
    "model_params['lambda_'] = model.lambda_\n",
    "\n",
    "model_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe20a069",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_convergence_plot(trn_acc_list, xlabel = 'Number of Epochs', ylabel = 'Accuracy %',\n",
    "                      title = 'Contrastive CorInfoMax Train Accuracy w.r.t. Epochs', \n",
    "                      figsize = (12,8), fontsize = 25, linewidth = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e28c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_convergence_plot(tst_acc_list, xlabel = 'Number of Epochs', ylabel = 'Accuracy %',\n",
    "                      title = 'Contrastive CorInfoMax Test Accuracy w.r.t. Epochs', \n",
    "                      figsize = (12,8), fontsize = 25, linewidth = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8611a21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import Math, display\n",
    "# ########### LATEX Style Display Matrix ###############\n",
    "# def display_matrix(array):\n",
    "#     \"\"\"Display given numpy array with Latex format in Jupyter Notebook.\n",
    "#     Args:\n",
    "#         array (numpy array): Array to be displayed\n",
    "#     \"\"\"\n",
    "#     data = \"\"\n",
    "#     for line in array:\n",
    "#         if len(line) == 1:\n",
    "#             data += \" %.3f &\" % line + r\" \\\\\\n\"\n",
    "#             continue\n",
    "#         for element in line:\n",
    "#             data += \" %.3f &\" % element\n",
    "#         data += r\" \\\\\" + \"\\n\"\n",
    "#     display(Math(\"\\\\begin{bmatrix} \\n%s\\\\end{bmatrix}\" % data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e88fc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display_matrix(model.B[0]['weight'][:10,:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cac654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display_matrix(torch.linalg.inv(model.Rh1)[:10,:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f3192b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.norm(model.B[0]['weight'] - torch.linalg.inv(model.Rh1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865769b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display_matrix(torch.linalg.inv(model.Rh2)[:10,:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
