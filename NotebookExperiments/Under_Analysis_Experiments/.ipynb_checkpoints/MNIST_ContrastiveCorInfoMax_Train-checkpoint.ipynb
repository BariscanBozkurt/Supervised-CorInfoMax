{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89b20c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../src\")\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import glob\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "from itertools import repeat\n",
    "from torch.nn.parameter import Parameter\n",
    "import collections\n",
    "import matplotlib\n",
    "from torch_utils import *\n",
    "from ContrastiveModels import *\n",
    "from visualization import *\n",
    "# matplotlib.use('Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef0c0a15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "128dc72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(), \n",
    "                                            torchvision.transforms.Normalize(mean=(0.0,), std=(1.0,))])\n",
    "\n",
    "mnist_dset_train = torchvision.datasets.MNIST('../../data', train=True, transform=transform, target_transform=None, download=True)\n",
    "train_loader = torch.utils.data.DataLoader(mnist_dset_train, batch_size=20, shuffle=True, num_workers=0)\n",
    "\n",
    "mnist_dset_test = torchvision.datasets.MNIST('../../data', train=False, transform=transform, target_transform=None, download=True)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_dset_test, batch_size=20, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c77e36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = hard_sigmoid\n",
    "architecture = [784, 500, 10]\n",
    "\n",
    "x,y = next(iter(train_loader))\n",
    "x = x.view(x.size(0),-1).to(device).T\n",
    "y_one_hot = F.one_hot(y, 10).to(device).T\n",
    "\n",
    "beta = 1\n",
    "lambda_ = 0.9999\n",
    "epsilon = 0.15\n",
    "one_over_epsilon = 1 / epsilon\n",
    "lr_start = {'ff' : np.array([0.275, 0.1]), 'fb': np.array([0.05, 0.01])}\n",
    "\n",
    "neural_lr_start = 0.05\n",
    "neural_lr_stop = 0.001\n",
    "neural_lr_rule = \"constant\"\n",
    "neural_lr_decay_multiplier = 0.01\n",
    "neural_dynamic_iterations_nudged = 10\n",
    "neural_dynamic_iterations_free = 20\n",
    "hopfield_g = 0.01\n",
    "model = ContrastiveCorInfoMax(architecture = architecture, lambda_ = lambda_, \n",
    "                              epsilon = epsilon, activation = activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "121ce866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x, y = next(iter(train_loader))\n",
    "# x, y = x.to(device), y.to(device)\n",
    "# x = x.view(x.size(0),-1).T\n",
    "# y_one_hot = F.one_hot(y, 10).to(device).T\n",
    "# hopfield_g = 0.01\n",
    "# neurons = model.init_neurons(x.size(1), device = model.device)\n",
    "# model.run_neural_dynamics_hopfield(x, y, neurons, hopfield_g, neural_lr_start, neural_lr_stop,\n",
    "#                                    neural_lr_rule, neural_lr_decay_multiplier, \n",
    "#                                    neural_dynamic_iterations_nudged, beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae2a3035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x, y = next(iter(train_loader))\n",
    "# x, y = x.to(device), y.to(device)\n",
    "# x = x.view(x.size(0),-1).T\n",
    "# y_one_hot = F.one_hot(y, 10).to(device).T\n",
    "\n",
    "# neurons = model.fast_forward(x)\n",
    "# neurons1 = neurons.copy()\n",
    "# layers_free = [x] + neurons1\n",
    "# Wff = model.Wff\n",
    "# forward_errors_free = [layers_free[jj + 1] - model.activation(Wff[jj]['weight'] @ layers_free[jj] + Wff[jj]['bias']) for jj in range(len(Wff))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3448d1d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy :\t 0.165\n"
     ]
    }
   ],
   "source": [
    "_ = evaluateContrastiveCorInfoMax(model, train_loader, neural_lr_start, neural_lr_stop, neural_lr_rule, \n",
    "                                  neural_lr_decay_multiplier, neural_dynamic_iterations_free, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c6107ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'neural_lr' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_39101/3549942399.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd_sgn\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         neurons = model.batch_step_hopfield(  x, y_one_hot, lr, neural_lr_start, neural_lr_stop, neural_lr_rule, \n\u001b[0m\u001b[1;32m     17\u001b[0m                                      \u001b[0mneural_lr_decay_multiplier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneural_dynamic_iterations_free\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                                      neural_dynamic_iterations_nudged, beta)\n",
      "\u001b[0;32m/scratch/users/bbozkurt15/Supervised-CorInfoMax/src/ContrastiveModels.py\u001b[0m in \u001b[0;36mbatch_step_hopfield\u001b[0;34m(self, x, y, lr, neural_lr_start, neural_lr_stop, neural_lr_rule, neural_lr_decay_multiplier, neural_dynamic_iterations_free, neural_dynamic_iterations_nudged, beta)\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;31m# self.B = B\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 546\u001b[0;31m         neurons = self.run_neural_dynamics_hopfield(x, y, neurons, neural_lr_start, neural_lr_stop, neural_lr_rule, \n\u001b[0m\u001b[1;32m    547\u001b[0m                                            neural_lr_decay_multiplier, neural_dynamic_iterations_nudged, beta)\n\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/users/bbozkurt15/Supervised-CorInfoMax/src/ContrastiveModels.py\u001b[0m in \u001b[0;36mrun_neural_dynamics_hopfield\u001b[0;34m(self, x, y, neurons, hopfield_g, neural_lr_start, neural_lr_stop, lr_rule, lr_decay_multiplier, neural_dynamic_iterations, beta)\u001b[0m\n\u001b[1;32m    453\u001b[0m                         \u001b[0mapical_voltage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgam_\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mjj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mjj\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mhopfield_g\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mjj\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mWfb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mjj\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mjj\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m                         \u001b[0mgradient_neurons\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mhopfield_g\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mneurons_intermediate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mjj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mone_over_epsilon\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbasal_voltage\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mneurons_intermediate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mjj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mone_over_epsilon\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mapical_voltage\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mneurons_intermediate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mjj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m                         \u001b[0mneurons_intermediate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mjj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneurons_intermediate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mjj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mneural_lr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgradient_neurons\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m                         \u001b[0mneurons\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mjj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneurons_intermediate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mjj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m                     \u001b[0mlayers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mneurons\u001b[0m  \u001b[0;31m# concatenate the input to other layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'neural_lr' referenced before assignment"
     ]
    }
   ],
   "source": [
    "trn_acc_list = []\n",
    "tst_acc_list = []\n",
    "\n",
    "n_epochs = 25\n",
    "\n",
    "for epoch_ in range(n_epochs):\n",
    "    lr = {'ff' : lr_start['ff'] * (0.99)**epoch_, 'fb' : lr_start['fb'] * (0.99)**epoch_}\n",
    "    for idx, (x, y) in tqdm(enumerate(train_loader)):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        x = x.view(x.size(0),-1).T\n",
    "        y_one_hot = F.one_hot(y, 10).to(device).T\n",
    "        if True:\n",
    "            rnd_sgn = 2*np.random.randint(2) - 1\n",
    "            beta = rnd_sgn*beta\n",
    "            \n",
    "        neurons = model.batch_step_hopfield(  x, y_one_hot, hopfield_g, lr, neural_lr_start, \n",
    "                                              neural_lr_stop, neural_lr_rule, \n",
    "                                              neural_lr_decay_multiplier, neural_dynamic_iterations_free,\n",
    "                                              neural_dynamic_iterations_nudged, beta)\n",
    "\n",
    "    trn_acc = evaluateContrastiveCorInfoMax(model, train_loader, neural_lr_start, neural_lr_stop, neural_lr_rule, \n",
    "                                            neural_lr_decay_multiplier, neural_dynamic_iterations_free, device, printing = False)\n",
    "    tst_acc = evaluateContrastiveCorInfoMax(model, test_loader, neural_lr_start, neural_lr_stop, neural_lr_rule, \n",
    "                                            neural_lr_decay_multiplier, neural_dynamic_iterations_free, device, printing = False)\n",
    "    trn_acc_list.append(trn_acc)\n",
    "    tst_acc_list.append(tst_acc)\n",
    "    \n",
    "    print(\"Epoch : {}, Train Accuracy : {}, Test Accuracy : {}\".format(epoch_+1, trn_acc, tst_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe20a069",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_convergence_plot(trn_acc_list, xlabel = 'Number of Epochs', ylabel = 'Accuracy %',\n",
    "                      title = 'Contrastive CorInfoMax Train Accuracy w.r.t. Epochs', \n",
    "                      figsize = (12,8), fontsize = 25, linewidth = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e28c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_convergence_plot(tst_acc_list, xlabel = 'Number of Epochs', ylabel = 'Accuracy %',\n",
    "                      title = 'Contrastive CorInfoMax Test Accuracy w.r.t. Epochs', \n",
    "                      figsize = (12,8), fontsize = 25, linewidth = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8611a21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Math, display\n",
    "########### LATEX Style Display Matrix ###############\n",
    "def display_matrix(array):\n",
    "    \"\"\"Display given numpy array with Latex format in Jupyter Notebook.\n",
    "    Args:\n",
    "        array (numpy array): Array to be displayed\n",
    "    \"\"\"\n",
    "    data = \"\"\n",
    "    for line in array:\n",
    "        if len(line) == 1:\n",
    "            data += \" %.3f &\" % line + r\" \\\\\\n\"\n",
    "            continue\n",
    "        for element in line:\n",
    "            data += \" %.3f &\" % element\n",
    "        data += r\" \\\\\" + \"\\n\"\n",
    "    display(Math(\"\\\\begin{bmatrix} \\n%s\\\\end{bmatrix}\" % data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e88fc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_matrix(model.B[0]['weight'][:10,:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cac654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display_matrix(torch.linalg.inv(model.Rh1)[:10,:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f3192b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.norm(model.B[0]['weight'] - torch.linalg.inv(model.Rh1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865769b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display_matrix(torch.linalg.inv(model.Rh2)[:10,:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
