{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fd7911f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import glob\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "from itertools import repeat\n",
    "from torch.nn.parameter import Parameter\n",
    "import collections\n",
    "import matplotlib\n",
    "from torch_utils import *\n",
    "from ExplicitModels import *\n",
    "from visualization import *\n",
    "# matplotlib.use('Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0481fdbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94c4836a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(),])\n",
    "\n",
    "mnist_dset_train = torchvision.datasets.MNIST('./data', train=True, transform=transform, target_transform=None, download=True)\n",
    "train_loader = torch.utils.data.DataLoader(mnist_dset_train, batch_size=20, shuffle=True, num_workers=0)\n",
    "\n",
    "mnist_dset_test = torchvision.datasets.MNIST('./data', train=False, transform=transform, target_transform=None, download=True)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_dset_test, batch_size=20, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd835cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# activation = F.relu\n",
    "# architecture = [784, 128, 64, 10]\n",
    "# lambda_ = 0.99999\n",
    "# epsilon = 0.2\n",
    "# supervised_lambda_weight = 1e-3\n",
    "# neural_lr_start = 0.001 \n",
    "# neural_lr_stop = 0.0005 \n",
    "# neural_lr_rule = \"constant\"\n",
    "# neural_lr_decay_multiplier = 0.005\n",
    "# neural_dynamic_iterations = 50\n",
    "\n",
    "\n",
    "# activation = F.relu\n",
    "# architecture = [784, 128, 64, 10]\n",
    "# lambda_ = 1\n",
    "# epsilon = 0.01\n",
    "# supervised_lambda_weight = 1\n",
    "# neural_lr_start = 1e-5\n",
    "# neural_lr_stop = 0.0005 \n",
    "# neural_lr_rule = \"constant\"\n",
    "# neural_lr_decay_multiplier = 0.005\n",
    "# neural_dynamic_iterations = 20\n",
    "\n",
    "# model = CorInfoMaxBiDirectionalNudged(architecture, lambda_, epsilon, activation, use_stepLR = True, \n",
    "#                                       sgd_nesterov = False, optimizer_type = \"sgd\", \n",
    "#                                       optim_lr_ff = 0.01, optim_lr_fb = 0.01, stepLR_step_size = 10*3000,)\n",
    "\n",
    "activation = F.relu\n",
    "architecture = [784, 128, 64, 10]\n",
    "lambda_ = 0.99999\n",
    "epsilon = 0.01\n",
    "supervised_lambda_weight = 1e-3\n",
    "neural_lr_start = 0.1\n",
    "neural_lr_stop = 0.0 \n",
    "neural_lr_rule = \"constant\"\n",
    "neural_lr_decay_multiplier = 0.005\n",
    "neural_dynamic_iterations = 50\n",
    "\n",
    "model = CorInfoMaxBiDirectionalNudged(architecture, lambda_, epsilon, activation, use_stepLR = True, \n",
    "                                      sgd_nesterov = False, optimizer_type = \"sgd\", \n",
    "                                      optim_lr_ff = 0.1, optim_lr_fb = 0.1, stepLR_step_size = 10*3000,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1c3cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [10:29,  4.77it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1, Train Accuracy : 0.11336666666666667, Test Accuracy : 0.1154\n",
      "B_1 update difference : 0.34239089488983154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "588it [01:54,  8.57it/s]"
     ]
    }
   ],
   "source": [
    "trn_acc_list = []\n",
    "tst_acc_list = []\n",
    "random_sign = False\n",
    "n_epochs = 50\n",
    "\n",
    "for epoch_ in range(n_epochs):\n",
    "    Bcopy = torch.clone(model.B[0][\"weight\"])\n",
    "    for idx, (x, y) in tqdm(enumerate(train_loader)):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        x = x.to(device).view(x.size(0),-1).T\n",
    "        y_one_hot = F.one_hot(y, 10).to(device).T\n",
    "        #y_one_hot = 0.94 * y_one_hot + 0.03 * torch.ones(*y_one_hot.shape, device = device)\n",
    "        if random_sign:\n",
    "            rnd_sgn = 2*np.random.randint(2) - 1\n",
    "            supervised_lambda_weight = rnd_sgn * supervised_lambda_weight\n",
    "\n",
    "        model.batch_step(  x, y_one_hot, supervised_lambda_weight,\n",
    "                           neural_lr_start, neural_lr_stop, neural_lr_rule,\n",
    "                           neural_lr_decay_multiplier, neural_dynamic_iterations,\n",
    "                        )\n",
    "#         if idx % 1 == 0:\n",
    "#             trn_acc = evaluatePC(model, train_loader, device, False, \n",
    "#                                  printing = False)\n",
    "#             tst_acc = evaluatePC(model, test_loader, device, False, \n",
    "#                                  printing = False)\n",
    "#             trn_acc_list.append(trn_acc)\n",
    "#             tst_acc_list.append(tst_acc)\n",
    "\n",
    "#             print(\"Epoch : {}, Train Accuracy : {}, Test Accuracy : {}\".format(epoch_+1, trn_acc, tst_acc))\n",
    "#             print(\"B_1 update difference : {}\".format(torch.norm(model.B[0]['weight'] - Bcopy)))\n",
    "        \n",
    "        \n",
    "    trn_acc = evaluatePC(model, train_loader, device, False, \n",
    "                         printing = False)\n",
    "    tst_acc = evaluatePC(model, test_loader, device, False, \n",
    "                         printing = False)\n",
    "    trn_acc_list.append(trn_acc)\n",
    "    tst_acc_list.append(tst_acc)\n",
    "    \n",
    "    print(\"Epoch : {}, Train Accuracy : {}, Test Accuracy : {}\".format(epoch_+1, trn_acc, tst_acc))\n",
    "    print(\"B_1 update difference : {}\".format(torch.norm(model.B[0]['weight'] - Bcopy)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c825e017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2b1adc4630a0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(torch2numpy(model.Wff[0]['weight']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767527c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2980ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f315fc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4e325d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5e48c290",
   "metadata": {},
   "outputs": [],
   "source": [
    "myiter = iter(train_loader)\n",
    "\n",
    "activation = F.relu\n",
    "architecture = [784, 128, 64, 10]\n",
    "lambda_ = 1\n",
    "epsilon = 0.1\n",
    "supervised_lambda_weight = 1e-6\n",
    "neural_lr_start = 1e-39\n",
    "neural_lr_stop = 0.0 \n",
    "neural_lr_rule = \"constant\"\n",
    "neural_lr_decay_multiplier = 0.005\n",
    "neural_dynamic_iterations = 1\n",
    "\n",
    "model = CorInfoMaxBiDirectionalNudged(architecture, lambda_, epsilon, activation, use_stepLR = True, \n",
    "                                      sgd_nesterov = False, optimizer_type = \"sgd\", \n",
    "                                      optim_lr_ff = 1.0, optim_lr_fb = 0, stepLR_step_size = 10*3000,)\n",
    "\n",
    "# Feedforward Synapses Initialization\n",
    "Wff = []\n",
    "for idx in range(len(architecture)-1):\n",
    "    # weight = torch.svd(torch.eye(architecture[idx + 1], architecture[idx]).to(self.device)) [2].T\n",
    "    weight = torch.eye(architecture[idx + 1], architecture[idx]).to(model.device)\n",
    "    bias = torch.zeros(architecture[idx + 1], 1).to(model.device)\n",
    "\n",
    "    # torch.nn.init.xavier_uniform_(weight)\n",
    "    # torch.nn.init.xavier_uniform_(bias)\n",
    "\n",
    "#     torch.nn.init.kaiming_uniform_(weight)\n",
    "#     fan_in, _ = torch.nn.init._calculate_fan_in_and_fan_out(weight)\n",
    "#     bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n",
    "#     torch.nn.init.uniform_(bias, -bound, bound)\n",
    "\n",
    "    Wff.append({'weight': weight.requires_grad_(), 'bias': bias.requires_grad_()})\n",
    "Wff = np.array(Wff)\n",
    "\n",
    "# Feedback Synapses Initialization\n",
    "Wfb = []\n",
    "for idx in range(len(architecture)-1):\n",
    "    weight = torch.eye(architecture[idx], architecture[idx + 1]).to(model.device)\n",
    "    bias = torch.zeros(architecture[idx], 1).to(model.device)\n",
    "\n",
    "#     weight = torch.linalg.pinv(Wff[idx]['weight'].detach())\n",
    "    # torch.nn.init.xavier_uniform_(weight)\n",
    "    # torch.nn.init.xavier_uniform_(bias)\n",
    "\n",
    "#     torch.nn.init.kaiming_uniform_(weight)\n",
    "#     fan_in, _ = torch.nn.init._calculate_fan_in_and_fan_out(weight)\n",
    "#     bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n",
    "#     torch.nn.init.uniform_(bias, -bound, bound)\n",
    "\n",
    "    Wfb.append({'weight': weight.requires_grad_(), 'bias': bias.requires_grad_()})\n",
    "Wfb = np.array(Wfb)\n",
    "\n",
    "# Lateral Synapses Initialization\n",
    "B = []\n",
    "for idx in range(len(architecture)-1):\n",
    "    weight = torch.randn(architecture[idx + 1], architecture[idx + 1], requires_grad = False).to(model.device)\n",
    "    # torch.nn.init.xavier_uniform_(weight)\n",
    "    torch.nn.init.kaiming_uniform_(weight)\n",
    "    weight = weight @ weight.T\n",
    "    weight = torch.eye(architecture[idx + 1], architecture[idx + 1], requires_grad = False).to(model.device)\n",
    "    B.append({'weight': weight})\n",
    "B = np.array(B)\n",
    "\n",
    "# Lateral Synapses Initialization\n",
    "Bsigma = []\n",
    "for idx in range(len(architecture)-1):\n",
    "    weight = torch.randn(architecture[idx + 1], architecture[idx + 1], requires_grad = False).to(model.device)\n",
    "    torch.nn.init.kaiming_uniform_(weight)\n",
    "    weight = weight @ weight.T\n",
    "    weight = torch.eye(architecture[idx + 1], architecture[idx + 1], requires_grad = False).to(model.device)\n",
    "    Bsigma.append({'weight': weight})\n",
    "Bsigma = np.array(Bsigma)\n",
    "\n",
    "model.Wff = Wff\n",
    "model.Wfb = Wfb\n",
    "model.B = B\n",
    "model.Bsigma = Bsigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8bbd38c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., device='cuda:0')"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(myiter)\n",
    "\n",
    "x, y = x.to(device), y.to(device)\n",
    "x = x.to(device).view(x.size(0),-1).T\n",
    "y_one_hot = F.one_hot(y, 10).to(device).T\n",
    "\n",
    "Wff, Wfb = model.Wff, model.Wfb\n",
    "B, Bsigma = model.B, model.Bsigma\n",
    "lambda_ = model.lambda_\n",
    "gam_ = model.gam_\n",
    "\n",
    "# optimizer = self.optimizer\n",
    "neurons = model.fast_forward(x, no_grad = True)\n",
    "# neurons = model.init_neurons(x.size(1), device = model.device)\n",
    "\n",
    "neurons = model.run_neural_dynamics( x, y_one_hot, neurons, supervised_lambda_weight, \n",
    "                                    neural_lr_start, neural_lr_stop, lr_rule = neural_lr_rule,\n",
    "                                    lr_decay_multiplier = neural_lr_decay_multiplier, \n",
    "                                    neural_dynamic_iterations = neural_dynamic_iterations)\n",
    "\n",
    "# neurons = model.neurons_zero_grad(neurons)\n",
    "model.optimizer.zero_grad()\n",
    "corinfo_cost = model.CorInfo_Cost(x, y, neurons).sum() #* (1 / lambda_weight) \n",
    "corinfo_cost.backward()\n",
    "model.optimizer.step()\n",
    "\n",
    "torch.norm(model.Wff[0][\"weight\"].grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e5ad9982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([8, 6, 6, 5, 5, 2, 1, 8, 0, 5, 6, 1, 6, 9, 6, 4, 1, 4, 7, 1],\n",
       "        device='cuda:0'),\n",
       " tensor([8, 6, 6, 5, 5, 2, 1, 8, 0, 5, 6, 1, 6, 9, 6, 4, 1, 4, 7, 1],\n",
       "        device='cuda:0'))"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(neurons[-1], 0), y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b866ad33",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(torch2numpy(Wff[0][\"weight\"].grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c05a57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(torch2numpy(Wfb[2][\"weight\"].grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3312ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Wfb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c26597c",
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_dynamic_iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da4c8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.Wfb[1]['weight'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845b41ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(torch2numpy(model.B[0]['weight']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951e0d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch2numpy(model.B[0]['weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a86f051",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.ones(128,128).to('cuda') + 0.0*model.B[0]['weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4b5528",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876fd719",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c3d59ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# activation = F.relu\n",
    "# architecture = [784, 128, 64, 10]\n",
    "# lambda_ = 0.9999\n",
    "# epsilon = 0.01\n",
    "# supervised_lambda_weight = 1e-3\n",
    "# neural_lr_start = 0.001 \n",
    "# neural_lr_stop = 0.0005 \n",
    "# neural_lr_rule = \"constant\"\n",
    "# neural_lr_decay_multiplier = 0.005\n",
    "# neural_dynamic_iterations = 50\n",
    "\n",
    "# model = CorInfoMaxBiDirectionalNudged(architecture, lambda_, epsilon, activation, use_stepLR = True, \n",
    "#                                       sgd_nesterov = False, optimizer_type = \"sgd\", \n",
    "#                                       optim_lr_ff = 1, optim_lr_fb = 0.1, stepLR_step_size = 10*3000,)\n",
    "\n",
    "activation = F.relu\n",
    "architecture = [784, 128, 64, 10]\n",
    "lambda_ = 0.99999\n",
    "epsilon = 0.01\n",
    "supervised_lambda_weight = 1\n",
    "neural_lr_start = 0.1 \n",
    "neural_lr_stop = 0.0005 \n",
    "neural_lr_rule = \"constant\"\n",
    "neural_lr_decay_multiplier = 0.005\n",
    "neural_dynamic_iterations = 20\n",
    "\n",
    "model = CorInfoMaxBiDirectionalNudged(architecture, lambda_, epsilon, activation, use_stepLR = True, \n",
    "                                      sgd_nesterov = False, optimizer_type = \"sgd\", \n",
    "                                      optim_lr_ff = 1, optim_lr_fb = 0.5, stepLR_step_size = 10*3000,)\n",
    "\n",
    "# model = CorInfoMaxNudged(architecture, lambda_, epsilon, activation, use_stepLR = True, \n",
    "#                          sgd_nesterov = False, optimizer_type = \"sgd\", \n",
    "#                          optim_lr = 1, stepLR_step_size = 10*3000,)\n",
    "\n",
    "x, y = next(iter(train_loader))\n",
    "x, y = x.to(device), y.to(device)\n",
    "x = x.to(device).view(x.size(0),-1).T\n",
    "y_one_hot = F.one_hot(y, 10).to(device).T\n",
    "\n",
    "neurons = model.fast_forward(x, no_grad = True)\n",
    "neurons = model.init_neurons(x.size(1), device = model.device)\n",
    "# for jj in range(len(neurons)):\n",
    "#     neurons[jj] = neurons[jj].requires_grad_()\n",
    "    \n",
    "# layers = [x] + neurons\n",
    "\n",
    "# layers_copy = model.copy_neurons(layers)\n",
    "# neurons = model.fast_forward(x, no_grad = True)\n",
    "neurons = model.run_neural_dynamics(x, y_one_hot, neurons, supervised_lambda_weight, \n",
    "                          neural_lr_start, neural_lr_stop, lr_rule = neural_lr_rule, \n",
    "                          lr_decay_multiplier = neural_lr_decay_multiplier, \n",
    "                          neural_dynamic_iterations = neural_dynamic_iterations)\n",
    "\n",
    "# corinfo_cost = model.CorInfo_Cost(x, y, neurons).sum()\n",
    "# corinfo_cost.backward()\n",
    "\n",
    "# (model.Wff[0]['weight'].grad)\n",
    "# neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91df46cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2, 4, 7, 4, 4, 4, 1, 7, 4, 5, 7, 8, 6, 8, 7, 8, 0, 0, 8, 8],\n",
       "        device='cuda:0'),\n",
       " tensor([2, 4, 7, 4, 4, 4, 1, 7, 4, 5, 7, 8, 6, 8, 7, 8, 0, 0, 8, 8],\n",
       "        device='cuda:0'))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(neurons[-1], 0), y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49285f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(torch2numpy((model.Wff[0]['weight'].grad)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa3d5df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a7e317",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab4bf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "mbs = x.size(1)\n",
    "for jj in range(len(neurons)):\n",
    "    neurons[jj] = neurons[jj].requires_grad_()\n",
    "corinfo_cost = model.CorInfo_Cost(x, y, neurons)\n",
    "init_grads = torch.tensor([1 for i in range(mbs)], dtype=torch.float, device=device, requires_grad=True) #Initializing gradients\n",
    "grads = torch.autograd.grad(corinfo_cost, neurons, grad_outputs=init_grads, create_graph=False) # dPhi/ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2b99d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_over_epsilon = model.one_over_epsilon\n",
    "gam_ = model.gam_\n",
    "\n",
    "x, y = next(iter(train_loader))\n",
    "x, y = x.to(device), y.to(device)\n",
    "x = x.to(device).view(x.size(0),-1).T\n",
    "y_one_hot = F.one_hot(y, 10).to(device).T\n",
    "\n",
    "Wff = model.Wff\n",
    "B = model.B\n",
    "\n",
    "neurons = model.fast_forward(x, no_grad = True)\n",
    "\n",
    "layers = [x] + neurons\n",
    "for jj in range(len(Wff)):\n",
    "    if jj == 0:\n",
    "        error = - one_over_epsilon * (layers[jj + 1] - (Wff[jj]['weight'] @ layers[jj] + Wff[jj]['bias'])) \n",
    "    else:\n",
    "        error = - one_over_epsilon * (layers[jj + 1] - (Wff[jj]['weight'] @ model.activation(layers[jj]) + Wff[jj]['bias']))\n",
    "\n",
    "    lateral_term = gam_ * 0.5 * (layers[jj + 1].T @ B[jj]['weight'] @ layers[jj + 1])\n",
    "    corinfo_cost = torch.sum(error * error, 0)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7159306a",
   "metadata": {},
   "outputs": [],
   "source": [
    "error.shape\n",
    "torch.sum(error * error, 0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3592a711",
   "metadata": {},
   "outputs": [],
   "source": [
    "outer_prod_broadcasting((B[jj]['weight'] @ layers[jj + 1]), layers[jj + 1].T).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac8cf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers[jj + 1][:,2].T @ B[jj]['weight'] @ layers[jj + 1][:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c09111",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sum((B[jj]['weight'] @ layers[jj + 1]) * layers[jj + 1], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb89c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(B[jj]['weight'] @ layers[jj + 1]).shape, layers[jj + 1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d5baa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_acc_list = []\n",
    "tst_acc_list = []\n",
    "random_sign = False\n",
    "n_epochs = 50\n",
    "\n",
    "for epoch_ in range(n_epochs):\n",
    "    for idx, (x, y) in tqdm(enumerate(train_loader)):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        x = x.to(device).view(x.size(0),-1).T\n",
    "        y_one_hot = F.one_hot(y, 10).to(device).T\n",
    "        #y_one_hot = 0.94 * y_one_hot + 0.03 * torch.ones(*y_one_hot.shape, device = device)\n",
    "        if random_sign:\n",
    "            rnd_sgn = 2*np.random.randint(2) - 1\n",
    "            supervised_lambda_weight = rnd_sgn * supervised_lambda_weight\n",
    "\n",
    "        model.batch_step(  x, y_one_hot, supervised_lambda_weight,\n",
    "                           neural_lr_start, neural_lr_stop, neural_lr_rule,\n",
    "                           neural_lr_decay_multiplier, neural_dynamic_iterations,\n",
    "                        )\n",
    "\n",
    "    trn_acc = evaluatePC(model, train_loader, device, False, \n",
    "                         printing = False)\n",
    "    tst_acc = evaluatePC(model, test_loader, device, False, \n",
    "                         printing = False)\n",
    "    trn_acc_list.append(trn_acc)\n",
    "    tst_acc_list.append(tst_acc)\n",
    "    \n",
    "    print(\"Epoch : {}, Train Accuracy : {}, Test Accuracy : {}\".format(epoch_+1, trn_acc, tst_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
