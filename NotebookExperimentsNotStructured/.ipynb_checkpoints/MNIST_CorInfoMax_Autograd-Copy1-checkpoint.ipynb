{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fd7911f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import glob\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "from itertools import repeat\n",
    "from torch.nn.parameter import Parameter\n",
    "import collections\n",
    "import matplotlib\n",
    "from torch_utils import *\n",
    "from ExplicitModels import *\n",
    "from visualization import *\n",
    "# matplotlib.use('Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0481fdbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94c4836a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(), \n",
    "                                            torchvision.transforms.Normalize(mean=(0.0,), std=(1.0,))])\n",
    "\n",
    "mnist_dset_train = torchvision.datasets.MNIST('./data', train=True, transform=transform, target_transform=None, download=True)\n",
    "train_loader = torch.utils.data.DataLoader(mnist_dset_train, batch_size=20, shuffle=True, num_workers=0)\n",
    "\n",
    "mnist_dset_test = torchvision.datasets.MNIST('./data', train=False, transform=transform, target_transform=None, download=True)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_dset_test, batch_size=20, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd835cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# activation = torch.sigmoid\n",
    "def mysoftmax(x, dim = 0):\n",
    "    return F.softmax(x, dim)\n",
    "\n",
    "def kWTA(inp_vector, k = 1):\n",
    "    tmpx = torch.clone(inp_vector)\n",
    "    topval = tmpx.topk(k, dim=0)[0][k - 1]\n",
    "    topval = topval.repeat(tmpx.shape[0], 1)\n",
    "    comp = (inp_vector>=topval)\n",
    "    return comp*inp_vector\n",
    "\n",
    "def Sparsify_kWTA(inp_vector, sparsity = 0.1):\n",
    "    k = int(inp_vector.shape[0] * sparsity)\n",
    "    if k == 0:\n",
    "        k = 1\n",
    "    tmpx = torch.clone(inp_vector)\n",
    "    topval = tmpx.topk(k, dim=0)[0][k - 1]\n",
    "    topval = topval.repeat(tmpx.shape[0], 1)\n",
    "    comp = (inp_vector>=topval)\n",
    "    return comp*inp_vector\n",
    "\n",
    "activation = Sparsify_kWTA\n",
    "\n",
    "architecture = [784, 500, 10]\n",
    "lambda_ = 0.9999\n",
    "epsilon = 0.01\n",
    "neural_lr_start = 0.1\n",
    "neural_lr_stop = 0.00\n",
    "neural_lr_rule = \"constant\"\n",
    "neural_lr_decay_multiplier = 0.005\n",
    "neural_dynamic_iterations = 50\n",
    "\n",
    "model = CorInfoMaxBiDirectional_wAutoGrad(architecture, lambda_, epsilon, activation, optimizer_type = \"sgd\",\n",
    "                                          optim_lr_ff = 0.01, optim_lr_fb = 0.001, \n",
    "                                          use_stepLR = True, sgd_weight_decay = 0.001, \n",
    "                                          stepLR_step_size = 10*3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f667b5df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [04:16, 11.69it/s]\n",
      "1it [00:00,  9.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1, Train Accuracy : 0.8989166666666667, Test Accuracy : 0.9052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [04:16, 11.68it/s]\n",
      "1it [00:00,  9.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 2, Train Accuracy : 0.90565, Test Accuracy : 0.9077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [04:20, 11.53it/s]\n",
      "1it [00:00,  8.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 3, Train Accuracy : 0.91415, Test Accuracy : 0.9152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [04:29, 11.12it/s]\n",
      "1it [00:00,  8.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 4, Train Accuracy : 0.9142333333333333, Test Accuracy : 0.9142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [04:22, 11.42it/s]\n",
      "1it [00:00,  5.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 5, Train Accuracy : 0.9177166666666666, Test Accuracy : 0.9198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [04:22, 11.44it/s]\n",
      "1it [00:00,  9.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 6, Train Accuracy : 0.9178666666666667, Test Accuracy : 0.916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "76it [00:07,  9.86it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_108795/1267604165.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m#y_one_hot = 0.94 * y_one_hot + 0.03 * torch.ones(*y_one_hot.shape, device = device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         model.batch_step(  x, y_one_hot, neural_lr_start, neural_lr_stop, neural_lr_rule,\n\u001b[0m\u001b[1;32m     16\u001b[0m                            \u001b[0mneural_lr_decay_multiplier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneural_dynamic_iterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                          )\n",
      "\u001b[0;32m/scratch/users/bbozkurt15/CorInfoMaxSupervised/Supervised-CorInfoMax/src/ExplicitModels.py\u001b[0m in \u001b[0;36mbatch_step\u001b[0;34m(self, x, y, neural_lr_start, neural_lr_stop, neural_lr_rule, neural_lr_decay_multiplier, neural_dynamic_iterations, mode)\u001b[0m\n\u001b[1;32m    848\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m         \u001b[0mpc_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPC_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneurons\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 850\u001b[0;31m         \u001b[0mpc_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    851\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m         \u001b[0;31m# optimizer = self.optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/bbozkurt15/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/bbozkurt15/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trn_acc_list = []\n",
    "tst_acc_list = []\n",
    "\n",
    "n_epochs = 50\n",
    "\n",
    "for epoch_ in range(n_epochs):\n",
    "\n",
    "    for idx, (x, y) in tqdm(enumerate(train_loader)):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        #x = activation_inverse(x.view(x.size(0),-1).T, \"sigmoid\")\n",
    "        x = x.view(x.size(0),-1).T\n",
    "        y_one_hot = 2*F.one_hot(y, 10).to(device).T\n",
    "        #y_one_hot = 0.94 * y_one_hot + 0.03 * torch.ones(*y_one_hot.shape, device = device)\n",
    "        \n",
    "        model.batch_step(  x, y_one_hot, neural_lr_start, neural_lr_stop, neural_lr_rule,\n",
    "                           neural_lr_decay_multiplier, neural_dynamic_iterations,\n",
    "                         )\n",
    "\n",
    "    trn_acc = evaluatePC(model, train_loader, device, False, \n",
    "                         printing = False)\n",
    "    tst_acc = evaluatePC(model, test_loader, device, False, \n",
    "                         printing = False)\n",
    "    trn_acc_list.append(trn_acc)\n",
    "    tst_acc_list.append(tst_acc)\n",
    "    \n",
    "    print(\"Epoch : {}, Train Accuracy : {}, Test Accuracy : {}\".format(epoch_+1, trn_acc, tst_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "627dd106",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_topk(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].flatten().float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        \n",
    "    result = [res_.item() for res_ in res]\n",
    "    if len(result) == 1:\n",
    "        result = result[0]\n",
    "    return result\n",
    "\n",
    "def evaluatePC_topk(model, loader, device, apply_activation_inverse = True, \n",
    "                    activation_type = \"sigmoid\", topk = [2], printing = True):\n",
    "    # Evaluate Predictive Coding Model on Classification Task\n",
    "    correct=0\n",
    "    phase = 'Train' if loader.dataset.train else 'Test'\n",
    "    \n",
    "    for x, y in loader:\n",
    "        if apply_activation_inverse:\n",
    "            x = activation_inverse(x.view(x.size(0),-1).T, activation_type).to(device)\n",
    "        else:\n",
    "            x = x.view(x.size(0),-1).T.to(device)\n",
    "        batch_size = x.size(1)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        neurons = model.fast_forward(x)\n",
    "\n",
    "        #pred = torch.argmax(neurons[-1], dim=0).squeeze()  \n",
    "        pred = neurons[-1]\n",
    "        correct += accuracy_topk(pred.T, y, topk) * batch_size\n",
    "\n",
    "    acc = correct/len(loader.dataset) \n",
    "    if printing:\n",
    "        print(phase+' accuracy :\\t', acc)   \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0141b80f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy :\t 96.355\n",
      "Test accuracy :\t 96.46\n"
     ]
    }
   ],
   "source": [
    "trn_acc = evaluatePC_topk(model, train_loader, device, False, \n",
    "                     printing = True, topk = [2])\n",
    "tst_acc = evaluatePC_topk(model, test_loader, device, False, \n",
    "                     printing = True, topk = [2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb79f02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(train_loader))\n",
    "x, y = x.to(device), y.to(device)\n",
    "x = x.view(x.size(0),-1).T\n",
    "target = y\n",
    "output = model.fast_forward(x)[-1].T\n",
    "mytopk = (2,)\n",
    "maxk = max(mytopk)\n",
    "batch_size = target.size(0)\n",
    "_, pred = output.topk(maxk, 1, True, True)\n",
    "pred = pred.t()\n",
    "correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "pred, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32d100e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output[8,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95222d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct[:2].flatten().float().sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41466dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "target.view(1, -1).expand_as(pred), pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fee3df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(train_loader))\n",
    "x, y = x.to(device), y.to(device)\n",
    "x = x.view(x.size(0),-1).T\n",
    "pred = model.fast_forward(x)[-1]\n",
    "accuracy_topk(pred.T, y, [1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508504b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.argmax(model.fast_forward(x)[-1], 0), y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ca3229",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fast_forward(x)[-1][:,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1f3774",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(torch2numpy(model.B[0]['weight']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4b90e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.norm(model.Wfb[1]['weight'] - torch.eye(*model.Wfb[1]['weight'].shape).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7652bde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.Wfb[1]['weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1730c3b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c73a9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(model.neural_dynamics_loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f801b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fast_forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3465da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15b16bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbb3fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity = 0.1\n",
    "int(neurons[0].shape[0] * sparsity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16a23a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "topval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b6d632",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 1\n",
    "tmpx = torch.clone(neurons[0]) # x.view(x.shape[0], -1)\n",
    "topval = tmpx.topk(k, dim=0)[0][0]#tmpx.topk(k, dim=0)[0][:,-1]\n",
    "topval = topval.repeat(tmpx.shape[0], 1)#.permute(1,0)\n",
    "# comp = (neurons[0]>=topval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631aab27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kWTA(inp_vector, k = 3):\n",
    "    tmpx = torch.clone(inp_vector)\n",
    "    topval = tmpx.topk(k, dim=0)[0][k - 1]\n",
    "    topval = topval.repeat(tmpx.shape[0], 1)\n",
    "    comp = (inp_vector>=topval)\n",
    "    return comp*inp_vector, topval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6541012",
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebecf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa, topval = kWTA(neurons[0], 5)\n",
    "torch.sum(aa[:,0] != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c67f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons[0].topk(3, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a625645f",
   "metadata": {},
   "outputs": [],
   "source": [
    "topval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ce6d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpx.topk(k, dim=0)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0883fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.max(neurons[0][:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d180b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "topval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe15aa6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "topval.repeat(tmpx.shape[1], 1).permute(1,0).shape#.view_as(neurons[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1873a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kWTA(inp_vector, k = 1):\n",
    "    tmpx = torch.clone(inp_vector) # x.view(x.shape[0], -1)\n",
    "    topval = tmpx.topk(k, dim=1)[0][:,-1]\n",
    "#     topval = topval.repeat(tmpx.shape[1], 1).permute(1,0)#.view_as(x)\n",
    "    topval = topval.repeat(tmpx.shape[1], 1).T\n",
    "    comp = (inp_vector>=topval)#.to(x)\n",
    "    return comp*inp_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d38e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc06dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "kWTA(neurons[0])[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa3d9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a82292",
   "metadata": {},
   "outputs": [],
   "source": [
    "kWTA(neurons[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1562863c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(train_loader))\n",
    "x = x.view(x.size(0),-1).T\n",
    "x, y = x.to(device), y.to(device)\n",
    "y = F.one_hot(y, 10).to(device).T\n",
    "neurons = model.init_neurons(x.size(1))\n",
    "\n",
    "mode = \"train\"\n",
    "if mode == \"train\":\n",
    "    neurons[-1] = y.to(torch.float)\n",
    "\n",
    "\n",
    "neurons = model.run_neural_dynamics( x, y, neurons, neural_lr_start, neural_lr_stop, lr_rule = neural_lr_rule,\n",
    "                                    lr_decay_multiplier = neural_lr_decay_multiplier, \n",
    "                                    neural_dynamic_iterations = neural_dynamic_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd0f976",
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0571fffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# F.softmax(neurons[0], 0)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ddb537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.sum(F.softmax(neurons[0], 0), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe66593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optim_params = []\n",
    "# for idx in range(len(model.Wff)):\n",
    "#     for key_ in [\"weight\", \"bias\"]:\n",
    "#         optim_params.append(  {'params': model.Wff[idx][key_], 'lr': lr_start[\"ff\"]}  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7526f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = torch.optim.Adam(optim_params, maximize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07503a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_acc_list = []\n",
    "tst_acc_list = []\n",
    "\n",
    "n_epochs = 50\n",
    "\n",
    "for epoch_ in range(n_epochs):\n",
    "    if epoch_ > 12:\n",
    "        neural_lr_start = 0.05\n",
    "    if epoch_ > 17:\n",
    "        neural_lr_start = 0.03\n",
    "    for idx, (x, y) in tqdm(enumerate(train_loader)):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        #x = activation_inverse(x.view(x.size(0),-1).T, \"sigmoid\")\n",
    "        x = x.view(x.size(0),-1).T\n",
    "        y_one_hot = F.one_hot(y, 10).to(device).T\n",
    "        y_one_hot = 0.94 * y_one_hot + 0.03 * torch.ones(*y_one_hot.shape, device = device)\n",
    "        \n",
    "        model.batch_step(  x, y_one_hot, neural_lr_start, neural_lr_stop, neural_lr_rule,\n",
    "                           neural_lr_decay_multiplier, neural_dynamic_iterations,\n",
    "                         )\n",
    "\n",
    "    trn_acc = evaluatePC(model, train_loader, device, False, \n",
    "                         printing = False)\n",
    "    tst_acc = evaluatePC(model, test_loader, device, False, \n",
    "                         printing = False)\n",
    "    trn_acc_list.append(trn_acc)\n",
    "    tst_acc_list.append(tst_acc)\n",
    "    \n",
    "    print(\"Epoch : {}, Train Accuracy : {}, Test Accuracy : {}\".format(epoch_+1, trn_acc, tst_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7579379b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.Wff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebdc5e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
