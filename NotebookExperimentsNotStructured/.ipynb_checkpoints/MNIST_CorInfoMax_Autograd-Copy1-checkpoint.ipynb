{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fd7911f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import glob\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "from itertools import repeat\n",
    "from torch.nn.parameter import Parameter\n",
    "import collections\n",
    "import matplotlib\n",
    "from torch_utils import *\n",
    "from ExplicitModels import *\n",
    "from visualization import *\n",
    "# matplotlib.use('Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0481fdbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94c4836a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(), \n",
    "                                            torchvision.transforms.Normalize(mean=(0.0,), std=(1.0,))])\n",
    "\n",
    "mnist_dset_train = torchvision.datasets.MNIST('./data', train=True, transform=transform, target_transform=None, download=True)\n",
    "train_loader = torch.utils.data.DataLoader(mnist_dset_train, batch_size=20, shuffle=True, num_workers=0)\n",
    "\n",
    "mnist_dset_test = torchvision.datasets.MNIST('./data', train=False, transform=transform, target_transform=None, download=True)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_dset_test, batch_size=20, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef96ca33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = torch.linspace(-2, 2, 100)\n",
    "y = torch.clip(x, -1, 1)\n",
    "plt.plot(x, y)\n",
    "\n",
    "def clipping_activation(x, min_ = -1, max_ = 1):\n",
    "    return torch.clip(x, min_, max_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd835cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# activation = torch.sigmoid\n",
    "def mysoftmax(x, dim = 0):\n",
    "    return F.softmax(x, dim)\n",
    "\n",
    "def kWTA(inp_vector, k = 1):\n",
    "    tmpx = torch.clone(inp_vector)\n",
    "    topval = tmpx.topk(k, dim=0)[0][k - 1]\n",
    "    topval = topval.repeat(tmpx.shape[0], 1)\n",
    "    comp = (inp_vector>=topval)\n",
    "    return comp*inp_vector\n",
    "\n",
    "def Sparsify_kWTA(inp_vector, sparsity = 0.1):\n",
    "    k = int(inp_vector.shape[0] * sparsity)\n",
    "    if k == 0:\n",
    "        k = 1\n",
    "    tmpx = torch.clone(inp_vector)\n",
    "    topval = tmpx.topk(k, dim=0)[0][k - 1]\n",
    "    topval = topval.repeat(tmpx.shape[0], 1)\n",
    "    comp = (inp_vector>=topval)\n",
    "    return comp*inp_vector\n",
    "\n",
    "activation = clipping_activation\n",
    "\n",
    "architecture = [784, 500, 10]\n",
    "lambda_ = 0.9999\n",
    "epsilon = 0.01\n",
    "neural_lr_start = 0.1\n",
    "neural_lr_stop = 0.00\n",
    "neural_lr_rule = \"constant\"\n",
    "neural_lr_decay_multiplier = 0.005\n",
    "neural_dynamic_iterations = 50\n",
    "\n",
    "model = CorInfoMaxBiDirectional_wAutoGrad(architecture, lambda_, epsilon, activation, optimizer_type = \"sgd\",\n",
    "                                          optim_lr_ff = 0.001, optim_lr_fb = 0.001, \n",
    "                                          use_stepLR = True, sgd_weight_decay = 0.01, \n",
    "                                          stepLR_step_size = 10*3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f667b5df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [02:49, 17.68it/s]\n",
      "2it [00:00, 13.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1, Train Accuracy : 0.7274666666666667, Test Accuracy : 0.7255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1420it [01:20, 17.66it/s]"
     ]
    }
   ],
   "source": [
    "trn_acc_list = []\n",
    "tst_acc_list = []\n",
    "\n",
    "n_epochs = 50\n",
    "\n",
    "for epoch_ in range(n_epochs):\n",
    "\n",
    "    for idx, (x, y) in tqdm(enumerate(train_loader)):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        #x = activation_inverse(x.view(x.size(0),-1).T, \"sigmoid\")\n",
    "        x = x.view(x.size(0),-1).T\n",
    "        y_one_hot = 2*F.one_hot(y, 10).to(device).T\n",
    "        #y_one_hot = 0.94 * y_one_hot + 0.03 * torch.ones(*y_one_hot.shape, device = device)\n",
    "        \n",
    "        model.batch_step(  x, y_one_hot, neural_lr_start, neural_lr_stop, neural_lr_rule,\n",
    "                           neural_lr_decay_multiplier, neural_dynamic_iterations,\n",
    "                         )\n",
    "\n",
    "    trn_acc = evaluatePC(model, train_loader, device, False, \n",
    "                         printing = False)\n",
    "    tst_acc = evaluatePC(model, test_loader, device, False, \n",
    "                         printing = False)\n",
    "    trn_acc_list.append(trn_acc)\n",
    "    tst_acc_list.append(tst_acc)\n",
    "    \n",
    "    print(\"Epoch : {}, Train Accuracy : {}, Test Accuracy : {}\".format(epoch_+1, trn_acc, tst_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "627dd106",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_topk(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].flatten().float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        \n",
    "    result = [res_.item() for res_ in res]\n",
    "    if len(result) == 1:\n",
    "        result = result[0]\n",
    "    return result\n",
    "\n",
    "def evaluatePC_topk(model, loader, device, apply_activation_inverse = True, \n",
    "                    activation_type = \"sigmoid\", topk = [2], printing = True):\n",
    "    # Evaluate Predictive Coding Model on Classification Task\n",
    "    correct=0\n",
    "    phase = 'Train' if loader.dataset.train else 'Test'\n",
    "    \n",
    "    for x, y in loader:\n",
    "        if apply_activation_inverse:\n",
    "            x = activation_inverse(x.view(x.size(0),-1).T, activation_type).to(device)\n",
    "        else:\n",
    "            x = x.view(x.size(0),-1).T.to(device)\n",
    "        batch_size = x.size(1)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        neurons = model.fast_forward(x)\n",
    "\n",
    "        #pred = torch.argmax(neurons[-1], dim=0).squeeze()  \n",
    "        pred = neurons[-1]\n",
    "        correct += accuracy_topk(pred.T, y, topk) * batch_size\n",
    "\n",
    "    acc = correct/len(loader.dataset) \n",
    "    if printing:\n",
    "        print(phase+' accuracy :\\t', acc)   \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0141b80f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy :\t 96.355\n",
      "Test accuracy :\t 96.46\n"
     ]
    }
   ],
   "source": [
    "trn_acc = evaluatePC_topk(model, train_loader, device, False, \n",
    "                     printing = True, topk = [2])\n",
    "tst_acc = evaluatePC_topk(model, test_loader, device, False, \n",
    "                     printing = True, topk = [2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb79f02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(train_loader))\n",
    "x, y = x.to(device), y.to(device)\n",
    "x = x.view(x.size(0),-1).T\n",
    "target = y\n",
    "output = model.fast_forward(x)[-1].T\n",
    "mytopk = (2,)\n",
    "maxk = max(mytopk)\n",
    "batch_size = target.size(0)\n",
    "_, pred = output.topk(maxk, 1, True, True)\n",
    "pred = pred.t()\n",
    "correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "pred, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32d100e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output[8,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95222d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct[:2].flatten().float().sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41466dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "target.view(1, -1).expand_as(pred), pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fee3df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(train_loader))\n",
    "x, y = x.to(device), y.to(device)\n",
    "x = x.view(x.size(0),-1).T\n",
    "pred = model.fast_forward(x)[-1]\n",
    "accuracy_topk(pred.T, y, [1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508504b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.argmax(model.fast_forward(x)[-1], 0), y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ca3229",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fast_forward(x)[-1][:,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1f3774",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(torch2numpy(model.B[0]['weight']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4b90e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.norm(model.Wfb[1]['weight'] - torch.eye(*model.Wfb[1]['weight'].shape).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7652bde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.Wfb[1]['weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1730c3b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c73a9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(model.neural_dynamics_loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f801b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fast_forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3465da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15b16bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbb3fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity = 0.1\n",
    "int(neurons[0].shape[0] * sparsity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16a23a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "topval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b6d632",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 1\n",
    "tmpx = torch.clone(neurons[0]) # x.view(x.shape[0], -1)\n",
    "topval = tmpx.topk(k, dim=0)[0][0]#tmpx.topk(k, dim=0)[0][:,-1]\n",
    "topval = topval.repeat(tmpx.shape[0], 1)#.permute(1,0)\n",
    "# comp = (neurons[0]>=topval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631aab27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kWTA(inp_vector, k = 3):\n",
    "    tmpx = torch.clone(inp_vector)\n",
    "    topval = tmpx.topk(k, dim=0)[0][k - 1]\n",
    "    topval = topval.repeat(tmpx.shape[0], 1)\n",
    "    comp = (inp_vector>=topval)\n",
    "    return comp*inp_vector, topval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6541012",
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebecf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa, topval = kWTA(neurons[0], 5)\n",
    "torch.sum(aa[:,0] != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c67f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons[0].topk(3, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a625645f",
   "metadata": {},
   "outputs": [],
   "source": [
    "topval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ce6d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpx.topk(k, dim=0)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0883fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.max(neurons[0][:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d180b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "topval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe15aa6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "topval.repeat(tmpx.shape[1], 1).permute(1,0).shape#.view_as(neurons[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1873a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kWTA(inp_vector, k = 1):\n",
    "    tmpx = torch.clone(inp_vector) # x.view(x.shape[0], -1)\n",
    "    topval = tmpx.topk(k, dim=1)[0][:,-1]\n",
    "#     topval = topval.repeat(tmpx.shape[1], 1).permute(1,0)#.view_as(x)\n",
    "    topval = topval.repeat(tmpx.shape[1], 1).T\n",
    "    comp = (inp_vector>=topval)#.to(x)\n",
    "    return comp*inp_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d38e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc06dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "kWTA(neurons[0])[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa3d9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a82292",
   "metadata": {},
   "outputs": [],
   "source": [
    "kWTA(neurons[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1562863c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(train_loader))\n",
    "x = x.view(x.size(0),-1).T\n",
    "x, y = x.to(device), y.to(device)\n",
    "y = F.one_hot(y, 10).to(device).T\n",
    "neurons = model.init_neurons(x.size(1))\n",
    "\n",
    "mode = \"train\"\n",
    "if mode == \"train\":\n",
    "    neurons[-1] = y.to(torch.float)\n",
    "\n",
    "\n",
    "neurons = model.run_neural_dynamics( x, y, neurons, neural_lr_start, neural_lr_stop, lr_rule = neural_lr_rule,\n",
    "                                    lr_decay_multiplier = neural_lr_decay_multiplier, \n",
    "                                    neural_dynamic_iterations = neural_dynamic_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd0f976",
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0571fffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# F.softmax(neurons[0], 0)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ddb537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.sum(F.softmax(neurons[0], 0), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe66593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optim_params = []\n",
    "# for idx in range(len(model.Wff)):\n",
    "#     for key_ in [\"weight\", \"bias\"]:\n",
    "#         optim_params.append(  {'params': model.Wff[idx][key_], 'lr': lr_start[\"ff\"]}  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7526f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = torch.optim.Adam(optim_params, maximize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07503a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_acc_list = []\n",
    "tst_acc_list = []\n",
    "\n",
    "n_epochs = 50\n",
    "\n",
    "for epoch_ in range(n_epochs):\n",
    "    if epoch_ > 12:\n",
    "        neural_lr_start = 0.05\n",
    "    if epoch_ > 17:\n",
    "        neural_lr_start = 0.03\n",
    "    for idx, (x, y) in tqdm(enumerate(train_loader)):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        #x = activation_inverse(x.view(x.size(0),-1).T, \"sigmoid\")\n",
    "        x = x.view(x.size(0),-1).T\n",
    "        y_one_hot = F.one_hot(y, 10).to(device).T\n",
    "        y_one_hot = 0.94 * y_one_hot + 0.03 * torch.ones(*y_one_hot.shape, device = device)\n",
    "        \n",
    "        model.batch_step(  x, y_one_hot, neural_lr_start, neural_lr_stop, neural_lr_rule,\n",
    "                           neural_lr_decay_multiplier, neural_dynamic_iterations,\n",
    "                         )\n",
    "\n",
    "    trn_acc = evaluatePC(model, train_loader, device, False, \n",
    "                         printing = False)\n",
    "    tst_acc = evaluatePC(model, test_loader, device, False, \n",
    "                         printing = False)\n",
    "    trn_acc_list.append(trn_acc)\n",
    "    tst_acc_list.append(tst_acc)\n",
    "    \n",
    "    print(\"Epoch : {}, Train Accuracy : {}, Test Accuracy : {}\".format(epoch_+1, trn_acc, tst_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7579379b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.Wff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebdc5e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
